[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science Workshop",
    "section": "",
    "text": "Welcome\nThank you for checking out this workshop! This page contains a brief overview of the goals, structure, and prerequisites of the workshop."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1Â  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. â€œLiterate Programming.â€ Comput. J. 27 (2): 97â€“111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2Â  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Goodman, Steven N, Daniele Fanelli, and John P A Ioannidis. 2016.\nâ€œWhat Does Research Reproducibility Mean?â€ Sci. Transl.\nMed. 8 (341): 341ps12.\n\n\nNational Academies of Sciences, Engineering, Medicine, Policy, Global\nAffairs, Committee on Science, Engineering, Medicine, Public Policy,\nBoard on Research Data, et al. 2019. Understanding Reproducibility\nand Replicability. National Academies Press (US).\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, and Eivind Hovig.\n2013. â€œTen Simple Rules for Reproducible Computational\nResearch.â€ PLoS Comput. Biol. 9 (10): e1003285.\n\n\nWickham, Hadley. 2014. â€œTidy Data.â€ J. Stat.\nSoftw. 59 (September): 1â€“23."
  },
  {
    "objectID": "index.html#disclaimer",
    "href": "index.html#disclaimer",
    "title": "Data Science Workshop",
    "section": "Disclaimer",
    "text": "Disclaimer\nThe following workshop contains my opinions on learning R and programming in general. I am no expert â€“ so please feel free to disagree with me on anything. In general, this workshop is designed to give you some exposure to a few useful topics, but it is by necessity incomplete. Very little, if any, of this workshop is uniquely mine. Instead, over the years, I have compiled a bunch of useful nuggets from other places. And I have packaged those nuggets here to fit within the scope this workshop. But, I strongly encourage you to check out those alternative7 resources. They are linked below and throughout this document. Therefore, I hope this tutorial will be useful, if through nothing else, as a portal to more useful parts of the internet.\n\n\n\n\n\n\nAlternative resources\n\n\n\n\nR for Data Science â€“ a wonderfully thorough and useful book that emphasizes the tidyverse\nR for Graduate Students â€“ very accessible introduction to R & the tidyverse\nFundamentals of Data Visualization â€“ â€œA guide to making visualizations that accurately reflect the data, tell a story, and look professional.â€ by Claus O. Wilke. This book is great, because it is not at all about programming, but just how to make the best data visualizations.\nAdvanced R â€“ R with the nitty-gritty details for the super nerds out there.\nggplot2 book â€“ detailed introduction to plotting with ggplot2\nLearning Statistics with R â€“ great book with an emphasis on stats\nR Markdown: The Definitive Guide â€“ great overview of the features of R Markdown\nR Markdown Cookbook â€“ additional R Markdown guide\nHappy Git and GitHub for the useR â€“ resource for version control\nNick Gotelliâ€™s Computational Biology â€“ a wonderful course on R taught by Nick Gotelli at UVM."
  },
  {
    "objectID": "index.html#alternative-resources",
    "href": "index.html#alternative-resources",
    "title": "Data Science Workshop",
    "section": "Alternative resources",
    "text": "Alternative resources\n\n\n\n\n\n\nAlternative resources\n\n\n\n\nGoogle â€“ when in doubt, Google it out\nR for Data Science â€“ a wonderfully thorough and useful book that emphasizes the tidyverse\nR for Graduate Students â€“ very accessible introduction to R & the tidyverse\nFundamentals of Data Visualization â€“ â€œA guide to making visualizations that accurately reflect the data, tell a story, and look professional.â€ by Claus O. Wilke. This book is great, because it is not at all about programming, but just how to make the best data visualizations.\nAdvanced R â€“ R with the nitty-gritty details for the super nerds out there.\nggplot2 book â€“ detailed introduction to plotting with ggplot2\nLearning Statistics with R â€“ there is also a newer version that is in development that emphasizes the tidyverse.\nR Markdown: The Definitive Guide â€“ great overview of the features of R Markdown\nR Markdown Cookbook â€“ additional R Markdown guide\nHappy Git and GitHub for the useR â€“ resource for version control\nNick Gotelliâ€™s Computational Biology â€“ a wonderful course on R taught by Nick Gotelli at UVM."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Data Science Workshop",
    "section": "",
    "text": "â†©ï¸\nI am not claiming to have found the global optimum of data science. I promise I would share the secret if I had it.â†©ï¸\nlike keeping the default theme â€“ yikes!â†©ï¸\nShould I use a box plot, strip chart, or violin plot?â†©ï¸\nI confess I have spent way to much time trying to find the most pleasing shade of purple.â†©ï¸\nThese prerequisites are intentionally designed to be a relatively low bar. See the green box if you donâ€™t meet these prerequisites.â†©ï¸\nread: betterâ†©ï¸"
  },
  {
    "objectID": "index.html#agenda",
    "href": "index.html#agenda",
    "title": "Data Science Workshop",
    "section": "Agenda",
    "text": "Agenda"
  },
  {
    "objectID": "index.html#structure",
    "href": "index.html#structure",
    "title": "Data Science Workshop",
    "section": "Structure",
    "text": "Structure\nThere are three parts to this workshop. But each is designed to be self-contained â€“ so you may pick-and-choose to attend any or all of these workshops. The three parts are as follows:\n\nComputational reproducibility\nPrinciples of the tidyverse and advanced techniques\nData visualization for presentations and publications"
  },
  {
    "objectID": "tidyverse.html#tidy-data",
    "href": "tidyverse.html#tidy-data",
    "title": "2Â  Tidyverse",
    "section": "2.2 Tidy data",
    "text": "2.2 Tidy data\nThe tidyverse gets its name from the type of data that it is designed to interact with â€“ tidy data. So letâ€™s quickly define tidy data4.\n\n\n\n\n\n\nTidy data â€“ definition\n\n\n\n\nEvery column is a variable.\nEvery row is an observation.\nEvery cell is a single value.\n\n\n\nBut that definition is a bit abstract â€“ especially if you have never thought about whether data is messy or tidy before â€“ so letâ€™s try a practical example.\nBelow is some made-up messy data.\nImagine over the course of several days, you measure the height of a few plants\n\n# Make up some random data\ndat &lt;- tibble(\n  plant_id = 1:15,\n  week1 = rnorm(15, mean = 10, sd = 3),\n  week2 = week1*runif(15, min = 1, max = 1.5),\n  week3 = week2*runif(15, min = 1, max = 1.5),\n  week4 = week3*runif(15, min = 1, max = 1.5),\n  week5 = week4*runif(15, min = 1, max = 1.5)\n)\n\n# Print the data\ndat\n\n# A tibble: 15 Ã— 6\n   plant_id   week1  week2  week3  week4  week5\n      &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1        1 11.5    15.3   19.6   22.5   31.9  \n 2        2  7.42   10.1   11.7   15.3   21.3  \n 3        3 10.8    15.8   18.0   23.3   27.6  \n 4        4 15.9    16.2   16.6   22.0   27.8  \n 5        5  9.09   10.0   13.8   18.0   21.7  \n 6        6  8.46    9.35  12.5   17.7   25.8  \n 7        7 11.5    13.6   14.6   15.6   16.9  \n 8        8 10.1    12.5   18.3   22.4   26.6  \n 9        9  8.85   11.8   13.7   16.8   19.2  \n10       10  8.55   12.0   15.8   18.0   20.1  \n11       11 13.0    18.2   21.2   22.2   24.7  \n12       12 11.0    13.0   19.4   26.6   38.1  \n13       13 11.6    11.6   13.5   16.2   22.4  \n14       14  0.0825  0.123  0.169  0.187  0.208\n15       15 12.8    14.1   18.0   19.7   28.6  \n\n\n\n2.2.1 Letâ€™s tidy it\n\ndat |&gt;\n  pivot_longer(contains(\"week\"),\n               names_to = \"week\",\n               values_to = \"height_cm\")\n\n# A tibble: 75 Ã— 3\n   plant_id week  height_cm\n      &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1        1 week1     11.5 \n 2        1 week2     15.3 \n 3        1 week3     19.6 \n 4        1 week4     22.5 \n 5        1 week5     31.9 \n 6        2 week1      7.42\n 7        2 week2     10.1 \n 8        2 week3     11.7 \n 9        2 week4     15.3 \n10        2 week5     21.3 \n# â€¦ with 65 more rows\n\n\n\nBAM! That is tidy data. 1. Every column is a variable â€“ id, time, height. 2. Every row is an observation â€“ a height measurement on a single plant. 3. Every cell is a single value.\n\n\ndat |&gt;\n  pivot_longer(contains(\"week\"),\n               names_to = \"week\",\n               values_to = \"height_cm\") |&gt; \n  mutate(week = as.numeric(str_remove_all(week, \"week\")))\n\n# A tibble: 75 Ã— 3\n   plant_id  week height_cm\n      &lt;int&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1        1     1     11.5 \n 2        1     2     15.3 \n 3        1     3     19.6 \n 4        1     4     22.5 \n 5        1     5     31.9 \n 6        2     1      7.42\n 7        2     2     10.1 \n 8        2     3     11.7 \n 9        2     4     15.3 \n10        2     5     21.3 \n# â€¦ with 65 more rows"
  },
  {
    "objectID": "tidyverse.html#guiding-principles",
    "href": "tidyverse.html#guiding-principles",
    "title": "2Â  Tidyverse",
    "section": "2.1 Guiding principles",
    "text": "2.1 Guiding principles\nâ€“"
  },
  {
    "objectID": "tidyverse.html#core-verbs",
    "href": "tidyverse.html#core-verbs",
    "title": "2Â  Tidyverse",
    "section": "2.2 Core verbs",
    "text": "2.2 Core verbs"
  },
  {
    "objectID": "tidyverse.html#advanced-techniques",
    "href": "tidyverse.html#advanced-techniques",
    "title": "2Â  Tidyverse",
    "section": "2.3 Advanced techniques",
    "text": "2.3 Advanced techniques\n\nOther useful tidyverse packages\n\nbroom â€“ clean model output â€“ technically a subpackage of tidymodels a cousin of the tidyverse\nrvest â€“ web scraping â€“ mining data from a website\nmodelr â€“ modelling â€“ support for modelling data in the tidyverse"
  },
  {
    "objectID": "repro.html",
    "href": "repro.html",
    "title": "2Â  Reproducibility & directory structure",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "Data Science Workshop",
    "section": "Prerequisites",
    "text": "Prerequisites\nThis workshop assumes several things6:\n\nYou have R and RStudio installed on your machine and you come ready to follow along with some coding.\nYou have some basic familiarity with coding in R. For example, you know the difference between a vector and a data frame.\nYou are able to do some simple tasks in R â€“ like creating an object, getting the mean of a vector, or importing a csv file.\n\n\n\n\n\n\n\nGood news if you are starting from zero\n\n\n\nYou can meet the above criteria in less than a day!\nThere are several great resources on the internet that will walk you through downloading R and R Studio and give you the basics. You will not need much experience at all for our workshop â€“ just a familiarity with the basics. Due to our limited time, and the wealth of resources covering step zero, we will start at step one and hit the ground running.\n\nResources if you are starting out â€“ or need a quick refresh\n\nR for Graduate Students â€“ very accessible introduction to R & the tidyverse\nR for Data Science â€“ a wonderfully thorough and useful book that emphasizes the tidyverse"
  },
  {
    "objectID": "tidyverse.html",
    "href": "tidyverse.html",
    "title": "2Â  Tidyverse",
    "section": "",
    "text": "3 Tidy data\nThe tidyverse gets its name from the type of data that it is designed to interact with â€“ tidy data. So letâ€™s quickly define tidy data.\nYikes. Thatâ€™s abstractâ€¦"
  },
  {
    "objectID": "tidyverse.html#links",
    "href": "tidyverse.html#links",
    "title": "2Â  Tidyverse",
    "section": "2.4 Links",
    "text": "2.4 Links\n\n2.4.1 Books & webpages\n\ntidyverse website â€“ poke around this website and you can stumble on some good stuff\nThe tidy tools manifesto â€“ who doesnâ€™t love a good manifesto? 1"
  },
  {
    "objectID": "tidyverse.html#what-is-the-tidyverse",
    "href": "tidyverse.html#what-is-the-tidyverse",
    "title": "2Â  Tidyverse",
    "section": "2.1 What is the tidyverse?",
    "text": "2.1 What is the tidyverse?\nA suite of inter-related packages with a common grammar and syntax.\n\n# Load library\nlibrary(tidyverse)\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.0     âœ” readr     2.1.4\nâœ” forcats   1.0.0     âœ” stringr   1.5.0\nâœ” ggplot2   3.4.1     âœ” tibble    3.1.8\nâœ” lubridate 1.9.2     âœ” tidyr     1.3.0\nâœ” purrr     1.0.1     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\n\n\nThis will load"
  },
  {
    "objectID": "tidyverse.html#messy-data",
    "href": "tidyverse.html#messy-data",
    "title": "2Â  Tidyverse",
    "section": "2.5 Messy data",
    "text": "2.5 Messy data\nAn example of some messy data.\n\n# Make up some random data\nmdh_df &lt;- tibble(gill = rnorm(15, mean = 12, sd = 2),\n                 adductor = rnorm(15, mean = 18, sd = 2.5),\n                 mantle = rnorm(15, mean = 6, sd = 3))\n\n# Print the data\nmdh_df\n\n# A tibble: 15 Ã— 3\n    gill adductor mantle\n   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n 1 13.2      17.6  4.93 \n 2 11.1      17.4  2.58 \n 3 12.9      19.0  4.31 \n 4  7.04     17.8  5.16 \n 5  8.24     17.4  1.27 \n 6 10.4      19.4  8.61 \n 7 12.1      18.2  8.04 \n 8 11.4      20.7  1.53 \n 9 13.7      15.8  9.55 \n10 14.2      17.2 10.0  \n11 16.0      16.0  6.62 \n12 13.1      17.8  3.89 \n13  8.76     17.1 11.5  \n14 13.2      16.9  0.427\n15 11.1      16.9  6.94"
  },
  {
    "objectID": "tidyverse.html#lets-tidy-it",
    "href": "tidyverse.html#lets-tidy-it",
    "title": "2Â  Tidyverse",
    "section": "2.4 Letâ€™s tidy it",
    "text": "2.4 Letâ€™s tidy it\n\ndat &lt;- dat |&gt;\n  pivot_longer(everything(),\n               names_to = \"tissue\",\n               values_to = \"iu_gfw\")\n\ndat\n\n# A tibble: 45 Ã— 2\n   tissue   iu_gfw\n   &lt;chr&gt;     &lt;dbl&gt;\n 1 gill      13.9 \n 2 adductor  15.3 \n 3 mantle     5.33\n 4 gill      13.4 \n 5 adductor  16.6 \n 6 mantle     6.31\n 7 gill      12.0 \n 8 adductor  15.2 \n 9 mantle     9.03\n10 gill      11.5 \n# â€¦ with 35 more rows\n\n\n\nBAM! That is tidy data. 1. Every column is a variable â€“ tissue and enzyme activity. 2. Every row is an observation â€“ enzyme activity in I.U./g f.w.. 3. Every cell is a single value."
  },
  {
    "objectID": "tidyverse.html#why-use-readr",
    "href": "tidyverse.html#why-use-readr",
    "title": "2Â  Tidyverse",
    "section": "4.1 Why use readr?",
    "text": "4.1 Why use readr?\nI find it a lot easier to define the data structure as you import data. And it creates a tibble instead of data.frame.\n\n# Create a .csv file to import\nwrite_csv(iris, \"iris.csv\")\n\n\n# Try read.csv\nd.f &lt;- read.csv(\"iris.csv\")\n\nstr(d.f)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : chr  \"setosa\" \"setosa\" \"setosa\" \"setosa\" ...\n\n\n\n# Try read_csv\nread_csv(\"iris.csv\")\n\nRows: 150 Columns: 5\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (1): Species\ndbl (4): Sepal.Length, Sepal.Width, Petal.Length, Petal.Width\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 150 Ã— 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# â€¦ with 140 more rows\n\n# Set col_type as you import data -- allows you to define level order too\nd_f &lt;- read_csv(\"iris.csv\",\n                col_types = list(Species = col_factor(c(\"versicolor\",\n                                                        \"setosa\", \n                                                        \"virginica\"))))\nd_f\n\n# A tibble: 150 Ã— 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# â€¦ with 140 more rows\n\nstr(d_f)\n\nspc_tbl_ [150 Ã— 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Sepal.Length: num [1:150] 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num [1:150] 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num [1:150] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num [1:150] 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"versicolor\",\"setosa\",..: 2 2 2 2 2 2 2 2 2 2 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Sepal.Length = col_double(),\n  ..   Sepal.Width = col_double(),\n  ..   Petal.Length = col_double(),\n  ..   Petal.Width = col_double(),\n  ..   Species = col_factor(levels = c(\"versicolor\", \"setosa\", \"virginica\"), ordered = FALSE, include_na = FALSE)\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nglimpse(d_f)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.â€¦\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.â€¦\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.â€¦\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.â€¦\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, sâ€¦"
  },
  {
    "objectID": "tidyverse.html#intro-to-dplyr",
    "href": "tidyverse.html#intro-to-dplyr",
    "title": "2Â  Tidyverse",
    "section": "5.1 Intro to dplyr",
    "text": "5.1 Intro to dplyr\ndplyr has a few core functions that are built to work on\nTaken from the dplyr vignette.\n\n5.1.1 Rows\n\nfilter() chooses rows based on column values.\nslice() chooses rows based on location.\narrange() changes the order of the rows.\n\n\n\n5.1.2 Columns\n\nselect() changes whether or not a column is included.\nrename() changes the name of columns.\nmutate() changes the values of columns and creates new columns.\nrelocate() changes the order of the columns.\n\n\n\n5.1.3 Groups of rows\n\nsummarise() collapses a group into a single row."
  },
  {
    "objectID": "tidyverse.html#pipe",
    "href": "tidyverse.html#pipe",
    "title": "2Â  Tidyverse",
    "section": "5.2 Pipe |>",
    "text": "5.2 Pipe |&gt;\nFrom magrittr.\n\nx |&gt; f is equivalent to f(x)\nx |&gt; f(y) is equivalent to f(x, y)\nx |&gt; f |&gt; g |&gt; h is equivalent to h(g(f(x)))\n\nThe argument placeholder\n\nx |&gt; f(y, .) is equivalent to f(y, x)\nx |&gt; f(y, z = .) is equivalent to f(y, z = x)\n\n\n5.2.1 A fun example from R for data science\n\nfoo_foo &lt;- little_bunny()\nfoo_foo_1 &lt;- hop(foo_foo, through = forest)\nfoo_foo_2 &lt;- scoop(foo_foo_1, up = field_mice)\nfoo_foo_3 &lt;- bop(foo_foo_2, on = head)\n\n\nfoo_foo |&gt;\n  hop(through = forest) |&gt;\n  scoop(up = field_mice) |&gt;\n  bop(on = head)"
  },
  {
    "objectID": "tidyverse.html#arrange",
    "href": "tidyverse.html#arrange",
    "title": "2Â  Tidyverse",
    "section": "5.3 arrange",
    "text": "5.3 arrange\n\nmdh_df |&gt;\n  arrange(tissue, iu_gfw)\n\n# A tibble: 45 Ã— 2\n   tissue   iu_gfw\n   &lt;chr&gt;     &lt;dbl&gt;\n 1 adductor   11.4\n 2 adductor   14.9\n 3 adductor   15.5\n 4 adductor   17.4\n 5 adductor   17.9\n 6 adductor   18.9\n 7 adductor   19.0\n 8 adductor   19.3\n 9 adductor   19.7\n10 adductor   19.7\n# â€¦ with 35 more rows\n\n\n\nmdh_df |&gt;\n  arrange(desc(tissue), desc(iu_gfw))\n\n# A tibble: 45 Ã— 2\n   tissue iu_gfw\n   &lt;chr&gt;   &lt;dbl&gt;\n 1 mantle  11.7 \n 2 mantle  10.3 \n 3 mantle  10.2 \n 4 mantle   8.88\n 5 mantle   8.69\n 6 mantle   7.85\n 7 mantle   6.49\n 8 mantle   6.27\n 9 mantle   6.05\n10 mantle   6.01\n# â€¦ with 35 more rows"
  },
  {
    "objectID": "tidyverse.html#summarise",
    "href": "tidyverse.html#summarise",
    "title": "2Â  Tidyverse",
    "section": "5.4 summarise",
    "text": "5.4 summarise\n\nmdh_df |&gt;\n  summarise(iu_gfw_avg = mean(iu_gfw))\n\n# A tibble: 1 Ã— 1\n  iu_gfw_avg\n       &lt;dbl&gt;\n1       12.9"
  },
  {
    "objectID": "tidyverse.html#group_by",
    "href": "tidyverse.html#group_by",
    "title": "2Â  Tidyverse",
    "section": "5.5 group_by",
    "text": "5.5 group_by\n\nmdh_df |&gt;\n  group_by(tissue) |&gt;\n  summarise(iu_gfw_avg = mean(iu_gfw),\n            iu_gfw_sd = sd(iu_gfw))\n\n# A tibble: 3 Ã— 3\n  tissue   iu_gfw_avg iu_gfw_sd\n  &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;\n1 adductor      19.0       3.45\n2 gill          12.4       1.75\n3 mantle         7.15      2.34\n\n\nWarning that you must be careful about the order when reusing variable names.\n\n# Bad order\nmdh_df |&gt;\n  group_by(tissue) |&gt;\n  summarise(iu_gfw = mean(iu_gfw),\n            sd = sd(iu_gfw))\n\n# A tibble: 3 Ã— 3\n  tissue   iu_gfw    sd\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 adductor  19.0     NA\n2 gill      12.4     NA\n3 mantle     7.15    NA\n\n\n\n# This order works because it collapses the data into a mean last\nmdh_df |&gt;\n  group_by(tissue) |&gt;\n  summarise(sd = sd(iu_gfw),\n            iu_gfw = mean(iu_gfw))\n\n# A tibble: 3 Ã— 3\n  tissue      sd iu_gfw\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 adductor  3.45  19.0 \n2 gill      1.75  12.4 \n3 mantle    2.34   7.15\n\n\nPrint out a pretty table using kableExtra."
  },
  {
    "objectID": "tidyverse.html#nest",
    "href": "tidyverse.html#nest",
    "title": "2Â  Tidyverse",
    "section": "5.6 nest",
    "text": "5.6 nest\nFor the most part, I find myself working with 2D structured data (e.g., tibble or data.frame). But sometimes you need to\n\nChickWeight |&gt;\n  glimpse()\n\nRows: 578\nColumns: 4\n$ weight &lt;dbl&gt; 42, 51, 59, 64, 76, 93, 106, 125, 149, 171, 199, 205, 40, 49, 5â€¦\n$ Time   &lt;dbl&gt; 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 1â€¦\n$ Chick  &lt;ord&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, â€¦\n$ Diet   &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, â€¦\n\n\n\nChickWeight |&gt;\n  group_by(Chick, Diet) |&gt;\n  nest() \n\n# A tibble: 50 Ã— 3\n# Groups:   Chick, Diet [50]\n   Chick Diet  data             \n   &lt;ord&gt; &lt;fct&gt; &lt;list&gt;           \n 1 1     1     &lt;tibble [12 Ã— 2]&gt;\n 2 2     1     &lt;tibble [12 Ã— 2]&gt;\n 3 3     1     &lt;tibble [12 Ã— 2]&gt;\n 4 4     1     &lt;tibble [12 Ã— 2]&gt;\n 5 5     1     &lt;tibble [12 Ã— 2]&gt;\n 6 6     1     &lt;tibble [12 Ã— 2]&gt;\n 7 7     1     &lt;tibble [12 Ã— 2]&gt;\n 8 8     1     &lt;tibble [11 Ã— 2]&gt;\n 9 9     1     &lt;tibble [12 Ã— 2]&gt;\n10 10    1     &lt;tibble [12 Ã— 2]&gt;\n# â€¦ with 40 more rows\n\n\n\nChickWeight_nest &lt;- ChickWeight |&gt;\n  group_by(Chick, Diet) |&gt;\n  nest() \n\nChickWeight_nest$data[1:2]\n\n[[1]]\n# A tibble: 12 Ã— 2\n   weight  Time\n    &lt;dbl&gt; &lt;dbl&gt;\n 1     42     0\n 2     51     2\n 3     59     4\n 4     64     6\n 5     76     8\n 6     93    10\n 7    106    12\n 8    125    14\n 9    149    16\n10    171    18\n11    199    20\n12    205    21\n\n[[2]]\n# A tibble: 12 Ã— 2\n   weight  Time\n    &lt;dbl&gt; &lt;dbl&gt;\n 1     40     0\n 2     49     2\n 3     58     4\n 4     72     6\n 5     84     8\n 6    103    10\n 7    122    12\n 8    138    14\n 9    162    16\n10    187    18\n11    209    20\n12    215    21"
  },
  {
    "objectID": "tidyverse.html#broom",
    "href": "tidyverse.html#broom",
    "title": "2Â  Tidyverse",
    "section": "5.7 broom",
    "text": "5.7 broom\nCHeck out the broom vignette.\nAnd the broom and dplyr vignette.\ntidy: constructs a tibble that summarizes the modelâ€™s statistical findings. This includes coefficients and p-values for each term in a regression, per-cluster information in clustering applications, or per-test information for multtest functions.\nglance: construct a concise one-row summary of the model. This typically contains values such as R^2, adjusted R^2, and residual standard error that are computed once for the entire model.\n\nChickWeight |&gt;\n  group_by(Chick, Diet) |&gt;\n  nest() |&gt;\n  mutate(\n    fit = map(data, ~ lm(weight ~ Time, data = .x)),\n    tidied = map(fit, tidy),\n    glanced = map(fit, glance)\n  ) |&gt; \n  unnest(tidied) \n\n# A tibble: 100 Ã— 10\n# Groups:   Chick, Diet [50]\n   Chick Diet  data     fit    term    estimâ€¦Â¹ std.eâ€¦Â² statiâ€¦Â³  p.value glanced \n   &lt;ord&gt; &lt;fct&gt; &lt;list&gt;   &lt;list&gt; &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;list&gt;  \n 1 1     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   24.5    6.73     3.64 4.56e- 3 &lt;tibble&gt;\n 2 1     1     &lt;tibble&gt; &lt;lm&gt;   Time       7.99   0.524   15.3  2.97e- 8 &lt;tibble&gt;\n 3 2     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   24.7    4.93     5.01 5.26e- 4 &lt;tibble&gt;\n 4 2     1     &lt;tibble&gt; &lt;lm&gt;   Time       8.72   0.384   22.7  6.15e-10 &lt;tibble&gt;\n 5 3     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   23.2    5.08     4.56 1.04e- 3 &lt;tibble&gt;\n 6 3     1     &lt;tibble&gt; &lt;lm&gt;   Time       8.49   0.396   21.5  1.08e- 9 &lt;tibble&gt;\n 7 4     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   32.9    4.01     8.21 9.42e- 6 &lt;tibble&gt;\n 8 4     1     &lt;tibble&gt; &lt;lm&gt;   Time       6.09   0.312   19.5  2.70e- 9 &lt;tibble&gt;\n 9 5     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   16.9    7.56     2.24 4.93e- 2 &lt;tibble&gt;\n10 5     1     &lt;tibble&gt; &lt;lm&gt;   Time      10.1    0.588   17.1  9.88e- 9 &lt;tibble&gt;\n# â€¦ with 90 more rows, and abbreviated variable names Â¹â€‹estimate, Â²â€‹std.error,\n#   Â³â€‹statistic\n\n\n\nChickWeight |&gt;\n  ggplot() +\n  geom_line(aes(x = Time, \n                 y = weight, \n                 color = Chick)) +\n  facet_wrap(~ Diet)"
  },
  {
    "objectID": "tidyverse.html#standard-curve-linear-regression",
    "href": "tidyverse.html#standard-curve-linear-regression",
    "title": "2Â  Tidyverse",
    "section": "6.1 Standard curve linear regression",
    "text": "6.1 Standard curve linear regression\n\n# Run linear model\nstd_lm &lt;- lm(abs ~ NADH, nadh_df)\n\nsummary(std_lm)\n\n\n# Save intercept & slope values\nint &lt;- as.numeric(std_lm$coefficients[1])\nslope &lt;- as.numeric(std_lm$coefficients[2])\n\n# Save values in a named vector\nstd_curve_lm &lt;- c(int = int, \n                  slope = slope)\n\nstd_curve_lm"
  },
  {
    "objectID": "tidyverse.html#absorbance-data",
    "href": "tidyverse.html#absorbance-data",
    "title": "2Â  Tidyverse",
    "section": "6.2 Absorbance data",
    "text": "6.2 Absorbance data\n\n# ADH activity absorbance data\nadh_df\n\n\n6.2.1 Tidy the data\n\nadh_df &lt;- adh_df %&gt;%\n  pivot_longer(cols = contains(\"min\"), \n               names_to = \"mins\", \n               values_to = \"abs\") %&gt;%\n  mutate(mins = as.numeric(str_remove_all(mins, \"_min\")))\n\nadh_df\n\n# Add temp data with some noise\nx &lt;- adh_df %&gt;%\n  mutate(temp = 23,\n         abs = abs*rnorm(160, mean = 0.9, sd = 0.02))\n\nadh_df &lt;- bind_rows(adh_df, x)"
  },
  {
    "objectID": "tidyverse.html#plot-the-standard-curve",
    "href": "tidyverse.html#plot-the-standard-curve",
    "title": "2Â  Tidyverse",
    "section": "6.3 Plot the standard curve",
    "text": "6.3 Plot the standard curve\n\nggplot(data = nadh_df, \n       aes(x = NADH, \n           y = abs)) +\n  geom_smooth(method = 'lm', \n              formula = y ~ x, \n              se = FALSE) +\n  geom_point() +\n  ggpmisc::stat_poly_eq(formula = y ~ x, \n                        aes(label = paste(..eq.label.., ..rr.label.., \n                                          sep = \"*\\\"; \\\"*\")),\n                        parse = TRUE, \n                        rr.digits = 5,\n                        label.x = 0.85, \n                        label.y = \"top\") +\n  theme_classic() +\n  labs(y = \"Absorbance @ 450 nm\", \n       x = \"NADH (nmol)\")"
  },
  {
    "objectID": "tidyverse.html#calculate-enzyme-activity",
    "href": "tidyverse.html#calculate-enzyme-activity",
    "title": "2Â  Tidyverse",
    "section": "6.4 Calculate enzyme activity",
    "text": "6.4 Calculate enzyme activity\n\nadh_df &lt;- adh_df %&gt;%\n  group_by(temp, EtOH) %&gt;%\n  mutate(nmol_NADH = (abs - std_curve_lm[\"int\"]) / std_curve_lm[\"slope\"],\n         deltaAbs = abs - abs[mins == 0],\n         deltaNADH = nmol_NADH - nmol_NADH[mins == 0],\n         deltaTime = mins - 0) %&gt;%\n  filter(deltaTime != 0) %&gt;%\n  mutate(dilution_factor = 150/sample_vol,\n         mU_mL = (deltaNADH/(deltaTime*(sample_vol/1000)))*dilution_factor) %&gt;%\n  ungroup(EtOH) %&gt;%\n  mutate(mU_mL = mU_mL - mU_mL[EtOH == 0])"
  },
  {
    "objectID": "tidyverse.html#calculating-km",
    "href": "tidyverse.html#calculating-km",
    "title": "2Â  Tidyverse",
    "section": "6.5 Calculating Km",
    "text": "6.5 Calculating Km\n\nadh_df %&gt;%\n  filter(mins &lt;= 60) %&gt;%\n  group_by(temp, EtOH) %&gt;%\n  nest() %&gt;%\n  mutate(\n    fit = map(data, ~ lm(abs ~ mins, data = .x)),\n    tidied = map(fit, tidy),\n    glanced = map(fit, glance))"
  },
  {
    "objectID": "tidyverse.html#footnotes",
    "href": "tidyverse.html#footnotes",
    "title": "2Â  Tidyverse",
    "section": "",
    "text": "Maybe even convert some of your old scripts to incorporate the tidyverse.â†©ï¸\nHonestly I think that joke underestimates how important good coding style is. You can actually read â€œbutitsuremakesthingseasiertoreadâ€ pretty easily because you are an expert reader â€“ youâ€™ve been at it everyday for decades â€“ coding, probably not so much. I donâ€™t think can overstate how important I think it is to write visually pleasing code.â†©ï¸\nNotice above that this function call loads nine core tidyverse packages. Any other tidyverse packages, including some we will cover later (e.g., broom), must be loaded separately.â†©ï¸\nWickham (2014)â†©ï¸"
  },
  {
    "objectID": "repro.html#power-of-projects-in-rstudio",
    "href": "repro.html#power-of-projects-in-rstudio",
    "title": "1Â  Reproducibility",
    "section": "1.2 Power of projects in RStudio",
    "text": "1.2 Power of projects in RStudio\nThe easiest ways to ensure that others (or yourself in the future) will be able to run your code without adjusting file paths is to make use of Projects in RStudio.\nJenny Bryan, a developer at RStudio, has an impassioned blog post on why you should make use of a project-oriented workflow. You should probably read this post in full, because she is threatening to set your computer on fire ğŸ”¥ if you donâ€™t listen."
  },
  {
    "objectID": "repro.html#version-control",
    "href": "repro.html#version-control",
    "title": "1Â  Reproducibility",
    "section": "1.6 Version control",
    "text": "1.6 Version control\nIt is beyond the scope of this workshop, but one important way people ensure the reproducibility of their projects is to utilize version control. In short, version control is a useful way to make sure that as you edit and add to large projects over time you donâ€™t loose/change any of the bits that make it work. For example, if you were to accidentally break a script, you could restore to a previous working version of that file, and then begin again. There are several software designed to do this, but the most popular in the data science world is Git and GitHub.\nThese tools can seem intimidating at first â€“ especially because they typically are interfaced with in the command line. But if it makes you more comfortable, you can use the point-and-click approach to git within RStudio itself or a desktop clients (e.g., GitHub Desktop). Here is a very useful tutorial on how to use Git and GitHub within RStudio.\n\n\n\n\nNational Academies of Sciences, Engineering, Medicine, Policy, Global Affairs, Committee on Science, Engineering, Medicine, Public Policy, Board on Research Data, et al. 2019. Understanding Reproducibility and Replicability. National Academies Press (US).\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, and Eivind Hovig. 2013. â€œTen Simple Rules for Reproducible Computational Research.â€ PLoS Comput. Biol. 9 (10): e1003285."
  },
  {
    "objectID": "repro.html#principles-of-reproducibility",
    "href": "repro.html#principles-of-reproducibility",
    "title": "1Â  Reproducibility",
    "section": "1.1 Principles of reproducibility",
    "text": "1.1 Principles of reproducibility"
  },
  {
    "objectID": "repro.html#workflow",
    "href": "repro.html#workflow",
    "title": "1Â  Reproducibility",
    "section": "1.3 Workflow",
    "text": "1.3 Workflow\nI believe in the power of short scripts that do â€œoneâ€ thing. For the sake of sharing science with collaborators and your future self, it is great to have your code in as tidy and neat a package as possible. One way to do that is to have modular scripts."
  },
  {
    "objectID": "repro.html#directory-structure",
    "href": "repro.html#directory-structure",
    "title": "1Â  Reproducibility",
    "section": "1.5 Directory structure",
    "text": "1.5 Directory structure\nThere are thousands of ways you could structure your files in a project â€“ but there are really only two ways of going about it. The first is ad hoc. You group up files in sub-directores as you go along, tailoring the directory structure into something that makes sense to you, or at least something that is workable. And the other way, is to use a backbone template directory struture and build off that.\nFor most of the time I have worked in R, I have used the ad hoc approach. And it the best I can say for it is that it works. In my eyes, each project is its own snowflake. But if you ask someone else to look at it, they may think a dungeon maze or London Below13 is more apt a metaphor. But I have come to embrace a consistent directory structure.\nhttps://www.r-bloggers.com/2018/08/structuring-r-projects/\n\nTemplateExample\n\n\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ 01_analysis/\nâ”‚   â”œâ”€â”€ 02_analysis/\nâ”‚   â”œâ”€â”€ 03_figures/\nâ”œâ”€â”€ data/\nâ”‚   â”œâ”€â”€ raw/\nâ”‚   â”œâ”€â”€ processed/\nâ”œâ”€â”€ docs/\nâ”‚   â”œâ”€â”€ index.qmd\nâ”œâ”€â”€ output/\nâ”‚   â”œâ”€â”€ figs/\nâ”‚   â”œâ”€â”€ tables/\nâ”œâ”€â”€ scratch/\nâ”œâ”€â”€ README.md\nâ””â”€â”€ .gitignore\n\n\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ 00_pheno/\nâ”‚   â”‚   â”œâ”€â”€ 00_pheno.R\nâ”‚   â”œâ”€â”€ 01_nuclei/\nâ”‚   â”‚   â”œâ”€â”€ 00_count_nuclei.ijm\nâ”‚   â”œâ”€â”€ 02_cellranger-arc/\nâ”‚   â”‚   â”œâ”€â”€ 00_mkref.sh\nâ”‚   â”‚   â”œâ”€â”€ 01_count.sh\nâ”‚   â”‚   â”œâ”€â”€ 02_aggr.sh\nâ”‚   â”œâ”€â”€ 03_seurat/\nâ”‚   â”‚   â”œâ”€â”€ 00_create_seurat_object.R\nâ”‚   â”‚   â”œâ”€â”€ 01_quality_control_filtering.R\nâ”‚   â”‚   â”œâ”€â”€ 02_initial_cluster.R\nâ”‚   â”œâ”€â”€ 04_plots/\nâ”‚   â”‚   â”œâ”€â”€ annot.R\nâ”‚   â”‚   â”œâ”€â”€ cluster.R\nâ”‚   â”‚   â”œâ”€â”€ final.R\nâ”œâ”€â”€ data/\nâ”‚   â”œâ”€â”€ raw/\nâ”‚   â”‚   â”œâ”€â”€ annot/\n|   |   â”‚   â”œâ”€â”€ calderon_markers.csv\n|   |   â”‚   â”œâ”€â”€ dmel_cell-cycle_genes.csv\n|   |   â”‚   â”œâ”€â”€ insitu_annot.csv\nâ”‚   â”‚   â”œâ”€â”€ nuclei/\nâ”‚   â”‚   â”œâ”€â”€ pheno/\nâ”‚   â”‚   â”œâ”€â”€ seq/\nâ”‚   â”œâ”€â”€ processed/\n|   |   â”‚   â”œâ”€â”€ annot.rds\n|   |   â”‚   â”œâ”€â”€ cluster_all.rds\n|   |   â”‚   â”œâ”€â”€ cluster_manual.rds\nâ”‚   â”‚   â”œâ”€â”€ annot/\nâ”‚   â”‚   â”œâ”€â”€ genes/\nâ”‚   â”‚   â”œâ”€â”€ seq/\nâ”‚   â”‚   â”œâ”€â”€ seurat_object/\n|   |   â”‚   â”œâ”€â”€ 00_dat_raw.rds\n|   |   â”‚   â”œâ”€â”€ 01_dat_qc.rds\n|   |   â”‚   â”œâ”€â”€ 02_dat_clust.rds\nâ”œâ”€â”€ docs/\nâ”‚   â”œâ”€â”€ index.qmd\nâ”œâ”€â”€ output/\nâ”‚   â”œâ”€â”€ figs/\n|   â”‚   â”œâ”€â”€ annot/\n|   |   â”‚   â”œâ”€â”€ umap.pdf\n|   |   â”‚   â”œâ”€â”€ tsne.pdf\n|   â”‚   â”œâ”€â”€ cluster/\n|   |   â”‚   â”œâ”€â”€ umap.pdf\n|   |   â”‚   â”œâ”€â”€ tsne.pdf\n|   â”‚   â”œâ”€â”€ final/\n|   |   â”‚   â”œâ”€â”€ fig_1.pdf\n|   |   â”‚   â”œâ”€â”€ fig_2.pdf\n|   |   â”‚   â”œâ”€â”€ fig_3.pdf\nâ”‚   â”œâ”€â”€ tables/\nâ”‚   â”œâ”€â”€ dars/\n|   â”‚   â”œâ”€â”€ cell_type.rds\n|   â”‚   â”œâ”€â”€ cluster.rds\nâ”‚   â”œâ”€â”€ degs/\n|   â”‚   â”œâ”€â”€ cell_type.rds\n|   â”‚   â”œâ”€â”€ cluster.rds\nâ”œâ”€â”€ scratch/\nâ”œâ”€â”€ README.md\nâ””â”€â”€ .gitignore\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you use Version Control this sort of directory structure is also helpful because you can easily mark entire directories to be ignored (e.g., including data/* our output/figs/* in the .gitignore file). Most version control software will have a file size limit. Anyway, the thing you are most concerned with version controlling is the code (i.e., the src/ directory). The data and output can and should be backed up somewhere else."
  },
  {
    "objectID": "repro.html#section",
    "href": "repro.html#section",
    "title": "1Â  Reproducibility",
    "section": "1.6 ",
    "text": "1.6 \n\n\n\n\n\n\nA tip for removing all unecessary or redundant code\n\n\n\nIt can be hard to strip your code down to only the necessary bits, but it is worth it for the sake of clarity.\nI sometimes create a scratch.R file or a scratch/ directory where I copy and paste bits of code that I am reluctant to throw away. I helps clean up the working code and makes me feel a little less like I wasted my time."
  },
  {
    "objectID": "index.html#resources-if-you-are-just-starting-out",
    "href": "index.html#resources-if-you-are-just-starting-out",
    "title": "Data Science Workshop",
    "section": "Resources if you are just starting out",
    "text": "Resources if you are just starting out\n\nR for Graduate Students\nR for Data Science"
  },
  {
    "objectID": "index.html#goals",
    "href": "index.html#goals",
    "title": "Data Science Workshop",
    "section": "Goals",
    "text": "Goals\nAs an open-source programming language, there is an abundance of approaches to doing data science in R. It is a wide open landscape ready for your exploration! But â€” to extend this metaphor to its breaking point â€” it isnâ€™t just a flat landscape, where each spot is as fertile as the next. It is more complicated. Its closer to a fitness landscape where there are hidden local and global optima 1. You are encouraged to explore that space for yourself â€“ find the high points and low points â€“ what works best for you and what doesnâ€™t2. But it is my hope that this workshop will serve as a useful initialization of your search of that complex adaptive landscape. And that along the way you will gain tools which will help you dig out of those valleys and climb to the top of those peaks. I have the following high-level goals for this workshop:\n\nEncourage best practices to ensure computational reproducibility. Reproducibility is not just necessary for good science â€“ it will save you and your collaborators a lot of time in the long run. Making sure your code is reproducible is not as difficult as it may seem.\nFoster an appreciation of the tidyverse and its underlying principles. Tools in R, and many other programming languages, are constantly evolving and that can make learning new tools seem futile. Especially if you already have something functional with a different set of tools. But the tidyverse, is likely to stick around, and it also represents something beyond a set of tools. It worth thinking about as a philosophy of programming that can help us write more useful and readable code.\nPersuade you to go beyond a graph that merely gets the job done and toward a version that most clearly communicates the story behind your data. There are many ways to represent data in graphical form. Each time we create a figure we are making dozens â€“ or maybe hundreds â€“ of choices. Some choices are passive3, and some are active4, and some may have little effect5, but I hope to convince you that spending some additional time iterating figures that you will share is well worth it."
  },
  {
    "objectID": "repro.html#footnotes",
    "href": "repro.html#footnotes",
    "title": "1Â  Reproducibility",
    "section": "",
    "text": "Please see Goodman, Fanelli, and Ioannidis (2016) for a more rigorous discussion of terms.â†©ï¸\nOne example of this sort of reproducibility, was the independent sets of experiments that showed that DNA as the hereditary molecule.â†©ï¸\nI hope the workshop helps ğŸ˜!â†©ï¸\nI definitely donâ€™t have a perfect workflow, but it has gotten better slowly over the years.â†©ï¸\nIn particular, taking control of the small details that make your code easier to share and easier for others to understandâ†©ï¸\nGoogle data provenance and look at the flow charts.â†©ï¸\nStatistical programming is right in Râ€™s wheelhouse. And it is also the most common type of programming for early career students in my discipline. You design and conduct an experiment. You generate data. You analyze data. You present data.â†©ï¸\nAs with all advice in these workshop, these are just my opinions â€“ no more. And as with all rules, there are always good exceptions to breaking any of these rules.â†©ï¸\nIf some of the tips donâ€™t make sense or you want more context, read on!â†©ï¸\nEither in reality or just as a mental exercise.â†©ï¸\nWhatâ€™s in the BOX???â†©ï¸\nRead this link to R for Data Science, for more information.â†©ï¸\nCheck out Neverwhere by Neil Gaimanâ†©ï¸"
  },
  {
    "objectID": "tidyverse.html#tidyverse-style",
    "href": "tidyverse.html#tidyverse-style",
    "title": "2Â  Tidyverse",
    "section": "2.2 Tidyverse style",
    "text": "2.2 Tidyverse style\nThe tidyverse style guide\n\nâ€œGood coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread.â€ 1\n\n\n\n\n\n\n\nCheat sheets\n\n\n\nTidyverse packages can help with all sorts of common data science tasks. Check out these cheat sheets for quick reference.\n\nData import\nData tidying\nData transformation\nData visualization\nFunctional programming\nStrings\nFactors\n\n\n\n\n# Load library\nlibrary(tidyverse)\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.0     âœ” readr     2.1.4\nâœ” forcats   1.0.0     âœ” stringr   1.5.0\nâœ” ggplot2   3.4.1     âœ” tibble    3.1.8\nâœ” lubridate 1.9.2     âœ” tidyr     1.3.0\nâœ” purrr     1.0.1     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\n\n\nRather than loading each package individually â€“ I often just load all of the core packages with the convenient library(tidyverse)2. Most of my scripts are dependent on at least three of the core packages, so it is easier to just have them all included. But you could load each individually."
  },
  {
    "objectID": "tidyverse.html#importing-data",
    "href": "tidyverse.html#importing-data",
    "title": "2Â  Tidyverse",
    "section": "2.4 Importing data",
    "text": "2.4 Importing data\nI find it a lot easier to define the data structure as you import data. And it creates a tibble instead of data.frame.\nThere are several reasons to prefer readr::read_csv() over base Râ€™s read.csv."
  },
  {
    "objectID": "tidyverse.html#wrangling-data",
    "href": "tidyverse.html#wrangling-data",
    "title": "2Â  Tidyverse",
    "section": "2.6 Wrangling data",
    "text": "2.6 Wrangling data\n\n2.6.1 Intro to dplyr\ndplyr has a few core functions that are built to work on\nTaken from the dplyr vignette.\n\n2.6.1.1 Rows\n\nfilter() chooses rows based on column values.\nslice() chooses rows based on location.\narrange() changes the order of the rows.\n\n\n\n2.6.1.2 Columns\n\nselect() changes whether or not a column is included.\nrename() changes the name of columns.\nmutate() changes the values of columns and creates new columns.\nrelocate() changes the order of the columns.\n\n\n\n2.6.1.3 Groups of rows\n\nsummarise() collapses a group into a single row.\n\n\n\n\n2.6.2 Pipe %&gt;%\nFrom magrittr.\n\nx %&gt;% f is equivalent to f(x)\nx %&gt;% f(y) is equivalent to f(x, y)\nx %&gt;% f %&gt;% g %&gt;% h is equivalent to h(g(f(x)))\n\nThe argument placeholder\n\nx %&gt;% f(y, .) is equivalent to f(y, x)\nx %&gt;% f(y, z = .) is equivalent to f(y, z = x)\n\n\n\n\n\n\n\n|&gt; native pipe operator\n\n\n\nIn new versions of R (&gt; 4.1.0), there is now a native pipe operator that comes within the syntax of R itself, rather than being loaded as a part of a separate package.\nAlthough they are largely the same, there are some meaningful differences between the two. These two articles from the tidyverse and Isabella VelÃ¡squez do a good job of explaining the differences relevant differences.\nI have started just using the native pipe (|&gt;) for almost all cases now. First, becuase it just looks cleaner. But also because then you can use a pipe without explicitly loading the mattingr package (_e.g.Â iris |&gt; dplyr::glimpse()). Where if you had used the magrittr pipe (%&gt;%), but not loaded the magrittr package, you would get an error.\n\n\n\n2.6.2.1 A fun example from R for data science\n\nfoo_foo &lt;- little_bunny()\nfoo_foo_1 &lt;- hop(foo_foo, through = forest)\nfoo_foo_2 &lt;- scoop(foo_foo_1, up = field_mice)\nfoo_foo_3 &lt;- bop(foo_foo_2, on = head)\n\n\nfoo_foo |&gt;\n  hop(through = forest) |&gt;\n  scoop(up = field_mice) |&gt;\n  bop(on = head)\n\n\n\n\n2.6.3 arrange\n\n# dat |&gt;\n#   arrange(tissue, iu_gfw)\n\n\n# dat |&gt;\n#   arrange(desc(tissue), desc(iu_gfw))\n\n\n\n2.6.4 summarise\n\n# dat |&gt;\n#   summarise(iu_gfw_avg = mean(iu_gfw))\n\n\n\n2.6.5 group_by\n\n# dat |&gt;\n#   group_by(tissue) |&gt;\n#   summarise(iu_gfw_avg = mean(iu_gfw),\n#             iu_gfw_sd = sd(iu_gfw))\n\nWarning that you must be careful about the order when reusing variable names.\n\n# # Bad order\n# dat |&gt;\n#   group_by(tissue) |&gt;\n#   summarise(iu_gfw = mean(iu_gfw),\n#             sd = sd(iu_gfw))\n\n\n# # This order works because it collapses the data into a mean last\n# dat |&gt;\n#   group_by(tissue) |&gt;\n#   summarise(sd = sd(iu_gfw),\n#             iu_gfw = mean(iu_gfw))\n\nPrint out a pretty table using kableExtra.\n\n\n2.6.6 nest\nFor the most part, I find myself working with 2D structured data (e.g., tibble or data.frame). But sometimes you need to\n\nChickWeight |&gt;\n  glimpse()\n\nRows: 578\nColumns: 4\n$ weight &lt;dbl&gt; 42, 51, 59, 64, 76, 93, 106, 125, 149, 171, 199, 205, 40, 49, 5â€¦\n$ Time   &lt;dbl&gt; 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 1â€¦\n$ Chick  &lt;ord&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, â€¦\n$ Diet   &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, â€¦\n\n\n\nChickWeight |&gt;\n  group_by(Chick, Diet) |&gt;\n  nest() \n\n# A tibble: 50 Ã— 3\n# Groups:   Chick, Diet [50]\n   Chick Diet  data             \n   &lt;ord&gt; &lt;fct&gt; &lt;list&gt;           \n 1 1     1     &lt;tibble [12 Ã— 2]&gt;\n 2 2     1     &lt;tibble [12 Ã— 2]&gt;\n 3 3     1     &lt;tibble [12 Ã— 2]&gt;\n 4 4     1     &lt;tibble [12 Ã— 2]&gt;\n 5 5     1     &lt;tibble [12 Ã— 2]&gt;\n 6 6     1     &lt;tibble [12 Ã— 2]&gt;\n 7 7     1     &lt;tibble [12 Ã— 2]&gt;\n 8 8     1     &lt;tibble [11 Ã— 2]&gt;\n 9 9     1     &lt;tibble [12 Ã— 2]&gt;\n10 10    1     &lt;tibble [12 Ã— 2]&gt;\n# â€¦ with 40 more rows\n\n\n\nChickWeight_nest &lt;- ChickWeight |&gt;\n  group_by(Chick, Diet) |&gt;\n  nest() \n\nChickWeight_nest$data[1:2]\n\n[[1]]\n# A tibble: 12 Ã— 2\n   weight  Time\n    &lt;dbl&gt; &lt;dbl&gt;\n 1     42     0\n 2     51     2\n 3     59     4\n 4     64     6\n 5     76     8\n 6     93    10\n 7    106    12\n 8    125    14\n 9    149    16\n10    171    18\n11    199    20\n12    205    21\n\n[[2]]\n# A tibble: 12 Ã— 2\n   weight  Time\n    &lt;dbl&gt; &lt;dbl&gt;\n 1     40     0\n 2     49     2\n 3     58     4\n 4     72     6\n 5     84     8\n 6    103    10\n 7    122    12\n 8    138    14\n 9    162    16\n10    187    18\n11    209    20\n12    215    21\n\n\n\n\n2.6.7 broom\n\n# Load library\nlibrary(broom)\n\nCheck out the broom vignette.\nAnd the broom and dplyr vignette.\ntidy: constructs a tibble that summarizes the modelâ€™s statistical findings. This includes coefficients and p-values for each term in a regression, per-cluster information in clustering applications, or per-test information for multtest functions.\nglance: construct a concise one-row summary of the model. This typically contains values such as R^2, adjusted R^2, and residual standard error that are computed once for the entire model.\n\nChickWeight |&gt;\n  group_by(Chick, Diet) |&gt;\n  nest() |&gt;\n  mutate(\n    fit = map(data, ~ lm(weight ~ Time, data = .x)),\n    tidied = map(fit, tidy),\n    glanced = map(fit, glance)\n  ) |&gt; \n  unnest(tidied) \n\n# A tibble: 100 Ã— 10\n# Groups:   Chick, Diet [50]\n   Chick Diet  data     fit    term    estimâ€¦Â¹ std.eâ€¦Â² statiâ€¦Â³  p.value glanced \n   &lt;ord&gt; &lt;fct&gt; &lt;list&gt;   &lt;list&gt; &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;list&gt;  \n 1 1     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   24.5    6.73     3.64 4.56e- 3 &lt;tibble&gt;\n 2 1     1     &lt;tibble&gt; &lt;lm&gt;   Time       7.99   0.524   15.3  2.97e- 8 &lt;tibble&gt;\n 3 2     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   24.7    4.93     5.01 5.26e- 4 &lt;tibble&gt;\n 4 2     1     &lt;tibble&gt; &lt;lm&gt;   Time       8.72   0.384   22.7  6.15e-10 &lt;tibble&gt;\n 5 3     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   23.2    5.08     4.56 1.04e- 3 &lt;tibble&gt;\n 6 3     1     &lt;tibble&gt; &lt;lm&gt;   Time       8.49   0.396   21.5  1.08e- 9 &lt;tibble&gt;\n 7 4     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   32.9    4.01     8.21 9.42e- 6 &lt;tibble&gt;\n 8 4     1     &lt;tibble&gt; &lt;lm&gt;   Time       6.09   0.312   19.5  2.70e- 9 &lt;tibble&gt;\n 9 5     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   16.9    7.56     2.24 4.93e- 2 &lt;tibble&gt;\n10 5     1     &lt;tibble&gt; &lt;lm&gt;   Time      10.1    0.588   17.1  9.88e- 9 &lt;tibble&gt;\n# â€¦ with 90 more rows, and abbreviated variable names Â¹â€‹estimate, Â²â€‹std.error,\n#   Â³â€‹statistic\n\n\n\nChickWeight |&gt;\n  ggplot() +\n  geom_line(aes(x = Time, \n                 y = weight, \n                 color = Chick)) +\n  facet_wrap(~ Diet)\n\n\n\n\n\n\n\n\nWickham, Hadley. 2014. â€œTidy Data.â€ J. Stat. Softw. 59 (September): 1â€“23."
  },
  {
    "objectID": "tidyverse.html#why-use-the-the-tidyverse",
    "href": "tidyverse.html#why-use-the-the-tidyverse",
    "title": "2Â  Tidyverse",
    "section": "2.1 Why use the the tidyverse?",
    "text": "2.1 Why use the the tidyverse?\nThere are base R equivalents to most things that you can do in the tidyverse. So you might wonder why it is necessary, or even useful, to learn the tidyverse. I think that skepticism is fair, but here are a few reasons why I think you should not only learn the tidyverse, but make it a regular part of your workflow1.\n\nAs a data scientist, most of your time will be spent writing code, not waiting for code to execute. Therefore you should put more value the coding style that is easiest to write and understand. The tidyverse emphasizes human readable code.\nBecause of the flexible nature of some of the tidyverse functions, the tidyverse can make for more reproducible code, that is less likely to break if some of the underlying data has changed or been added too.\nAn increasing number of newly developed packages depend on the tidyverse. So you might as well embrace it.\nYou are already using it! If have made any figures in R, more likely than not, you are already used one tidyverse package, ggplot2.\n\n\n2.1.1 Tidyverse style\n\n\n\n\n\n\nThe tidy tools manifesto\n\n\n\nMy favorite part of the tidyverse is the final principle in this manifesto:\n\nDesign for humans. â€œPrograms must be written for people to read, and only incidentally for machines to execute.â€ â€” Hal Abelson\n\n\n\nThe tidyverse style guide\n\nâ€œGood coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread.â€ 2\n\n\n\n\n\n\n\nCheat sheets\n\n\n\nTidyverse packages can help with many common tasks. Check out these cheat sheets for quick reference.\n\nData import\nData tidying\nData transformation\nData visualization\nFunctional programming\nStrings\nFactors\n\n\n\n\n# Load library\nlibrary(tidyverse)\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.0     âœ” readr     2.1.4\nâœ” forcats   1.0.0     âœ” stringr   1.5.0\nâœ” ggplot2   3.4.1     âœ” tibble    3.1.8\nâœ” lubridate 1.9.2     âœ” tidyr     1.3.0\nâœ” purrr     1.0.1     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\n\n\nRather than loading each package individually â€“ I often just load all of the core packages with the convenient library(tidyverse)3. Most of my scripts are dependent on at least three of the core packages, so it is easier to just have them all included. But you could load each individually."
  },
  {
    "objectID": "tidyverse.html#tools-for-quick-clean-up",
    "href": "tidyverse.html#tools-for-quick-clean-up",
    "title": "2Â  Tidyverse",
    "section": "2.5 Tools for quick clean up",
    "text": "2.5 Tools for quick clean up\nA hazard of caring about how coding in the tidyverse style, is that you will notice bad formatting everywhere.\n\n2.5.1 Stylr package\n\n\n2.5.2 Janitor package\nJanitor package\nCleaning up data\n\niris |&gt; \n  janitor::clean_names()\n\n    sepal_length sepal_width petal_length petal_width    species\n1            5.1         3.5          1.4         0.2     setosa\n2            4.9         3.0          1.4         0.2     setosa\n3            4.7         3.2          1.3         0.2     setosa\n4            4.6         3.1          1.5         0.2     setosa\n5            5.0         3.6          1.4         0.2     setosa\n6            5.4         3.9          1.7         0.4     setosa\n7            4.6         3.4          1.4         0.3     setosa\n8            5.0         3.4          1.5         0.2     setosa\n9            4.4         2.9          1.4         0.2     setosa\n10           4.9         3.1          1.5         0.1     setosa\n11           5.4         3.7          1.5         0.2     setosa\n12           4.8         3.4          1.6         0.2     setosa\n13           4.8         3.0          1.4         0.1     setosa\n14           4.3         3.0          1.1         0.1     setosa\n15           5.8         4.0          1.2         0.2     setosa\n16           5.7         4.4          1.5         0.4     setosa\n17           5.4         3.9          1.3         0.4     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.7         3.8          1.7         0.3     setosa\n20           5.1         3.8          1.5         0.3     setosa\n21           5.4         3.4          1.7         0.2     setosa\n22           5.1         3.7          1.5         0.4     setosa\n23           4.6         3.6          1.0         0.2     setosa\n24           5.1         3.3          1.7         0.5     setosa\n25           4.8         3.4          1.9         0.2     setosa\n26           5.0         3.0          1.6         0.2     setosa\n27           5.0         3.4          1.6         0.4     setosa\n28           5.2         3.5          1.5         0.2     setosa\n29           5.2         3.4          1.4         0.2     setosa\n30           4.7         3.2          1.6         0.2     setosa\n31           4.8         3.1          1.6         0.2     setosa\n32           5.4         3.4          1.5         0.4     setosa\n33           5.2         4.1          1.5         0.1     setosa\n34           5.5         4.2          1.4         0.2     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.0         3.2          1.2         0.2     setosa\n37           5.5         3.5          1.3         0.2     setosa\n38           4.9         3.6          1.4         0.1     setosa\n39           4.4         3.0          1.3         0.2     setosa\n40           5.1         3.4          1.5         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n42           4.5         2.3          1.3         0.3     setosa\n43           4.4         3.2          1.3         0.2     setosa\n44           5.0         3.5          1.6         0.6     setosa\n45           5.1         3.8          1.9         0.4     setosa\n46           4.8         3.0          1.4         0.3     setosa\n47           5.1         3.8          1.6         0.2     setosa\n48           4.6         3.2          1.4         0.2     setosa\n49           5.3         3.7          1.5         0.2     setosa\n50           5.0         3.3          1.4         0.2     setosa\n51           7.0         3.2          4.7         1.4 versicolor\n52           6.4         3.2          4.5         1.5 versicolor\n53           6.9         3.1          4.9         1.5 versicolor\n54           5.5         2.3          4.0         1.3 versicolor\n55           6.5         2.8          4.6         1.5 versicolor\n56           5.7         2.8          4.5         1.3 versicolor\n57           6.3         3.3          4.7         1.6 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n59           6.6         2.9          4.6         1.3 versicolor\n60           5.2         2.7          3.9         1.4 versicolor\n61           5.0         2.0          3.5         1.0 versicolor\n62           5.9         3.0          4.2         1.5 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.9          4.7         1.4 versicolor\n65           5.6         2.9          3.6         1.3 versicolor\n66           6.7         3.1          4.4         1.4 versicolor\n67           5.6         3.0          4.5         1.5 versicolor\n68           5.8         2.7          4.1         1.0 versicolor\n69           6.2         2.2          4.5         1.5 versicolor\n70           5.6         2.5          3.9         1.1 versicolor\n71           5.9         3.2          4.8         1.8 versicolor\n72           6.1         2.8          4.0         1.3 versicolor\n73           6.3         2.5          4.9         1.5 versicolor\n74           6.1         2.8          4.7         1.2 versicolor\n75           6.4         2.9          4.3         1.3 versicolor\n76           6.6         3.0          4.4         1.4 versicolor\n77           6.8         2.8          4.8         1.4 versicolor\n78           6.7         3.0          5.0         1.7 versicolor\n79           6.0         2.9          4.5         1.5 versicolor\n80           5.7         2.6          3.5         1.0 versicolor\n81           5.5         2.4          3.8         1.1 versicolor\n82           5.5         2.4          3.7         1.0 versicolor\n83           5.8         2.7          3.9         1.2 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           6.7         3.1          4.7         1.5 versicolor\n88           6.3         2.3          4.4         1.3 versicolor\n89           5.6         3.0          4.1         1.3 versicolor\n90           5.5         2.5          4.0         1.3 versicolor\n91           5.5         2.6          4.4         1.2 versicolor\n92           6.1         3.0          4.6         1.4 versicolor\n93           5.8         2.6          4.0         1.2 versicolor\n94           5.0         2.3          3.3         1.0 versicolor\n95           5.6         2.7          4.2         1.3 versicolor\n96           5.7         3.0          4.2         1.2 versicolor\n97           5.7         2.9          4.2         1.3 versicolor\n98           6.2         2.9          4.3         1.3 versicolor\n99           5.1         2.5          3.0         1.1 versicolor\n100          5.7         2.8          4.1         1.3 versicolor\n101          6.3         3.3          6.0         2.5  virginica\n102          5.8         2.7          5.1         1.9  virginica\n103          7.1         3.0          5.9         2.1  virginica\n104          6.3         2.9          5.6         1.8  virginica\n105          6.5         3.0          5.8         2.2  virginica\n106          7.6         3.0          6.6         2.1  virginica\n107          4.9         2.5          4.5         1.7  virginica\n108          7.3         2.9          6.3         1.8  virginica\n109          6.7         2.5          5.8         1.8  virginica\n110          7.2         3.6          6.1         2.5  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          6.4         2.7          5.3         1.9  virginica\n113          6.8         3.0          5.5         2.1  virginica\n114          5.7         2.5          5.0         2.0  virginica\n115          5.8         2.8          5.1         2.4  virginica\n116          6.4         3.2          5.3         2.3  virginica\n117          6.5         3.0          5.5         1.8  virginica\n118          7.7         3.8          6.7         2.2  virginica\n119          7.7         2.6          6.9         2.3  virginica\n120          6.0         2.2          5.0         1.5  virginica\n121          6.9         3.2          5.7         2.3  virginica\n122          5.6         2.8          4.9         2.0  virginica\n123          7.7         2.8          6.7         2.0  virginica\n124          6.3         2.7          4.9         1.8  virginica\n125          6.7         3.3          5.7         2.1  virginica\n126          7.2         3.2          6.0         1.8  virginica\n127          6.2         2.8          4.8         1.8  virginica\n128          6.1         3.0          4.9         1.8  virginica\n129          6.4         2.8          5.6         2.1  virginica\n130          7.2         3.0          5.8         1.6  virginica\n131          7.4         2.8          6.1         1.9  virginica\n132          7.9         3.8          6.4         2.0  virginica\n133          6.4         2.8          5.6         2.2  virginica\n134          6.3         2.8          5.1         1.5  virginica\n135          6.1         2.6          5.6         1.4  virginica\n136          7.7         3.0          6.1         2.3  virginica\n137          6.3         3.4          5.6         2.4  virginica\n138          6.4         3.1          5.5         1.8  virginica\n139          6.0         3.0          4.8         1.8  virginica\n140          6.9         3.1          5.4         2.1  virginica\n141          6.7         3.1          5.6         2.4  virginica\n142          6.9         3.1          5.1         2.3  virginica\n143          5.8         2.7          5.1         1.9  virginica\n144          6.8         3.2          5.9         2.3  virginica\n145          6.7         3.3          5.7         2.5  virginica\n146          6.7         3.0          5.2         2.3  virginica\n147          6.3         2.5          5.0         1.9  virginica\n148          6.5         3.0          5.2         2.0  virginica\n149          6.2         3.4          5.4         2.3  virginica\n150          5.9         3.0          5.1         1.8  virginica\n\n\n\n# Create a .csv file to import\nwrite_csv(iris, \"iris.csv\")\n\n\n# Try read.csv\nd.f &lt;- read.csv(\"iris.csv\")\n\nstr(d.f)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : chr  \"setosa\" \"setosa\" \"setosa\" \"setosa\" ...\n\n\n\n# Try read_csv\nread_csv(\"iris.csv\")\n\nRows: 150 Columns: 5\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (1): Species\ndbl (4): Sepal.Length, Sepal.Width, Petal.Length, Petal.Width\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 150 Ã— 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# â€¦ with 140 more rows\n\n# Set col_type as you import data -- allows you to define level order too\nd_f &lt;- read_csv(\"iris.csv\",\n                col_types = list(Species = col_factor(c(\"versicolor\",\n                                                        \"setosa\", \n                                                        \"virginica\"))))\nd_f\n\n# A tibble: 150 Ã— 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# â€¦ with 140 more rows\n\nstr(d_f)\n\nspc_tbl_ [150 Ã— 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Sepal.Length: num [1:150] 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num [1:150] 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num [1:150] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num [1:150] 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"versicolor\",\"setosa\",..: 2 2 2 2 2 2 2 2 2 2 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Sepal.Length = col_double(),\n  ..   Sepal.Width = col_double(),\n  ..   Petal.Length = col_double(),\n  ..   Petal.Width = col_double(),\n  ..   Species = col_factor(levels = c(\"versicolor\", \"setosa\", \"virginica\"), ordered = FALSE, include_na = FALSE)\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nglimpse(d_f)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.â€¦\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.â€¦\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.â€¦\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.â€¦\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, sâ€¦"
  },
  {
    "objectID": "repro.html#practical-reproducibility",
    "href": "repro.html#practical-reproducibility",
    "title": "1Â  Reproducibility",
    "section": "1.1 Practical reproducibility",
    "text": "1.1 Practical reproducibility\nMuch of the advice on computational reproducibility is somewhat abstract6. That is, in part, the nature of the beast. Each project represents its own unique challenges. But it is also because the advice is often made for a broad range of projects in all sorts of different programming languages on everything from model simulations to genome assembly, all the way to creating programmatic tools for others. In contrast, this workshop will focus on a narrower set of tasks related to statistical programming in R7. In other words, the type of programming where you have some raw data generated elsewhere (e.g., enzyme activity or species abundance data) that you are going to preform some sort of analysis on it (e.g., normalization and a significance test), and then make figures.\n\n\n\n\n\n\nTL;DR - Practical tips for computational reproducibility 8\n\n\n\n\n\n\nR & RStudio specific tips\n\nUse the â€œProjectsâ€ feature in R.\nDo not save .RData on exit, and do not restore .RData on open. You can change this default behavior in RStudio in the Global Options.\nUse the built in version control tools. There are easy ways to interact with Git and GitHub with the RStudio IDE.\nUse the tidyverse packages! See the tidyverse chapter of this workshop.\n\n\n\nRepository tips\n\nUse a consistent directory structure. You can save this structure as a template and begin from there, rather than build each project from scratch.\nUse sub-directories. Favor a highly nested directory structure, over a directory with dozens of files with long and repetative names. If you find yourself making a bunch of files with the same prefix, that probably means that they should all be in their own directory.\nAdd a number prefix to your scripts (and possible directories), so it is clear which order they must be run 01_normalize_data.R.\nYou can have directory structures that mirror each other â€“ this makes it easier to know where the relevant info is saved. For example, the data from data/raw/pheno/2023-07-04_data.csv could be analyzed in a script in src/pheno/01_anova.R, and the output could be saved in output/pheno/anova_results.rds and the corresponding figure saved in output/figs/pheno/boxplot.pdf.\n\n\n\nScript writing\n\nEvery script should be able to run without errors from top to bottom (i.e., in R, source(file_name.R) or clicking the source button in RStudio should always work when you save a file).\nWhen you are using multiple packages with overlapping function names, the order that you load the libraries can matter. If you have this make sure you can\nThe order of each script should make sense and be consistent (e.g., description, load packages, load data, manipulate data, save data). If you find yourself violating this rule. Loading packages later in a script or multiple saves of data intermediates within a file, it may make sense to split up the script. See next tip.\nFavor small scripts that are focused on a single task, over big scripts that do many things.\nYou should be able to run every script with a completely clean global environment.\nDevelop a consistent coding style (e.g., snake_case, indents, comments)\nYou should be able to clone the parent directory of the project and run the scripts â€“ without any alteration, on any machine.\n\n\n\nData handling\n\nAvoid any manual manipulation of data (i.e., donâ€™t mess around copy-and-pasting or editing raw data, change it reproducibly with code).\nSave output automatically by writing it into the code (e.g., saveRDS(), readr::write_csv(), ggsave()).\nSave intermediate data. If you are starting with a big data set, it is nice save that intermediate so a collaborator (or you in the future, or some random researcher on the internet), can re-do an intermediate step rather than begin from raw data. If they want to know how different you results would look normalized your data in a different way\n\n\n\nRandom pet-peeves\n\nDonâ€™t copy and paste output into R scripts. If you need to save an output table, then write it to a csv or save it as an .rds file. If you need quick access to some intermediary info then use RMarkdown or Quarto to create .html reports.\nDonâ€™t include anything that isnâ€™t necessary in your code.\nOpt for long and explicit variable or function names over short and implicit names.\nUse a driver script that automates the entire workflow in a single script call.\nDo not save install.packages(\"some_package\") in your script â€“ even if it is commented out. If in the future, you happen to have a new machine that doesnâ€™t have some_package installed, you will remember how to install it. This is something that can just be run directly in the console, when necessary, and does not need to be saved in the script.\n\n\n\nVersion control\n\nCommit and push relatively often. This makes your commit history a useful record the changes you have made. It also makes it less likely that you will run into issues pushing and pulling. Or at least less traumatic if you do run into issues.\nAlways pull first â€“ just in case your local state is a little behind.\nDonâ€™t commit large files (e.g., raw data or large pdf figures) to version control. The software usually has limits."
  },
  {
    "objectID": "repro.html#version-control-1",
    "href": "repro.html#version-control-1",
    "title": "1Â  Reproducibility",
    "section": "1.6 Version control",
    "text": "1.6 Version control\nIt is beyond the scope of this workshop, but one important way people ensure the reproducibility of their projects is to utilize version control. In short, version control is a useful way to make sure that as you edit and add to large projects over time you donâ€™t loose/change any of the bits that make it work. For example, if you were to accidentally break a script, you could restore to a previous working version of that file, and then begin again. There are several software designed to do this, but the most popular in the data science world is Git and GitHub.\nThese tools can seem intimidating at first â€“ especially because they typically are interfaced with in the command line. But if it makes you more comfortable, you can use the point-and-click approach to git within RStudio itself or a desktop clients (e.g., GitHub Desktop). Here is a very useful tutorial on how to use Git and GitHub within RStudio.\n\n\n\n\nNational Academies of Sciences, Engineering, Medicine, Policy, Global Affairs, Committee on Science, Engineering, Medicine, Public Policy, Board on Research Data, et al. 2019. Understanding Reproducibility and Replicability. National Academies Press (US).\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, and Eivind Hovig. 2013. â€œTen Simple Rules for Reproducible Computational Research.â€ PLoS Comput. Biol. 9 (10): e1003285."
  },
  {
    "objectID": "repro.html#the",
    "href": "repro.html#the",
    "title": "1Â  Reproducibility",
    "section": "1.2 The",
    "text": "1.2 The\n\nR & RStudio specific tips\n\nUse the â€œProjectsâ€ feature in R.\nDo not save .RData on exit, and do not restore .RData on open. You can change this default behavior in RStudio in the Global Options.\n\n\n\nRepository tips\n\nUse a consistent directory structure. You can save this structure as a template and begin from there, rather than build each project from scratch.\nUse sub-directories. Favor a highly nested directory structure over directories with dozens of files with long names. If you find yourself making a bunch of files with the same prefix, that probably means that they should all be in their own directory.\nAdd a number prefix to your scripts (and possible directories), so it is clear which order they must be run 01_normalize_data.R.\n\n\n\nScript writing\n\nEvery script should be able to run without errors from top to bottom (i.e., in R, source(file_name.R) or clicking the source button in RStudio should always work when you save a file).\nWhen you are using multiple packages with overlapping function names, the order that you load the libraries can matter. If you have this make sure you can\nThe order of each script should make sense and be consistent (e.g., description, load packages, load data, manipulate data, save data). If you find yourself violating this rule. Loading packages later in a script or multiple saves of data intermediates within a file, it may make sense to split up the script. See next tip.\nFavor small scripts that are focused on a single task, over big scripts that do many things.\nYou should be able to run every script with a completely clean global environment.\nDevelop a consistent coding style (e.g., snake_case, indents, comments)\nYou should be able to clone the parent directory of the project and run the scripts â€“ without any alteration, on any machine.\n\n\n\nData handling\n\nAvoid manual manipulation of data (i.e., donâ€™t mess around copy-and-pasting or editing raw data, change it reproducibly with code).\nSave output automatically by writing it into the code (e.g., saveRDS(), readr::write_csv(), ggsave()).\nSave intermediate data as a file.\n\n\n\nRandom pet-peeves\n\nDonâ€™t copy and paste output into R scripts. If you need to save an output table, then write it to a csv or save it as an .rds file. If you need quick access to some intermediary info then use RMarkdown or Quarto to create .html reports.\nDonâ€™t include anything that isnâ€™t necessary in your code.\nOpt for long and explicit variable or function names over short and implicit names.\nUse a driver script that automates the entire workflow in a single script call.\n\n\n\nVersion control\n\nIf you are using version control, always pull first.\nDonâ€™t commit large files (e.g., raw data or large pdf figures) to version control. They usually have limits.\nCommit and push relatively often. This makes your commit history a useful record the changes you have made, and also makes it less likely that you will run into issues pushing and pulling.\n\n:::"
  },
  {
    "objectID": "repro.html#ten-simple-rules-for-reproducible-computational-research-sandve2013-cq.",
    "href": "repro.html#ten-simple-rules-for-reproducible-computational-research-sandve2013-cq.",
    "title": "1Â  Reproducibility",
    "section": "1.2 Ten simple rules for reproducible computational research (Sandve et al. 2013).",
    "text": "1.2 Ten simple rules for reproducible computational research (Sandve et al. 2013).\n\nFor every result, keep track of how it was produced\nAvoid manual data manipulation steps\nArchive the exact versions of all external programs used\nVersion control all custom scripts\nRecord all intermediate results, when possible in standardized formats\nFor analyses that include randomness, note underlying random seeds\nAlways store raw Data behind plots\nGenerate hierarchical analysis output, allowing layers of increasing detail to be inspected\nConnect textual statements to underlying results\nProvide public access to scripts, runs, and results"
  },
  {
    "objectID": "repro.html#projects-in-rstudio",
    "href": "repro.html#projects-in-rstudio",
    "title": "1Â  Reproducibility",
    "section": "1.4 Projects in RStudio",
    "text": "1.4 Projects in RStudio\nProjects are your friend. Jenny Bryan, a developer at RStudio, has an impassioned blog post on why you should embrace a project-oriented workflow. You should probably read her post in full, because if you donâ€™t listen, she is threatening to set your computer on fire ğŸ”¥. But seriously, you should read it.\nAs a way of quickly summarizing one of her points: you should make sure that your final product (i.e., your script) is completely free of things that are specific to your own personal habits. For example, do you have something similar to setwd(\"/Users/tsoleary/R/quest_workshop_2023\") at the start of your script? Or in some other way, are you using absolute paths? If you do, then for a certainty if someone else wants to run your code, they will have to edit it to make sure they donâ€™t immediately run into an error. This means that right off the bat, your code is not reproducibility-friendly. As a remedy, she suggests using projects and the here package discussed below.\n\nhere package\nThe here package is a great way to make sure that your code can be run easily on someone elseâ€™s machine. Jenny Bryan has another post dedicated specifically to the here package: read it here.\nWhat I like about it is that it allows you to easily separate out the file and the directory that you want to place it in â€“ see below:\n\n# Load data\ndat &lt;- read_csv(here::here(\"data/raw/counts.csv\"))\n\n\n\n\n\n\n\nhere::here\n\n\n\nAs youâ€™ll notice above rather than load the here package with library(here) and then use the here() function, I use the package::function_name notation to call the here function without attaching the whole here package. The added bonus is that it is kinda fun to say Here, Here! ğŸº\n\n\nI find the here package very useful for working with RMarkdown documents. By default, RMarkdown documents often use what ever directory that document is in as its root directory, so then all relative paths are in relation to where ever that RMarkdown document happens to be. But the here package allows you to continue to use the project root for your relative paths!\n\n\n\n\n\n\nTip\n\n\n\nProjects in RStudio allows for easy integration with Version Control! Check out the short SectionÂ 1.7 on Version Control."
  },
  {
    "objectID": "repro.html#sec-vc",
    "href": "repro.html#sec-vc",
    "title": "1Â  Reproducibility",
    "section": "1.7 Version control",
    "text": "1.7 Version control\nThe details of the software are beyond the scope of this workshop, but one important way people ensure the reproducibility of their projects is to utilize Version Control. In short, Version Control is a useful way to make sure that as you edit and add to large projects over time you donâ€™t lose or change any of the bits that make it work. For example, if you were to accidentally break a script, you could restore to a previous working version of that file, and then begin again. There are several software designed to do this, but the most popular in the data science world is Git and GitHub.\nThese tools can seem intimidating at first â€“ especially because they typically are interfaced with in the command line. But if it makes you more comfortable, you can use the point-and-click approach to git within RStudio itself or a desktop clients (e.g., GitHub Desktop). Here is a very useful tutorial on how to use Git and GitHub within RStudio.\n\n\n\n\nGoodman, Steven N, Daniele Fanelli, and John P A Ioannidis. 2016. â€œWhat Does Research Reproducibility Mean?â€ Sci. Transl. Med. 8 (341): 341ps12.\n\n\nNational Academies of Sciences, Engineering, Medicine, Policy, Global Affairs, Committee on Science, Engineering, Medicine, Public Policy, Board on Research Data, et al. 2019. Understanding Reproducibility and Replicability. National Academies Press (US).\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, and Eivind Hovig. 2013. â€œTen Simple Rules for Reproducible Computational Research.â€ PLoS Comput. Biol. 9 (10): e1003285."
  },
  {
    "objectID": "repro.html#scripting",
    "href": "repro.html#scripting",
    "title": "1Â  Reproducibility",
    "section": "1.5 Scripting",
    "text": "1.5 Scripting\nI believe in short scripts that do one thing, rather then a huge unruly script that does everything. This helps adhere to Rule 5: Record all intermediate results, when possible in standardized formats & Rule 8: Generate hierarchical analysis output, allowing layers of increasing detail to be inspected. Creating small scripts with intermediate results mean that you in the future or a reviewer can easily jump into the analysis mid-way and explore the data.\nImagine you have an RNA-sequencing project. The journal will require you to provide the raw sequence files. But you should also provide your audience with the raw counts file, as well as a .rds file that contains the full DESeq2 object. This allows them to easily explore the data for themselves, rather than start from step zero. Then they could easily begin again at the model analysis step, without having to repeat the mapping steps.\n\n\n\n\n\n\nDriver scripts\n\n\n\nIt can be useful to create a top-level script that executes all the code in the project, generating all plots and results. This both ensures that your results are reproducible and that if you need to change one small thing, like your input data, you can easily regenerate all your results.\n\n\n\n\n\nsrc/driver.R\n\n# ------------------------------------------------------------------------------\n# Simple driver script to execute all scripts\n# TS O'Leary\n# ------------------------------------------------------------------------------\n\n# Source all files\nsource(\"src/analysis_1/00_file.R\")\nsource(\"src/analysis_1/01_file.R\")\n..."
  },
  {
    "objectID": "repro.html#snippets",
    "href": "repro.html#snippets",
    "title": "1Â  Reproducibility",
    "section": "1.7 Snippets",
    "text": "1.7 Snippets\n\nsnippet mhead_snip\n    # ------------------------------------------------------------------------------\n    # ${1:script_description}\n    # TS O'Leary\n    # ------------------------------------------------------------------------------\n\n    # Load libraries\n    library(tidyverse)\n\n    # Load data\n    dat &lt;- read_csv(\"data/raw/starwars.csv\")\n    \n    # Analyze data\n    dat &lt;- dat %&gt;%\n    group_by(Species) %&gt;%\n        count()\n    \n    # Save data\n    saveRDS(\"data/processed/count.rds\")"
  },
  {
    "objectID": "repro.html#scratch-code",
    "href": "repro.html#scratch-code",
    "title": "1Â  Reproducibility",
    "section": "1.8 Scratch code",
    "text": "1.8 Scratch code\nI often find that I write code that is not used in the final analysis. You may find yourself doing the same. It is sometimes a random exploratory figure that doesnâ€™t end up telling you much, or maybe you normalized some data in the wrong way, or used an inappropriate type of statistical model. But in each case, you have spent some valuable amount of time writing that code, and so you are reluctant to remove it from you script. So you just comment it out â€“ or worse, just leave it hanging there in the script. After all, it might be useful down the line, somehow, somewhere. I sympathize with that, but I think it is worth removing all unnecessary code. It will help you in the future when you donâ€™t remember what you did, and donâ€™t know if that bit of code is important.\n\n\n\n\n\n\nA tip for removing all unecessary or redundant code\n\n\n\nIt can be hard to strip your code down to only the necessary bits, but it is worth it for the sake of clarity and reproducibility. I sometimes create a scratch.R file or a scratch/ directory where I copy and paste bits of code that I am reluctant to throw away. It helps clean up the final code and makes me feel a little less like I wasted my time."
  },
  {
    "objectID": "repro.html#ten-simple-rules",
    "href": "repro.html#ten-simple-rules",
    "title": "1Â  Reproducibility",
    "section": "1.2 Ten simple rules",
    "text": "1.2 Ten simple rules\nThe tips outlined above are a useful and specific starting point9. But rather than rely solely on my eccentricities, letâ€™s instead adopt these simple rules from Sandve et al. (2013). Over the course of this workshop, we will look at some specific coding practices and think about how they may violate, or adhere to, one (or more) of these rules. The additional benefit of adpoting these rules is that they are easy enough to apply to other types of projects. It is worth reading in full.\n\n\n\n\n\n\nTen simple rules for reproducible computational research\n\n\n\n\nFor every result, keep track of how it was produced\nAvoid manual data manipulation steps\nArchive the exact versions of all external programs used\nVersion control all custom scripts\nRecord all intermediate results, when possible in standardized formats\nFor analyses that include randomness, note underlying random seeds\nAlways store raw data behind plots\nGenerate hierarchical analysis output, allowing layers of increasing detail to be inspected\nConnect textual statements to underlying results\nProvide public access to scripts, runs, and results"
  },
  {
    "objectID": "repro.html#opening-in-rstudio",
    "href": "repro.html#opening-in-rstudio",
    "title": "1Â  Reproducibility",
    "section": "1.3 Opening in RStudio",
    "text": "1.3 Opening in RStudio\nOkay, letâ€™s begin by opening up RStudio10. Do you have objects already in your Global Environment? Is the console full of code you ran last time? Or do you always keep RStudio running, because you are worried about loosing the results you finally managed to get, and you need to do more stuff later?\nI know people that do great work in R and live their lives like this â€“ but it kinda makes me sweat. How do you know what is real? What if those objects were created under some other conditions and you have since edited your script? How many packages do you have loaded? What are they?11 It stresses me out, in part because you are violating Rule 1 â€“ you donâ€™t necessarily have a good track record of how that object was produced. It could me something that you ran into the console long ago and you have since changed your script. You want your source of truth12 to be the script. In other words, the list of specfic commands that take you from raw data to your results. Zombie objects in the Global Environment are not your friend.\nIt is best practice to start with a blank slate every time you open RStudio. This will force you to rely solely on the code infront of you. Rather than something that may or may not be what you remember it to be. It also mimics the environment of someone else, sitting down at their own machine, trying to replicate your results â€“ getting closer to ensuring reproducibility.\n\n\n\n\n\n\nTip\n\n\n\nThere is actually an easy way to set up a blank slate as RStudioâ€™s default behavior. Just execute usethis::use_blank_slate() in the console and it will ensure that the Global Options of RStudio are configured in such a way that you have a blank slate each time you open R. Alternatively, you can manually adjust the Global Options as explained here."
  },
  {
    "objectID": "repro.html#scripts",
    "href": "repro.html#scripts",
    "title": "1Â  Reproducibility",
    "section": "1.6 Scripts",
    "text": "1.6 Scripts\nI believe in short scripts that do one thing, rather then a huge unruly script that does everything. This helps adhere to Rule 5: Record all intermediate results, when possible in standardized formats & Rule 8: Generate hierarchical analysis output, allowing layers of increasing detail to be inspected. Creating small scripts with intermediate results mean that you in the future or a reviewer can easily jump into the analysis mid-way and explore the data.\nIf you read Jenny Bryanâ€™s blog post on a project-oriented workflow referenced earlier, you likely ran across this advice:\n\nWhat about objects that take a long time to create? Isolate that bit in its own script and write the precious object to file with saveRDS(my_precious, here(\"results\", \"my_precious.rds\")). Now you can develop scripts to do downstream work that reload the precious object via my_precious &lt;- readRDS(here(\"results\", \"my_precious.rds\")). It is a good idea to break data analysis into logical, isolated pieces anyway.\n\nThis is my favorite way to code.\nImagine you have an RNA-sequencing project. The journal will require you to provide the raw sequence files. But you should also provide your audience with the raw counts file, as well as a .rds file that contains the full DESeq2 object. This allows them to easily explore the data for themselves, rather than start from step zero. Then they could easily begin again at the model analysis step, without having to repeat the mapping steps.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\n\n1.6.1 Driver scripts\nIf you now have a bunch of small scripts that do small tasks, it can be useful to create a top-level script that executes all the code in the project, generating all plots and results. This both ensures that your results are reproducible and that if you need to change one small thing, like your input data, you can easily regenerate all your results.\n\n\n\nsrc/driver.R\n\n# ------------------------------------------------------------------------------\n# Simple example driver script to execute all scripts\n# TS O'Leary\n# ------------------------------------------------------------------------------\n\n# Source all files\nsource(here::here(\"src/analysis_1/00_normalize.R\"))\nsource(here::here(\"src/analysis_1/01_analyze.R\"))\nsource(here::here(\"src/analysis_1/02_model.R\"))\nsource(here::here(\"src/analysis_1/03_integrate.R\"))\n\n\nOne thing that I have been experimenting with is using\n\n\n1.6.2 Snippets\nYou should use the available tools as much as you can to aid your workflow.\nI use snippets to create my script templates.\n\nsnippet mhead_snip\n    # ------------------------------------------------------------------------------\n    # ${1:script_description}\n    # TS O'Leary\n    # ------------------------------------------------------------------------------\n\n    # Load libraries\n    library(tidyverse)\n\n    # Load data\n    dat &lt;- read_csv(here::here(\"data/raw/starwars.csv\"))\n    \n    # Analyze data\n    dat &lt;- dat %&gt;%\n    group_by(Species) %&gt;%\n        count()\n    \n    # Save data\n    saveRDS(here::here(\"data/processed/count.rds\"))\n\nThis template ensures that I do several things:\n\nAdd a top level description to each file. I usually try to keep it to one sentance that says what the script is doing. If you have split up your scripts into bite sized chunks, this should be easy.\nGives a place to load libraries and data at the top of the script.\nReminds me to save the output at the end of the script.\n\n\n\n1.6.3 Quick tools\n\n\n1.6.4 Scratch code\nI often find that I write code that is not used in the final analysis. You may find yourself doing the same. It is sometimes a random exploratory figure that doesnâ€™t end up telling you much, or maybe you normalized some data in the wrong way, or used an inappropriate type of statistical model. But in each case, you have spent some valuable amount of time writing that code, and so you are reluctant to remove it from you script. So you just comment it out â€“ or worse, just leave it hanging there in the script. After all, it might be useful down the line, somehow, somewhere. I sympathize with that, but I think it is worth removing all unnecessary code. It will help you in the future when you donâ€™t remember what you did, and donâ€™t know if that bit of code is important.\n\n\n\n\n\n\nA tip for removing all unecessary or redundant code\n\n\n\nIt can be hard to strip your code down to only the necessary bits, but it is worth it for the sake of clarity and reproducibility. I sometimes create a scratch.R file or a scratch/ directory where I copy and paste bits of code that I am reluctant to throw away. It helps clean up the final code and makes me feel a little less like I wasted my time."
  },
  {
    "objectID": "repro.html#quick-tools",
    "href": "repro.html#quick-tools",
    "title": "1Â  Reproducibility",
    "section": "1.9 Quick tools",
    "text": "1.9 Quick tools"
  },
  {
    "objectID": "data_viz.html",
    "href": "data_viz.html",
    "title": "3Â  Data visualization",
    "section": "",
    "text": "There are several great resources out there on the world wide web for learning how to do create figures in R. They do a thorough job of introducing the basics. The simple mechanics of moving from data to figure. In particular, I recommend, the Data Visualization Chapter of R for Data Science. It is a great place to get started with a narrative introduction to ggplot. As you make more ambitious figures, ggplot2: Elegant Graphics for Data Analysis will provide you with even more detail. Similarly, the R Graphics Cookbook provides useful solutions to common problems (e.g. changing the order of items on a categorical axis).\nThis workshop is not intended to review that kind of book"
  },
  {
    "objectID": "data_viz.html#choosing-a-type-of-visualization",
    "href": "data_viz.html#choosing-a-type-of-visualization",
    "title": "3Â  Data visualization",
    "section": "3.3 Choosing a type of visualization",
    "text": "3.3 Choosing a type of visualization\nOkay this is a little bit of a warm up\nChoosing a type of visualization depends entirely on the sorts of questions you are trying to ask. So for now, letâ€™s pick a few different questions. I donâ€™t know anything about these penguins. So here are some simple questions that I have brainstormed:\n\nAre different species of penguins different weights?\nAre penguins from different islands different weights?\n\n\nWe will stick with the first question for now. But it is worth trying the others.\nI really hate the default theme for ggplot. So rather than look at it. Letâ€™s just set something that is a little easier on the eyes at the beginning. This command below will set cowplot::theme_minimal_grid() as the default theme for all plots going forward.\n\n# Set a nicer looking theme as a place holder\ntheme_set(cowplot::theme_minimal_grid())\n\n\nBox plotViolin plotStrip plotBeeswarmHistogramDensity plot\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_boxplot(\n    aes(x = species,\n        y = body_mass_g))\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_violin(\n    aes(x = species,\n        y = body_mass_g))\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_jitter(\n    aes(x = species,\n        y = body_mass_g),\n    width = 0.1)\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  ggbeeswarm::geom_beeswarm(\n    corral.width = 2.0,\n    aes(x = species,\n        y = body_mass_g)) \n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_histogram(\n    aes(x = body_mass_g),\n    color = \"grey20\",\n    fill = \"grey80\",\n    bins = 30) +\n  facet_wrap(~species,\n             nrow = 3)\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_density(\n    aes(x = body_mass_g,\n        color = species,\n        fill = species),\n    alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice the advantages and disadvantages of the different styles.\n\n\n\nSome have more information than others. If you had to pick one? Which would you pick?\n\n\nFortunately we donâ€™t have to pick."
  },
  {
    "objectID": "data_viz.html#creating-the-axes",
    "href": "data_viz.html#creating-the-axes",
    "title": "3Â  Data visualization",
    "section": "3.5 Creating the axes",
    "text": "3.5 Creating the axes\n\npenguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_boxplot(\n    width = 0.6,\n    outlier.shape = NA\n    ) + \n  ggbeeswarm::geom_beeswarm(\n    shape = 21,\n    width = 0.2\n    ) +\n  scale_y_continuous(\n    name = \"Body mass (g)\",\n    limits = c(0, 7000)\n    ) +\n  scale_x_discrete(\n   name = element_blank()\n  )"
  },
  {
    "objectID": "data_viz.html#choosing-a-theme",
    "href": "data_viz.html#choosing-a-theme",
    "title": "3Â  Data visualization",
    "section": "3.6 Choosing a theme",
    "text": "3.6 Choosing a theme\n\npenguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_boxplot(\n    width = 0.6,\n    outlier.shape = NA\n    ) + \n  ggbeeswarm::geom_beeswarm(\n    shape = 21,\n    width = 0.2\n    ) +\n  scale_y_continuous(\n    name = \"Body mass (g)\",\n    limits = c(0, 7000)\n    ) +\n  scale_x_discrete(\n   name = element_blank()\n   ) +\n  cowplot::theme_minimal_hgrid()\n\n\n\n\nOh no! Look at that brual\n\npenguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_boxplot(\n    width = 0.6,\n    outlier.shape = NA\n    ) + \n  ggbeeswarm::geom_beeswarm(\n    shape = 21,\n    width = 0.2\n    ) +\n  scale_y_continuous(\n    name = \"Body mass (g)\",\n    limits = c(0, 7000),\n    expand = c(0, 0.5)\n    ) +\n  scale_x_discrete(\n   name = element_blank()\n   ) +\n  cowplot::theme_minimal_hgrid()"
  },
  {
    "objectID": "data_viz.html#footnotes",
    "href": "data_viz.html#footnotes",
    "title": "3Â  Data visualization",
    "section": "",
    "text": "Shhh! Donâ€™t tell that to Chapter 1 of this workshop.â†©ï¸"
  },
  {
    "objectID": "data_viz.html#explore-the-data",
    "href": "data_viz.html#explore-the-data",
    "title": "3Â  Data visualization",
    "section": "3.2 Explore the data",
    "text": "3.2 Explore the data\n\nMeet the Palmer penguins\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\n\n\n\nTest\n\n\n\n\n\n\n\n# Load libraries\nlibrary(tidyverse)\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.0     âœ” readr     2.1.4\nâœ” forcats   1.0.0     âœ” stringr   1.5.0\nâœ” ggplot2   3.4.1     âœ” tibble    3.1.8\nâœ” lubridate 1.9.2     âœ” tidyr     1.3.0\nâœ” purrr     1.0.1     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(palmerpenguins)\n\n\n# Take a peak at the data\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelâ€¦\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerseâ€¦\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, â€¦\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, â€¦\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186â€¦\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, â€¦\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, maleâ€¦\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007â€¦"
  },
  {
    "objectID": "data_viz.html#limits",
    "href": "data_viz.html#limits",
    "title": "3Â  Data visualization",
    "section": "3.4 Limits",
    "text": "3.4 Limits\n\npenguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_violin(width = 0.8) + \n  geom_boxplot(width = 0.2) +\n  scale_y_continuous(\n    limits = c(0, 7000)\n  )\n\n\n\n\n\npenguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_boxplot(\n    width = 0.6,\n    outlier.shape = NA\n    ) + \n  ggbeeswarm::geom_beeswarm(\n    shape = 21,\n    width = 0.2\n    ) +\n  scale_y_continuous(\n    limits = c(0, 7000)\n  )"
  },
  {
    "objectID": "data_viz.html#the-small-details",
    "href": "data_viz.html#the-small-details",
    "title": "3Â  Data visualization",
    "section": "3.7 The small details",
    "text": "3.7 The small details\n\npenguins |&gt;  \n  ggplot(\n    aes(x = body_mass_g)\n    ) +\n  geom_histogram(\n    color = \"grey20\",\n    fill = \"grey80\"\n    ) +\n  facet_grid(rows = vars(island),\n             cols = vars(species)) +\n  cowplot::theme_minimal_hgrid() +\n  theme(strip.background = element_rect(fill = \"grey90\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`)."
  },
  {
    "objectID": "data_viz.html#gallery-of-visualizations",
    "href": "data_viz.html#gallery-of-visualizations",
    "title": "3Â  Data visualization",
    "section": "3.1 Gallery of visualizations",
    "text": "3.1 Gallery of visualizations"
  }
]