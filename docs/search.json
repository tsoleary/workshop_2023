[
  {
    "objectID": "repro.html",
    "href": "repro.html",
    "title": "Reproducibility",
    "section": "",
    "text": "Reproducibility is an integral part of science. Its core idea is simple enough, even if it covers a broad set of ideas. To ensure we are on the same page, I will loosely define1 terms, before moving on some practical principles of computational reproducibility.\n\nResults reproducibility â€“ if you do the same thing, you should get the same results. This is essence of the scientific method. If you are unable to reproduce the results, you may not have a full understanding of the underlying causes.\nInferential reproducibility â€“ reliably draw the same types of conclusions from different sets of experiments2.\nMethods reproducibility â€“ description of the methods are sufficiently detailed, complete, and accurate enough so that the experiment may be replicated in full.\n\nThis workshop is focused on a narrow set of methods reproducibility, computational reproducibility, for which, I am adopting the formal definition: â€œobtaining consistent results using the same input data; computational steps, methods, and code; and conditions of analysisâ€ (National Academies of Sciences, Engineering et al. 2019). That seems self-evident, so for a practical, working definition, consider asking yourself the following questions.\n\n\n\n\n\n\nQuestions to ask yourself\n\n\n\n\nWill I be able to re-run this code, on a new computer, without alteration, and obtain identical results?\nOne year from now, will I be able to understand what I did? How about 3 years from now?\nWill my collaborators (or potential unknown reviewers) be able to clone the project directory and run the code on their local machines without issue and without asking for any clarifications?\n\n\n\nIf the answer to any of those questions above is not yes, then you probably have some room for improvement in your computational reproducibility. That is totally fine â€“ this is why you are taking this workshop3! Reproducibility is a process4 â€“ but there are small and meaningful ways that you can make your projects a little better. So letâ€™s dive in.\n\n\n\n\n\n\nA quick note on why you should care about computational reproducibility5.\n\n\n\n\n\nCoding can feel like a personal exercise. It is an intimate bond between you and your computer. Every once in a while, you share the fruits of your labor â€” a result or a figure, but no one really looks under the hood. This fosters a whatever-gets-the-job-done approach. It doesnâ€™t have to be pretty. It just needs to work. And I think that is appropriate, sometimes. But the reality is: if you plan on publishing, then, like it or not, you plan on sharing your code and others will relying on the accuracy of your results. If you keep that fact in mind from the beginning, you will likely save yourself, your collaborators, and the scientific world a lot of time.\n\n\n\n\n\nMuch of the advice on computational reproducibility is somewhat abstract6. That is, in part, the nature of the beast. Each project represents its own unique challenges. But it is also because the advice is often made for a broad range of projects in all sorts of different programming languages on everything from model simulations to genome assembly, all the way to creating programmatic tools for others. In contrast, this workshop will focus on a narrower set of tasks related to statistical programming in R7. In other words, the type of programming where you have some raw data generated elsewhere (e.g., enzyme activity or species abundance data) that you are going to preform some sort of analysis on it (e.g., normalization and a significance test), and then make figures.\n\n\n\n\n\n\nTL;DR - Practical tips for computational reproducibility 8\n\n\n\n\n\n\n\n\nUse the â€œProjectsâ€ feature in R.\nDo not save .RData on exit, and do not restore .RData on open. You can change this default behavior in RStudio in the Global Options.\nUse the built in version control tools. There are easy ways to interact with Git and GitHub with the RStudio IDE.\nUse the tidyverse packages! See the tidyverse chapter of this workshop.\n\n\n\n\n\nUse a consistent directory structure. You can save this structure as a template and begin from there, rather than build each project from scratch.\nUse sub-directories. Favor a highly nested directory structure, over a directory with dozens of files with long and repetative names. If you find yourself making a bunch of files with the same prefix, that probably means that they should all be in their own directory.\nAdd a number prefix to your scripts (and possible directories), so it is clear which order they must be run 01_normalize_data.R.\nYou can have directory structures that mirror each other â€“ this makes it easier to know where the relevant info is saved. For example, the data from data/raw/pheno/2023-07-04_data.csv could be analyzed in a script in src/pheno/01_anova.R, and the output could be saved in output/pheno/anova_results.rds and the corresponding figure saved in output/figs/pheno/boxplot.pdf.\n\n\n\n\n\nEvery script should be able to run without errors from top to bottom (i.e., in R, source(file_name.R) or clicking the source button in RStudio should always work when you save a file).\nWhen you are using multiple packages with overlapping function names, the order that you load the libraries can matter. If you have this make sure you can\nThe order of each script should make sense and be consistent (e.g., description, load packages, load data, manipulate data, save data). If you find yourself violating this rule. Loading packages later in a script or multiple saves of data intermediates within a file, it may make sense to split up the script. See next tip.\nFavor small scripts that are focused on a single task, over big scripts that do many things.\nYou should be able to run every script with a completely clean global environment.\nDevelop a consistent coding style (e.g., snake_case, indents, comments)\nYou should be able to clone the parent directory of the project and run the scripts â€“ without any alteration, on any machine.\n\n\n\n\n\nAvoid any manual manipulation of data (i.e., donâ€™t mess around copy-and-pasting or editing raw data, change it reproducibly with code).\nSave output automatically by writing it into the code (e.g., saveRDS(), readr::write_csv(), ggsave()).\nSave intermediate data. If you are starting with a big data set, it is nice save that intermediate so a collaborator (or you in the future, or some random researcher on the internet), can re-do an intermediate step rather than begin from raw data. If they want to know how different you results would look normalized your data in a different way\n\n\n\n\n\nDonâ€™t copy and paste output into R scripts. If you need to save an output table, then write it to a csv or save it as an .rds file. If you need quick access to some intermediary info then use RMarkdown or Quarto to create .html reports.\nDonâ€™t include anything that isnâ€™t necessary in your code.\nOpt for long and explicit variable or function names over short and implicit names.\nUse a driver script that automates the entire workflow in a single script call.\nDo not save install.packages(\"some_package\") in your script â€“ even if it is commented out. If in the future, you happen to have a new machine that doesnâ€™t have some_package installed, you will remember how to install it. This is something that can just be run directly in the console, when necessary, and does not need to be saved in the script.\n\n\n\n\n\nCommit and push relatively often. This makes your commit history a useful record the changes you have made. It also makes it less likely that you will run into issues pushing and pulling. Or at least less traumatic if you do run into issues.\nAlways pull first â€“ just in case your local state is a little behind.\nDonâ€™t commit large files (e.g., raw data or large pdf figures) to version control. The software usually has limits.\n\n\n\n\n\n\n\n\nThe tips outlined above are a useful and specific starting point9. But rather than rely solely on my eccentricities, letâ€™s instead adopt these simple rules from Sandve et al. (2013). Over the course of this workshop, we will look at some specific coding practices and think about how they may violate, or adhere to, one (or more) of these rules. The additional benefit of adpoting these rules is that they are easy enough to apply to other types of projects. It is worth reading in full.\n\n\n\n\n\n\nTen simple rules for reproducible computational research\n\n\n\n\nFor every result, keep track of how it was produced\nAvoid manual data manipulation steps\nArchive the exact versions of all external programs used\nVersion control all custom scripts\nRecord all intermediate results, when possible in standardized formats\nFor analyses that include randomness, note underlying random seeds\nAlways store raw data behind plots\nGenerate hierarchical analysis output, allowing layers of increasing detail to be inspected\nConnect textual statements to underlying results\nProvide public access to scripts, runs, and results\n\n\n\n\n\n\nOkay, letâ€™s begin by opening up RStudio10. Do you have objects already in your Global Environment? Is the console full of code you ran last time? Or do you always keep RStudio running, because you are worried about loosing the results you finally managed to get, and you need to do more stuff later?\nI know people that do great work in R and live their lives like this â€“ but it kinda makes me sweat. How do you know what is real? What if those objects were created under some other conditions and you have since edited your script? How many packages do you have loaded? What are they?11 It stresses me out, in part because you are violating Rule 1 â€“ you donâ€™t necessarily have a good track record of how that object was produced. It could me something that you ran into the console long ago and you have since changed your script. You want your source of truth12 to be the script. In other words, the list of specfic commands that take you from raw data to your results. Zombie objects in the Global Environment are not your friend.\nIt is best practice to start with a blank slate every time you open RStudio. This will force you to rely solely on the code infront of you. Rather than something that may or may not be what you remember it to be. It also mimics the environment of someone else, sitting down at their own machine, trying to replicate your results â€“ getting closer to ensuring reproducibility.\n\n\n\n\n\n\nTip\n\n\n\nThere is actually an easy way to set up a blank slate as RStudioâ€™s default behavior. Just execute usethis::use_blank_slate() in the console and it will ensure that the Global Options of RStudio are configured in such a way that you have a blank slate each time you open R. Alternatively, you can manually adjust the Global Options as explained here.\n\n\n\n\n\nProjects are your friend. Jenny Bryan, a developer at RStudio, has an impassioned blog post on why you should embrace a project-oriented workflow. You should probably read her post in full, because if you donâ€™t listen, she is threatening to set your computer on fire ğŸ”¥. But seriously, you should read it.\nAs a way of quickly summarizing one of her points: you should make sure that your final product (i.e., your script) is completely free of things that are specific to your own personal habits. For example, do you have something similar to setwd(\"/Users/tsoleary/R/quest_workshop_2023\") at the start of your script? Or in some other way, are you using absolute paths? If you do, then for a certainty if someone else wants to run your code, they will have to edit it to make sure they donâ€™t immediately run into an error. This means that right off the bat, your code is not reproducibility-friendly. As a remedy, she suggests using projects and the here package discussed below.\n\n\nThe here package is a great way to make sure that your code can be run easily on someone elseâ€™s machine. Jenny Bryan has another post dedicated specifically to the here package: read it here.\nWhat I like about it is that it allows you to easily separate out the file and the directory that you want to place it in â€“ see below:\n\n# Load data\ndat &lt;- read_csv(here::here(\"data/raw/counts.csv\"))\n\n\n\n\n\n\n\nhere::here\n\n\n\nAs youâ€™ll notice above rather than load the here package with library(here) and then use the here() function, I use the package::function_name notation to call the here function without attaching the whole here package. The added bonus is that it is kinda fun to say Here, Here! ğŸº\n\n\nI find the here package very useful for working with RMarkdown documents. By default, RMarkdown documents often use what ever directory that document is in as its root directory, so then all relative paths are in relation to where ever that RMarkdown document happens to be. But the here package allows you to continue to use the project root for your relative paths!\n\n\n\n\n\n\nTip\n\n\n\nProjects in RStudio allows for easy integration with Version Control! Check out the short SectionÂ 1.7 on Version Control.\n\n\n\n\n\n\nThere are thousands of ways you could structure your files in a project â€“ but there are really only two ways of going about it. The first is ad hoc. You group up files in sub-directores as you go along, tailoring the directory structure into something that makes sense to you, or at least something that is workable. And the other way, is to use a backbone template directory struture and build off that.\nFor most of the time I have worked in R, I have used the ad hoc approach. And it the best I can say for it is that it works. In my eyes, each project is its own snowflake. But if you ask someone else to look at it, they may think a dungeon maze or London Below13 is more apt a metaphor. But I have come to embrace a consistent directory structure.\nhttps://www.r-bloggers.com/2018/08/structuring-r-projects/\n\nTemplateExample\n\n\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ 01_analysis/\nâ”‚   â”œâ”€â”€ 02_analysis/\nâ”‚   â”œâ”€â”€ 03_figures/\nâ”œâ”€â”€ data/\nâ”‚   â”œâ”€â”€ raw/\nâ”‚   â”œâ”€â”€ processed/\nâ”œâ”€â”€ docs/\nâ”‚   â”œâ”€â”€ index.qmd\nâ”œâ”€â”€ output/\nâ”‚   â”œâ”€â”€ figs/\nâ”‚   â”œâ”€â”€ tables/\nâ”œâ”€â”€ scratch/\nâ”œâ”€â”€ README.md\nâ””â”€â”€ .gitignore\n\n\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ 00_pheno/\nâ”‚   â”‚   â”œâ”€â”€ 00_pheno.R\nâ”‚   â”œâ”€â”€ 01_nuclei/\nâ”‚   â”‚   â”œâ”€â”€ 00_count_nuclei.ijm\nâ”‚   â”œâ”€â”€ 02_cellranger-arc/\nâ”‚   â”‚   â”œâ”€â”€ 00_mkref.sh\nâ”‚   â”‚   â”œâ”€â”€ 01_count.sh\nâ”‚   â”‚   â”œâ”€â”€ 02_aggr.sh\nâ”‚   â”œâ”€â”€ 03_seurat/\nâ”‚   â”‚   â”œâ”€â”€ 00_create_seurat_object.R\nâ”‚   â”‚   â”œâ”€â”€ 01_quality_control_filtering.R\nâ”‚   â”‚   â”œâ”€â”€ 02_initial_cluster.R\nâ”‚   â”œâ”€â”€ 04_plots/\nâ”‚   â”‚   â”œâ”€â”€ annot.R\nâ”‚   â”‚   â”œâ”€â”€ cluster.R\nâ”‚   â”‚   â”œâ”€â”€ final.R\nâ”œâ”€â”€ data/\nâ”‚   â”œâ”€â”€ raw/\nâ”‚   â”‚   â”œâ”€â”€ annot/\n|   |   â”‚   â”œâ”€â”€ calderon_markers.csv\n|   |   â”‚   â”œâ”€â”€ dmel_cell-cycle_genes.csv\n|   |   â”‚   â”œâ”€â”€ insitu_annot.csv\nâ”‚   â”‚   â”œâ”€â”€ nuclei/\nâ”‚   â”‚   â”œâ”€â”€ pheno/\nâ”‚   â”‚   â”œâ”€â”€ seq/\nâ”‚   â”œâ”€â”€ processed/\n|   |   â”‚   â”œâ”€â”€ annot.rds\n|   |   â”‚   â”œâ”€â”€ cluster_all.rds\n|   |   â”‚   â”œâ”€â”€ cluster_manual.rds\nâ”‚   â”‚   â”œâ”€â”€ annot/\nâ”‚   â”‚   â”œâ”€â”€ genes/\nâ”‚   â”‚   â”œâ”€â”€ seq/\nâ”‚   â”‚   â”œâ”€â”€ seurat_object/\n|   |   â”‚   â”œâ”€â”€ 00_dat_raw.rds\n|   |   â”‚   â”œâ”€â”€ 01_dat_qc.rds\n|   |   â”‚   â”œâ”€â”€ 02_dat_clust.rds\nâ”œâ”€â”€ docs/\nâ”‚   â”œâ”€â”€ index.qmd\nâ”œâ”€â”€ output/\nâ”‚   â”œâ”€â”€ figs/\n|   â”‚   â”œâ”€â”€ annot/\n|   |   â”‚   â”œâ”€â”€ umap.pdf\n|   |   â”‚   â”œâ”€â”€ tsne.pdf\n|   â”‚   â”œâ”€â”€ cluster/\n|   |   â”‚   â”œâ”€â”€ umap.pdf\n|   |   â”‚   â”œâ”€â”€ tsne.pdf\n|   â”‚   â”œâ”€â”€ final/\n|   |   â”‚   â”œâ”€â”€ fig_1.pdf\n|   |   â”‚   â”œâ”€â”€ fig_2.pdf\n|   |   â”‚   â”œâ”€â”€ fig_3.pdf\nâ”‚   â”œâ”€â”€ tables/\nâ”‚   â”œâ”€â”€ dars/\n|   â”‚   â”œâ”€â”€ cell_type.rds\n|   â”‚   â”œâ”€â”€ cluster.rds\nâ”‚   â”œâ”€â”€ degs/\n|   â”‚   â”œâ”€â”€ cell_type.rds\n|   â”‚   â”œâ”€â”€ cluster.rds\nâ”œâ”€â”€ scratch/\nâ”œâ”€â”€ README.md\nâ””â”€â”€ .gitignore\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you use Version Control this sort of directory structure is also helpful because you can easily mark entire directories to be ignored (e.g., including data/* our output/figs/* in the .gitignore file). Most version control software will have a file size limit. Anyway, the thing you are most concerned with version controlling is the code (i.e., the src/ directory). The data and output can and should be backed up somewhere else.\n\n\n\n\n\nI believe in short scripts that do one thing, rather then a huge unruly script that does everything. This helps adhere to Rule 5: Record all intermediate results, when possible in standardized formats & Rule 8: Generate hierarchical analysis output, allowing layers of increasing detail to be inspected. Creating small scripts with intermediate results mean that you in the future or a reviewer can easily jump into the analysis mid-way and explore the data.\nIf you read Jenny Bryanâ€™s blog post on a project-oriented workflow referenced earlier, you likely ran across this advice:\n\nWhat about objects that take a long time to create? Isolate that bit in its own script and write the precious object to file with saveRDS(my_precious, here(\"results\", \"my_precious.rds\")). Now you can develop scripts to do downstream work that reload the precious object via my_precious &lt;- readRDS(here(\"results\", \"my_precious.rds\")). It is a good idea to break data analysis into logical, isolated pieces anyway.\n\nThis is my favorite way to code.\nImagine you have an RNA-sequencing project. The journal will require you to provide the raw sequence files. But you should also provide your audience with the raw counts file, as well as a .rds file that contains the full DESeq2 object. This allows them to easily explore the data for themselves, rather than start from step zero. Then they could easily begin again at the model analysis step, without having to repeat the mapping steps.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\n\n\nIf you now have a bunch of small scripts that do small tasks, it can be useful to create a top-level script that executes all the code in the project, generating all plots and results. This both ensures that your results are reproducible and that if you need to change one small thing, like your input data, you can easily regenerate all your results.\n\n\n\nsrc/driver.R\n\n# ------------------------------------------------------------------------------\n# Simple example driver script to execute all scripts\n# TS O'Leary\n# ------------------------------------------------------------------------------\n\n# Source all files\nsource(here::here(\"src/analysis_1/00_normalize.R\"))\nsource(here::here(\"src/analysis_1/01_analyze.R\"))\nsource(here::here(\"src/analysis_1/02_model.R\"))\nsource(here::here(\"src/analysis_1/03_integrate.R\"))\n\n\nOne thing that I have been experimenting with is using\n\n\n\nYou should use the available tools as much as you can to aid your workflow.\nI use snippets to create my script templates.\n\nsnippet mhead_snip\n    # ------------------------------------------------------------------------------\n    # ${1:script_description}\n    # TS O'Leary\n    # ------------------------------------------------------------------------------\n\n    # Load libraries\n    library(tidyverse)\n\n    # Load data\n    dat &lt;- read_csv(here::here(\"data/raw/starwars.csv\"))\n    \n    # Analyze data\n    dat &lt;- dat %&gt;%\n    group_by(Species) %&gt;%\n        count()\n    \n    # Save data\n    saveRDS(here::here(\"data/processed/count.rds\"))\n\nThis template ensures that I do several things:\n\nAdd a top level description to each file. I usually try to keep it to one sentance that says what the script is doing. If you have split up your scripts into bite sized chunks, this should be easy.\nGives a place to load libraries and data at the top of the script.\nReminds me to save the output at the end of the script.\n\n\n\n\n\n\n\nI often find that I write code that is not used in the final analysis. You may find yourself doing the same. It is sometimes a random exploratory figure that doesnâ€™t end up telling you much, or maybe you normalized some data in the wrong way, or used an inappropriate type of statistical model. But in each case, you have spent some valuable amount of time writing that code, and so you are reluctant to remove it from you script. So you just comment it out â€“ or worse, just leave it hanging there in the script. After all, it might be useful down the line, somehow, somewhere. I sympathize with that, but I think it is worth removing all unnecessary code. It will help you in the future when you donâ€™t remember what you did, and donâ€™t know if that bit of code is important.\n\n\n\n\n\n\nA tip for removing all unecessary or redundant code\n\n\n\nIt can be hard to strip your code down to only the necessary bits, but it is worth it for the sake of clarity and reproducibility. I sometimes create a scratch.R file or a scratch/ directory where I copy and paste bits of code that I am reluctant to throw away. It helps clean up the final code and makes me feel a little less like I wasted my time.\n\n\n\n\n\n\nThe details of the software are beyond the scope of this workshop, but one important way people ensure the reproducibility of their projects is to utilize Version Control. In short, Version Control is a useful way to make sure that as you edit and add to large projects over time you donâ€™t lose or change any of the bits that make it work. For example, if you were to accidentally break a script, you could restore to a previous working version of that file, and then begin again. There are several software designed to do this, but the most popular in the data science world is Git and GitHub.\nThese tools can seem intimidating at first â€“ especially because they typically are interfaced with in the command line. But if it makes you more comfortable, you can use the point-and-click approach to git within RStudio itself or a desktop clients (e.g., GitHub Desktop). Here is a very useful tutorial on how to use Git and GitHub within RStudio.\n\n\n\n\nGoodman, Steven N, Daniele Fanelli, and John P A Ioannidis. 2016. â€œWhat Does Research Reproducibility Mean?â€ Sci. Transl. Med. 8 (341): 341ps12.\n\n\nNational Academies of Sciences, Engineering, Medicine, Policy, Global Affairs, Committee on Science, Engineering, Medicine, Public Policy, Board on Research Data, et al. 2019. Understanding Reproducibility and Replicability. National Academies Press (US).\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, and Eivind Hovig. 2013. â€œTen Simple Rules for Reproducible Computational Research.â€ PLoS Comput. Biol. 9 (10): e1003285."
  },
  {
    "objectID": "repro.html#practical-reproducibility",
    "href": "repro.html#practical-reproducibility",
    "title": "Reproducibility",
    "section": "",
    "text": "Much of the advice on computational reproducibility is somewhat abstract6. That is, in part, the nature of the beast. Each project represents its own unique challenges. But it is also because the advice is often made for a broad range of projects in all sorts of different programming languages on everything from model simulations to genome assembly, all the way to creating programmatic tools for others. In contrast, this workshop will focus on a narrower set of tasks related to statistical programming in R7. In other words, the type of programming where you have some raw data generated elsewhere (e.g., enzyme activity or species abundance data) that you are going to preform some sort of analysis on it (e.g., normalization and a significance test), and then make figures.\n\n\n\n\n\n\nTL;DR - Practical tips for computational reproducibility 8\n\n\n\n\n\n\n\n\nUse the â€œProjectsâ€ feature in R.\nDo not save .RData on exit, and do not restore .RData on open. You can change this default behavior in RStudio in the Global Options.\nUse the built in version control tools. There are easy ways to interact with Git and GitHub with the RStudio IDE.\nUse the tidyverse packages! See the tidyverse chapter of this workshop.\n\n\n\n\n\nUse a consistent directory structure. You can save this structure as a template and begin from there, rather than build each project from scratch.\nUse sub-directories. Favor a highly nested directory structure, over a directory with dozens of files with long and repetative names. If you find yourself making a bunch of files with the same prefix, that probably means that they should all be in their own directory.\nAdd a number prefix to your scripts (and possible directories), so it is clear which order they must be run 01_normalize_data.R.\nYou can have directory structures that mirror each other â€“ this makes it easier to know where the relevant info is saved. For example, the data from data/raw/pheno/2023-07-04_data.csv could be analyzed in a script in src/pheno/01_anova.R, and the output could be saved in output/pheno/anova_results.rds and the corresponding figure saved in output/figs/pheno/boxplot.pdf.\n\n\n\n\n\nEvery script should be able to run without errors from top to bottom (i.e., in R, source(file_name.R) or clicking the source button in RStudio should always work when you save a file).\nWhen you are using multiple packages with overlapping function names, the order that you load the libraries can matter. If you have this make sure you can\nThe order of each script should make sense and be consistent (e.g., description, load packages, load data, manipulate data, save data). If you find yourself violating this rule. Loading packages later in a script or multiple saves of data intermediates within a file, it may make sense to split up the script. See next tip.\nFavor small scripts that are focused on a single task, over big scripts that do many things.\nYou should be able to run every script with a completely clean global environment.\nDevelop a consistent coding style (e.g., snake_case, indents, comments)\nYou should be able to clone the parent directory of the project and run the scripts â€“ without any alteration, on any machine.\n\n\n\n\n\nAvoid any manual manipulation of data (i.e., donâ€™t mess around copy-and-pasting or editing raw data, change it reproducibly with code).\nSave output automatically by writing it into the code (e.g., saveRDS(), readr::write_csv(), ggsave()).\nSave intermediate data. If you are starting with a big data set, it is nice save that intermediate so a collaborator (or you in the future, or some random researcher on the internet), can re-do an intermediate step rather than begin from raw data. If they want to know how different you results would look normalized your data in a different way\n\n\n\n\n\nDonâ€™t copy and paste output into R scripts. If you need to save an output table, then write it to a csv or save it as an .rds file. If you need quick access to some intermediary info then use RMarkdown or Quarto to create .html reports.\nDonâ€™t include anything that isnâ€™t necessary in your code.\nOpt for long and explicit variable or function names over short and implicit names.\nUse a driver script that automates the entire workflow in a single script call.\nDo not save install.packages(\"some_package\") in your script â€“ even if it is commented out. If in the future, you happen to have a new machine that doesnâ€™t have some_package installed, you will remember how to install it. This is something that can just be run directly in the console, when necessary, and does not need to be saved in the script.\n\n\n\n\n\nCommit and push relatively often. This makes your commit history a useful record the changes you have made. It also makes it less likely that you will run into issues pushing and pulling. Or at least less traumatic if you do run into issues.\nAlways pull first â€“ just in case your local state is a little behind.\nDonâ€™t commit large files (e.g., raw data or large pdf figures) to version control. The software usually has limits."
  },
  {
    "objectID": "repro.html#ten-simple-rules",
    "href": "repro.html#ten-simple-rules",
    "title": "Reproducibility",
    "section": "",
    "text": "The tips outlined above are a useful and specific starting point9. But rather than rely solely on my eccentricities, letâ€™s instead adopt these simple rules from Sandve et al. (2013). Over the course of this workshop, we will look at some specific coding practices and think about how they may violate, or adhere to, one (or more) of these rules. The additional benefit of adpoting these rules is that they are easy enough to apply to other types of projects. It is worth reading in full.\n\n\n\n\n\n\nTen simple rules for reproducible computational research\n\n\n\n\nFor every result, keep track of how it was produced\nAvoid manual data manipulation steps\nArchive the exact versions of all external programs used\nVersion control all custom scripts\nRecord all intermediate results, when possible in standardized formats\nFor analyses that include randomness, note underlying random seeds\nAlways store raw data behind plots\nGenerate hierarchical analysis output, allowing layers of increasing detail to be inspected\nConnect textual statements to underlying results\nProvide public access to scripts, runs, and results"
  },
  {
    "objectID": "repro.html#opening-in-rstudio",
    "href": "repro.html#opening-in-rstudio",
    "title": "Reproducibility",
    "section": "",
    "text": "Okay, letâ€™s begin by opening up RStudio10. Do you have objects already in your Global Environment? Is the console full of code you ran last time? Or do you always keep RStudio running, because you are worried about loosing the results you finally managed to get, and you need to do more stuff later?\nI know people that do great work in R and live their lives like this â€“ but it kinda makes me sweat. How do you know what is real? What if those objects were created under some other conditions and you have since edited your script? How many packages do you have loaded? What are they?11 It stresses me out, in part because you are violating Rule 1 â€“ you donâ€™t necessarily have a good track record of how that object was produced. It could me something that you ran into the console long ago and you have since changed your script. You want your source of truth12 to be the script. In other words, the list of specfic commands that take you from raw data to your results. Zombie objects in the Global Environment are not your friend.\nIt is best practice to start with a blank slate every time you open RStudio. This will force you to rely solely on the code infront of you. Rather than something that may or may not be what you remember it to be. It also mimics the environment of someone else, sitting down at their own machine, trying to replicate your results â€“ getting closer to ensuring reproducibility.\n\n\n\n\n\n\nTip\n\n\n\nThere is actually an easy way to set up a blank slate as RStudioâ€™s default behavior. Just execute usethis::use_blank_slate() in the console and it will ensure that the Global Options of RStudio are configured in such a way that you have a blank slate each time you open R. Alternatively, you can manually adjust the Global Options as explained here."
  },
  {
    "objectID": "repro.html#projects-in-rstudio",
    "href": "repro.html#projects-in-rstudio",
    "title": "Reproducibility",
    "section": "",
    "text": "Projects are your friend. Jenny Bryan, a developer at RStudio, has an impassioned blog post on why you should embrace a project-oriented workflow. You should probably read her post in full, because if you donâ€™t listen, she is threatening to set your computer on fire ğŸ”¥. But seriously, you should read it.\nAs a way of quickly summarizing one of her points: you should make sure that your final product (i.e., your script) is completely free of things that are specific to your own personal habits. For example, do you have something similar to setwd(\"/Users/tsoleary/R/quest_workshop_2023\") at the start of your script? Or in some other way, are you using absolute paths? If you do, then for a certainty if someone else wants to run your code, they will have to edit it to make sure they donâ€™t immediately run into an error. This means that right off the bat, your code is not reproducibility-friendly. As a remedy, she suggests using projects and the here package discussed below.\n\n\nThe here package is a great way to make sure that your code can be run easily on someone elseâ€™s machine. Jenny Bryan has another post dedicated specifically to the here package: read it here.\nWhat I like about it is that it allows you to easily separate out the file and the directory that you want to place it in â€“ see below:\n\n# Load data\ndat &lt;- read_csv(here::here(\"data/raw/counts.csv\"))\n\n\n\n\n\n\n\nhere::here\n\n\n\nAs youâ€™ll notice above rather than load the here package with library(here) and then use the here() function, I use the package::function_name notation to call the here function without attaching the whole here package. The added bonus is that it is kinda fun to say Here, Here! ğŸº\n\n\nI find the here package very useful for working with RMarkdown documents. By default, RMarkdown documents often use what ever directory that document is in as its root directory, so then all relative paths are in relation to where ever that RMarkdown document happens to be. But the here package allows you to continue to use the project root for your relative paths!\n\n\n\n\n\n\nTip\n\n\n\nProjects in RStudio allows for easy integration with Version Control! Check out the short SectionÂ 1.7 on Version Control."
  },
  {
    "objectID": "repro.html#directory-structure",
    "href": "repro.html#directory-structure",
    "title": "Reproducibility",
    "section": "",
    "text": "There are thousands of ways you could structure your files in a project â€“ but there are really only two ways of going about it. The first is ad hoc. You group up files in sub-directores as you go along, tailoring the directory structure into something that makes sense to you, or at least something that is workable. And the other way, is to use a backbone template directory struture and build off that.\nFor most of the time I have worked in R, I have used the ad hoc approach. And it the best I can say for it is that it works. In my eyes, each project is its own snowflake. But if you ask someone else to look at it, they may think a dungeon maze or London Below13 is more apt a metaphor. But I have come to embrace a consistent directory structure.\nhttps://www.r-bloggers.com/2018/08/structuring-r-projects/\n\nTemplateExample\n\n\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ 01_analysis/\nâ”‚   â”œâ”€â”€ 02_analysis/\nâ”‚   â”œâ”€â”€ 03_figures/\nâ”œâ”€â”€ data/\nâ”‚   â”œâ”€â”€ raw/\nâ”‚   â”œâ”€â”€ processed/\nâ”œâ”€â”€ docs/\nâ”‚   â”œâ”€â”€ index.qmd\nâ”œâ”€â”€ output/\nâ”‚   â”œâ”€â”€ figs/\nâ”‚   â”œâ”€â”€ tables/\nâ”œâ”€â”€ scratch/\nâ”œâ”€â”€ README.md\nâ””â”€â”€ .gitignore\n\n\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ 00_pheno/\nâ”‚   â”‚   â”œâ”€â”€ 00_pheno.R\nâ”‚   â”œâ”€â”€ 01_nuclei/\nâ”‚   â”‚   â”œâ”€â”€ 00_count_nuclei.ijm\nâ”‚   â”œâ”€â”€ 02_cellranger-arc/\nâ”‚   â”‚   â”œâ”€â”€ 00_mkref.sh\nâ”‚   â”‚   â”œâ”€â”€ 01_count.sh\nâ”‚   â”‚   â”œâ”€â”€ 02_aggr.sh\nâ”‚   â”œâ”€â”€ 03_seurat/\nâ”‚   â”‚   â”œâ”€â”€ 00_create_seurat_object.R\nâ”‚   â”‚   â”œâ”€â”€ 01_quality_control_filtering.R\nâ”‚   â”‚   â”œâ”€â”€ 02_initial_cluster.R\nâ”‚   â”œâ”€â”€ 04_plots/\nâ”‚   â”‚   â”œâ”€â”€ annot.R\nâ”‚   â”‚   â”œâ”€â”€ cluster.R\nâ”‚   â”‚   â”œâ”€â”€ final.R\nâ”œâ”€â”€ data/\nâ”‚   â”œâ”€â”€ raw/\nâ”‚   â”‚   â”œâ”€â”€ annot/\n|   |   â”‚   â”œâ”€â”€ calderon_markers.csv\n|   |   â”‚   â”œâ”€â”€ dmel_cell-cycle_genes.csv\n|   |   â”‚   â”œâ”€â”€ insitu_annot.csv\nâ”‚   â”‚   â”œâ”€â”€ nuclei/\nâ”‚   â”‚   â”œâ”€â”€ pheno/\nâ”‚   â”‚   â”œâ”€â”€ seq/\nâ”‚   â”œâ”€â”€ processed/\n|   |   â”‚   â”œâ”€â”€ annot.rds\n|   |   â”‚   â”œâ”€â”€ cluster_all.rds\n|   |   â”‚   â”œâ”€â”€ cluster_manual.rds\nâ”‚   â”‚   â”œâ”€â”€ annot/\nâ”‚   â”‚   â”œâ”€â”€ genes/\nâ”‚   â”‚   â”œâ”€â”€ seq/\nâ”‚   â”‚   â”œâ”€â”€ seurat_object/\n|   |   â”‚   â”œâ”€â”€ 00_dat_raw.rds\n|   |   â”‚   â”œâ”€â”€ 01_dat_qc.rds\n|   |   â”‚   â”œâ”€â”€ 02_dat_clust.rds\nâ”œâ”€â”€ docs/\nâ”‚   â”œâ”€â”€ index.qmd\nâ”œâ”€â”€ output/\nâ”‚   â”œâ”€â”€ figs/\n|   â”‚   â”œâ”€â”€ annot/\n|   |   â”‚   â”œâ”€â”€ umap.pdf\n|   |   â”‚   â”œâ”€â”€ tsne.pdf\n|   â”‚   â”œâ”€â”€ cluster/\n|   |   â”‚   â”œâ”€â”€ umap.pdf\n|   |   â”‚   â”œâ”€â”€ tsne.pdf\n|   â”‚   â”œâ”€â”€ final/\n|   |   â”‚   â”œâ”€â”€ fig_1.pdf\n|   |   â”‚   â”œâ”€â”€ fig_2.pdf\n|   |   â”‚   â”œâ”€â”€ fig_3.pdf\nâ”‚   â”œâ”€â”€ tables/\nâ”‚   â”œâ”€â”€ dars/\n|   â”‚   â”œâ”€â”€ cell_type.rds\n|   â”‚   â”œâ”€â”€ cluster.rds\nâ”‚   â”œâ”€â”€ degs/\n|   â”‚   â”œâ”€â”€ cell_type.rds\n|   â”‚   â”œâ”€â”€ cluster.rds\nâ”œâ”€â”€ scratch/\nâ”œâ”€â”€ README.md\nâ””â”€â”€ .gitignore\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you use Version Control this sort of directory structure is also helpful because you can easily mark entire directories to be ignored (e.g., including data/* our output/figs/* in the .gitignore file). Most version control software will have a file size limit. Anyway, the thing you are most concerned with version controlling is the code (i.e., the src/ directory). The data and output can and should be backed up somewhere else."
  },
  {
    "objectID": "repro.html#scripts",
    "href": "repro.html#scripts",
    "title": "Reproducibility",
    "section": "",
    "text": "I believe in short scripts that do one thing, rather then a huge unruly script that does everything. This helps adhere to Rule 5: Record all intermediate results, when possible in standardized formats & Rule 8: Generate hierarchical analysis output, allowing layers of increasing detail to be inspected. Creating small scripts with intermediate results mean that you in the future or a reviewer can easily jump into the analysis mid-way and explore the data.\nIf you read Jenny Bryanâ€™s blog post on a project-oriented workflow referenced earlier, you likely ran across this advice:\n\nWhat about objects that take a long time to create? Isolate that bit in its own script and write the precious object to file with saveRDS(my_precious, here(\"results\", \"my_precious.rds\")). Now you can develop scripts to do downstream work that reload the precious object via my_precious &lt;- readRDS(here(\"results\", \"my_precious.rds\")). It is a good idea to break data analysis into logical, isolated pieces anyway.\n\nThis is my favorite way to code.\nImagine you have an RNA-sequencing project. The journal will require you to provide the raw sequence files. But you should also provide your audience with the raw counts file, as well as a .rds file that contains the full DESeq2 object. This allows them to easily explore the data for themselves, rather than start from step zero. Then they could easily begin again at the model analysis step, without having to repeat the mapping steps.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\n\n\nIf you now have a bunch of small scripts that do small tasks, it can be useful to create a top-level script that executes all the code in the project, generating all plots and results. This both ensures that your results are reproducible and that if you need to change one small thing, like your input data, you can easily regenerate all your results.\n\n\n\nsrc/driver.R\n\n# ------------------------------------------------------------------------------\n# Simple example driver script to execute all scripts\n# TS O'Leary\n# ------------------------------------------------------------------------------\n\n# Source all files\nsource(here::here(\"src/analysis_1/00_normalize.R\"))\nsource(here::here(\"src/analysis_1/01_analyze.R\"))\nsource(here::here(\"src/analysis_1/02_model.R\"))\nsource(here::here(\"src/analysis_1/03_integrate.R\"))\n\n\nOne thing that I have been experimenting with is using\n\n\n\nYou should use the available tools as much as you can to aid your workflow.\nI use snippets to create my script templates.\n\nsnippet mhead_snip\n    # ------------------------------------------------------------------------------\n    # ${1:script_description}\n    # TS O'Leary\n    # ------------------------------------------------------------------------------\n\n    # Load libraries\n    library(tidyverse)\n\n    # Load data\n    dat &lt;- read_csv(here::here(\"data/raw/starwars.csv\"))\n    \n    # Analyze data\n    dat &lt;- dat %&gt;%\n    group_by(Species) %&gt;%\n        count()\n    \n    # Save data\n    saveRDS(here::here(\"data/processed/count.rds\"))\n\nThis template ensures that I do several things:\n\nAdd a top level description to each file. I usually try to keep it to one sentance that says what the script is doing. If you have split up your scripts into bite sized chunks, this should be easy.\nGives a place to load libraries and data at the top of the script.\nReminds me to save the output at the end of the script.\n\n\n\n\n\n\n\nI often find that I write code that is not used in the final analysis. You may find yourself doing the same. It is sometimes a random exploratory figure that doesnâ€™t end up telling you much, or maybe you normalized some data in the wrong way, or used an inappropriate type of statistical model. But in each case, you have spent some valuable amount of time writing that code, and so you are reluctant to remove it from you script. So you just comment it out â€“ or worse, just leave it hanging there in the script. After all, it might be useful down the line, somehow, somewhere. I sympathize with that, but I think it is worth removing all unnecessary code. It will help you in the future when you donâ€™t remember what you did, and donâ€™t know if that bit of code is important.\n\n\n\n\n\n\nA tip for removing all unecessary or redundant code\n\n\n\nIt can be hard to strip your code down to only the necessary bits, but it is worth it for the sake of clarity and reproducibility. I sometimes create a scratch.R file or a scratch/ directory where I copy and paste bits of code that I am reluctant to throw away. It helps clean up the final code and makes me feel a little less like I wasted my time."
  },
  {
    "objectID": "repro.html#sec-vc",
    "href": "repro.html#sec-vc",
    "title": "Reproducibility",
    "section": "",
    "text": "The details of the software are beyond the scope of this workshop, but one important way people ensure the reproducibility of their projects is to utilize Version Control. In short, Version Control is a useful way to make sure that as you edit and add to large projects over time you donâ€™t lose or change any of the bits that make it work. For example, if you were to accidentally break a script, you could restore to a previous working version of that file, and then begin again. There are several software designed to do this, but the most popular in the data science world is Git and GitHub.\nThese tools can seem intimidating at first â€“ especially because they typically are interfaced with in the command line. But if it makes you more comfortable, you can use the point-and-click approach to git within RStudio itself or a desktop clients (e.g., GitHub Desktop). Here is a very useful tutorial on how to use Git and GitHub within RStudio.\n\n\n\n\nGoodman, Steven N, Daniele Fanelli, and John P A Ioannidis. 2016. â€œWhat Does Research Reproducibility Mean?â€ Sci. Transl. Med. 8 (341): 341ps12.\n\n\nNational Academies of Sciences, Engineering, Medicine, Policy, Global Affairs, Committee on Science, Engineering, Medicine, Public Policy, Board on Research Data, et al. 2019. Understanding Reproducibility and Replicability. National Academies Press (US).\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, and Eivind Hovig. 2013. â€œTen Simple Rules for Reproducible Computational Research.â€ PLoS Comput. Biol. 9 (10): e1003285."
  },
  {
    "objectID": "repro.html#footnotes",
    "href": "repro.html#footnotes",
    "title": "Reproducibility",
    "section": "",
    "text": "Please see Goodman, Fanelli, and Ioannidis (2016) for a more rigorous discussion of terms.â†©ï¸\nOne example of this sort of reproducibility, was the independent sets of experiments that showed that DNA as the hereditary molecule.â†©ï¸\nI hope the workshop helps ğŸ˜!â†©ï¸\nI definitely donâ€™t have a perfect workflow, but it has gotten better slowly over the years.â†©ï¸\nIn particular, taking control of the small details that make your code easier to share and easier for others to understandâ†©ï¸\nGoogle data provenance and look at the flow charts.â†©ï¸\nStatistical programming is right in Râ€™s wheelhouse. And it is also the most common type of programming for early career students in my discipline. You design and conduct an experiment. You generate data. You analyze data. You present data.â†©ï¸\nAs with all advice in these workshop, these are just my opinions â€“ no more. And as with all rules, there are always good exceptions to breaking any of these rules.â†©ï¸\nIf some of the tips donâ€™t make sense or you want more context, read on!â†©ï¸\nEither in reality or just as a mental exercise.â†©ï¸\nWhatâ€™s in the BOX???â†©ï¸\nRead this link to R for Data Science, for more information.â†©ï¸\nCheck out Neverwhere by Neil Gaimanâ†©ï¸"
  },
  {
    "objectID": "data_viz.html",
    "href": "data_viz.html",
    "title": "Data visualization",
    "section": "",
    "text": "There are several great resources out there on the world wide web for learning how to create figures in R. They do a thorough job of introducing the basics. The simple (but sometimes not so simple) mechanics of moving from data to a figure. In particular, I recommend, the Data Visualization Chapter of R for Data Science. It is a great place to get started with a narrative introduction to ggplot. As you make more ambitious figures, ggplot2: Elegant Graphics for Data Analysis will provide you with even more detail. Similarly, the R Graphics Cookbook provides useful solutions to common problems (e.g., changing the order of items on a categorical axis).\nHowever, this workshop is not intended to replace that kind of book. Instead, it is designed to focus on the soft skills of data visualization. What are a few small changes that I can make to take this figure from workable to shareable, or even better, from something that I have to squint at to something that speaks for itself.\n\n\n\n\n\n\nFundamentals of Data Visualization\n\n\n\nMuch of the content of this workshop is inspired by the approach in Fundamentals of Data Visualization by Claus O. Wilke. You may recognize these initials if you have tried to arrange a multi-panel figure in R with cowplot::plot_grid(). I canâ€™t recommend this book highly enough. I will consider this workshop a success even if the only thing you get out of it is reading this book.\nThe mechanics of plotting are important. They are how you create the figure after all. But at the end of the day 99% of readers wonâ€™t see how you created the plots1, they will only see the final image you produce. That image is your chance to capture their attention with your data. Make it count.\n\n\n\n\nThe structure of this workshop will be to take some data. Explore it and slowly refine our way to a good figure. Therefore the first figures that we make will be a little ugly and will violate some\n\n\n\n\n\n\nTL;DR - Tips for data visualization\n\n\n\n\n\n\nInclude as much detail of your data as possible â€“ but no more.\n\nFavor including zero in the plot axis limits when it seems appropriate. This is particularly true for things where zero actually means something (e.g., amounts).\nUse color as a tool to highlight. But donâ€™t go overboard.\nUse consistent a color scheme.\nDo not use abbreviations in figures. Unless the abbreviation is ubiquitous or more useful than the full terms (e.g., a specific mutation in a gene). If you have coded your underlying data to have certain abbreviations for the sake of brevity, re-code them for the figure.\nUse sentence case for axis titles.\nUse gridlines that emphasize the variable of interest.\n\nInclude units in axis titles.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\n\n\n\nTest\n\n\n\n\n\n\n\n# Load libraries\nlibrary(tidyverse)\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.0     âœ” readr     2.1.4\nâœ” forcats   1.0.0     âœ” stringr   1.5.0\nâœ” ggplot2   3.4.1     âœ” tibble    3.1.8\nâœ” lubridate 1.9.2     âœ” tidyr     1.3.0\nâœ” purrr     1.0.1     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(palmerpenguins)\n\n\n# Take a peak at the data\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelâ€¦\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerseâ€¦\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, â€¦\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, â€¦\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186â€¦\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, â€¦\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, maleâ€¦\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007â€¦\n\n\n\n\n\n\nOkay this is a little bit of a warm up\nChoosing a type of visualization depends entirely on the sorts of questions you are trying to ask. So for now, letâ€™s pick a few different questions. I donâ€™t know anything about these penguins. So here are some simple questions that I have brainstormed:\n\nAre different species of penguins different weights?\nAre penguins from different islands different weights?\n\n\nWe will stick with the first question for now. But it is worth trying the others.\nI really hate the default theme for ggplot. So rather than look at it. Letâ€™s just set something that is a little easier on the eyes at the beginning. This command below will set cowplot::theme_minimal_grid() as the default theme for all plots going forward.\n\n# Set a nicer looking theme as a place holder\ntheme_set(cowplot::theme_minimal_grid())\n\n\nBox plotViolin plotStrip plotBeeswarmHistogramDensity plot\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_boxplot(\n    aes(x = species,\n        y = body_mass_g))\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_violin(\n    aes(x = species,\n        y = body_mass_g))\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_jitter(\n    aes(x = species,\n        y = body_mass_g),\n    width = 0.1)\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  ggbeeswarm::geom_beeswarm(\n    corral.width = 2.0,\n    aes(x = species,\n        y = body_mass_g)) \n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_histogram(\n    aes(x = body_mass_g),\n    color = \"grey20\",\n    fill = \"grey80\",\n    bins = 30) +\n  facet_wrap(~species,\n             nrow = 3)\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_density(\n    aes(x = body_mass_g,\n        color = species,\n        fill = species),\n    alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice the advantages and disadvantages of the different styles.\n\n\n\nSome have more information than others. If you had to pick one? Which would you pick?\n\n\nFortunately we donâ€™t have to pick.\n\n\n\n\npenguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_violin(width = 0.8) + \n  geom_boxplot(width = 0.2) +\n  scale_y_continuous(\n    limits = c(0, 7000)\n  )\n\n\n\n\n\npenguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_boxplot(\n    width = 0.6,\n    outlier.shape = NA\n    ) + \n  ggbeeswarm::geom_beeswarm(\n    shape = 21,\n    width = 0.2\n    ) +\n  scale_y_continuous(\n    limits = c(0, 7000)\n  )\n\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_boxplot(\n    width = 0.6,\n    outlier.shape = NA\n    ) + \n  ggbeeswarm::geom_beeswarm(\n    shape = 21,\n    width = 0.2\n    ) +\n  scale_y_continuous(\n    name = \"Body mass (g)\",\n    limits = c(0, 7000)\n    ) +\n  scale_x_discrete(\n   name = element_blank()\n  )\n\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_boxplot(\n    width = 0.6,\n    outlier.shape = NA\n    ) + \n  ggbeeswarm::geom_beeswarm(\n    shape = 21,\n    width = 0.2\n    ) +\n  scale_y_continuous(\n    name = \"Body mass (g)\",\n    limits = c(0, 7000)\n    ) +\n  scale_x_discrete(\n   name = element_blank()\n   ) +\n  cowplot::theme_minimal_hgrid()\n\n\n\n\nOh no! Look at that brual\n\npenguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_boxplot(\n    width = 0.6,\n    outlier.shape = NA\n    ) + \n  ggbeeswarm::geom_beeswarm(\n    shape = 21,\n    width = 0.2\n    ) +\n  scale_y_continuous(\n    name = \"Body mass (g)\",\n    limits = c(0, 7000),\n    expand = c(0, 0.5)\n    ) +\n  scale_x_discrete(\n   name = element_blank()\n   ) +\n  cowplot::theme_minimal_hgrid()\n\n\n\n\n\n\n\n\npenguins |&gt;  \n  ggplot(\n    aes(x = body_mass_g)\n    ) +\n  geom_histogram(\n    color = \"grey20\",\n    fill = \"grey80\"\n    ) +\n  facet_grid(rows = vars(island),\n             cols = vars(species)) +\n  cowplot::theme_minimal_hgrid() +\n  theme(strip.background = element_rect(fill = \"grey90\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`)."
  },
  {
    "objectID": "data_viz.html#explore-the-data",
    "href": "data_viz.html#explore-the-data",
    "title": "Data visualization",
    "section": "",
    "text": "Artwork by @allison_horst\n\n\n\n\n\n\n\n\nTest\n\n\n\n\n\n\n\n# Load libraries\nlibrary(tidyverse)\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.0     âœ” readr     2.1.4\nâœ” forcats   1.0.0     âœ” stringr   1.5.0\nâœ” ggplot2   3.4.1     âœ” tibble    3.1.8\nâœ” lubridate 1.9.2     âœ” tidyr     1.3.0\nâœ” purrr     1.0.1     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(palmerpenguins)\n\n\n# Take a peak at the data\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelâ€¦\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerseâ€¦\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, â€¦\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, â€¦\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186â€¦\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, â€¦\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, maleâ€¦\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007â€¦"
  },
  {
    "objectID": "data_viz.html#choosing-a-type-of-visualization",
    "href": "data_viz.html#choosing-a-type-of-visualization",
    "title": "Data visualization",
    "section": "",
    "text": "Okay this is a little bit of a warm up\nChoosing a type of visualization depends entirely on the sorts of questions you are trying to ask. So for now, letâ€™s pick a few different questions. I donâ€™t know anything about these penguins. So here are some simple questions that I have brainstormed:\n\nAre different species of penguins different weights?\nAre penguins from different islands different weights?\n\n\nWe will stick with the first question for now. But it is worth trying the others.\nI really hate the default theme for ggplot. So rather than look at it. Letâ€™s just set something that is a little easier on the eyes at the beginning. This command below will set cowplot::theme_minimal_grid() as the default theme for all plots going forward.\n\n# Set a nicer looking theme as a place holder\ntheme_set(cowplot::theme_minimal_grid())\n\n\nBox plotViolin plotStrip plotBeeswarmHistogramDensity plot\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_boxplot(\n    aes(x = species,\n        y = body_mass_g))\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_violin(\n    aes(x = species,\n        y = body_mass_g))\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_jitter(\n    aes(x = species,\n        y = body_mass_g),\n    width = 0.1)\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  ggbeeswarm::geom_beeswarm(\n    corral.width = 2.0,\n    aes(x = species,\n        y = body_mass_g)) \n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_histogram(\n    aes(x = body_mass_g),\n    color = \"grey20\",\n    fill = \"grey80\",\n    bins = 30) +\n  facet_wrap(~species,\n             nrow = 3)\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_density(\n    aes(x = body_mass_g,\n        color = species,\n        fill = species),\n    alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice the advantages and disadvantages of the different styles.\n\n\n\nSome have more information than others. If you had to pick one? Which would you pick?\n\n\nFortunately we donâ€™t have to pick."
  },
  {
    "objectID": "data_viz.html#limits",
    "href": "data_viz.html#limits",
    "title": "Data visualization",
    "section": "",
    "text": "penguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_violin(width = 0.8) + \n  geom_boxplot(width = 0.2) +\n  scale_y_continuous(\n    limits = c(0, 7000)\n  )\n\n\n\n\n\npenguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_boxplot(\n    width = 0.6,\n    outlier.shape = NA\n    ) + \n  ggbeeswarm::geom_beeswarm(\n    shape = 21,\n    width = 0.2\n    ) +\n  scale_y_continuous(\n    limits = c(0, 7000)\n  )"
  },
  {
    "objectID": "data_viz.html#creating-the-axes",
    "href": "data_viz.html#creating-the-axes",
    "title": "Data visualization",
    "section": "",
    "text": "penguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_boxplot(\n    width = 0.6,\n    outlier.shape = NA\n    ) + \n  ggbeeswarm::geom_beeswarm(\n    shape = 21,\n    width = 0.2\n    ) +\n  scale_y_continuous(\n    name = \"Body mass (g)\",\n    limits = c(0, 7000)\n    ) +\n  scale_x_discrete(\n   name = element_blank()\n  )"
  },
  {
    "objectID": "data_viz.html#choosing-a-theme",
    "href": "data_viz.html#choosing-a-theme",
    "title": "Data visualization",
    "section": "",
    "text": "penguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_boxplot(\n    width = 0.6,\n    outlier.shape = NA\n    ) + \n  ggbeeswarm::geom_beeswarm(\n    shape = 21,\n    width = 0.2\n    ) +\n  scale_y_continuous(\n    name = \"Body mass (g)\",\n    limits = c(0, 7000)\n    ) +\n  scale_x_discrete(\n   name = element_blank()\n   ) +\n  cowplot::theme_minimal_hgrid()\n\n\n\n\nOh no! Look at that brual\n\npenguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_boxplot(\n    width = 0.6,\n    outlier.shape = NA\n    ) + \n  ggbeeswarm::geom_beeswarm(\n    shape = 21,\n    width = 0.2\n    ) +\n  scale_y_continuous(\n    name = \"Body mass (g)\",\n    limits = c(0, 7000),\n    expand = c(0, 0.5)\n    ) +\n  scale_x_discrete(\n   name = element_blank()\n   ) +\n  cowplot::theme_minimal_hgrid()"
  },
  {
    "objectID": "data_viz.html#the-small-details",
    "href": "data_viz.html#the-small-details",
    "title": "Data visualization",
    "section": "",
    "text": "penguins |&gt;  \n  ggplot(\n    aes(x = body_mass_g)\n    ) +\n  geom_histogram(\n    color = \"grey20\",\n    fill = \"grey80\"\n    ) +\n  facet_grid(rows = vars(island),\n             cols = vars(species)) +\n  cowplot::theme_minimal_hgrid() +\n  theme(strip.background = element_rect(fill = \"grey90\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`)."
  },
  {
    "objectID": "data_viz.html#footnotes",
    "href": "data_viz.html#footnotes",
    "title": "Data visualization",
    "section": "",
    "text": "Shhh! Donâ€™t tell that to Chapter 1 of this workshop.â†©ï¸"
  },
  {
    "objectID": "tidyverse.html",
    "href": "tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "The tidyverse is an inter-related set of packages that have a common grammar and syntax. It encompases We will not dive deeply into each topic, but instead, the workshop will introduce the core philosophy behind the tidyverse and some of the most used functions. Then, we will spend more time on some of the more advanced techniques that make the tidyverse powerful and exciting.\n\n\nThere are base R equivalents to most things that you can do in the tidyverse. So you might wonder why it is necessary, or even useful, to learn the tidyverse. I think that skepticism is fair, but here are a few reasons why I think you should not only learn the tidyverse, but make it a regular part of your workflow1.\n\nAs a data scientist, most of your time will be spent writing code, not waiting for code to execute. Therefore you should put more value the coding style that is easiest to write and understand. The tidyverse emphasizes human readable code.\nBecause of the flexible nature of some of the tidyverse functions, the tidyverse can make for more reproducible code, that is less likely to break if some of the underlying data has changed or been added too.\nAn increasing number of newly developed packages depend on the tidyverse. So you might as well embrace it.\nYou are already using it! If have made any figures in R, more likely than not, you are already used one tidyverse package, ggplot2.\n\n\n\n\n\n\n\n\n\nThe tidy tools manifesto\n\n\n\nMy favorite part of the tidyverse is the final principle in this manifesto:\n\nDesign for humans. â€œPrograms must be written for people to read, and only incidentally for machines to execute.â€ â€” Hal Abelson\n\n\n\nThe tidyverse style guide\n\nâ€œGood coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread.â€ 2\n\n\n\n\n\n\n\nCheat sheets\n\n\n\nTidyverse packages can help with many common tasks. Check out these cheat sheets for quick reference.\n\nData import\nData tidying\nData transformation\nData visualization\nFunctional programming\nStrings\nFactors\n\n\n\n\n# Load library\nlibrary(tidyverse)\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.0     âœ” readr     2.1.4\nâœ” forcats   1.0.0     âœ” stringr   1.5.0\nâœ” ggplot2   3.4.1     âœ” tibble    3.1.8\nâœ” lubridate 1.9.2     âœ” tidyr     1.3.0\nâœ” purrr     1.0.1     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\n\n\nRather than loading each package individually â€“ I often just load all of the core packages with the convenient library(tidyverse)3. Most of my scripts are dependent on at least three of the core packages, so it is easier to just have them all included. But you could load each individually.\n\n\n\n\n\n\nThe tidyverse gets its name from the type of data that it is designed to interact with â€“ tidy data. So letâ€™s quickly define tidy data4.\n\n\n\n\n\n\nTidy data â€“ definition\n\n\n\n\nEvery column is a variable.\nEvery row is an observation.\nEvery cell is a single value.\n\n\n\nBut that definition is a bit abstract â€“ especially if you have never thought about whether data is messy or tidy before â€“ so letâ€™s try a practical example.\nBelow is some made-up messy data.\nImagine over the course of several days, you measure the height of a few plants\n\n# Make up some random data\ndat &lt;- tibble(\n  plant_id = 1:15,\n  week1 = rnorm(15, mean = 10, sd = 3),\n  week2 = week1*runif(15, min = 1, max = 1.5),\n  week3 = week2*runif(15, min = 1, max = 1.5),\n  week4 = week3*runif(15, min = 1, max = 1.5),\n  week5 = week4*runif(15, min = 1, max = 1.5)\n)\n\n# Print the data\ndat\n\n# A tibble: 15 Ã— 6\n   plant_id week1 week2 week3 week4 week5\n      &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1        1 12.3  18.2  19.7   24.6  26.7\n 2        2 11.8  17.2  21.1   24.4  32.2\n 3        3  9.63 14.1  18.0   24.5  29.5\n 4        4  7.52  9.25  9.62  14.4  15.0\n 5        5  9.27  9.50 10.9   15.4  19.0\n 6        6  8.02 11.0  15.8   16.6  22.6\n 7        7  8.05  8.62 12.3   15.8  19.6\n 8        8  7.43  8.65  8.68  11.4  13.9\n 9        9 12.0  16.6  18.1   26.2  32.9\n10       10 11.6  15.6  20.3   25.1  28.2\n11       11  5.64  7.77  7.86  10.2  12.5\n12       12 14.2  15.5  18.2   19.5  23.0\n13       13 11.5  14.4  20.8   24.6  32.9\n14       14  5.39  7.97 10.4   15.4  17.1\n15       15  9.12 13.5  14.8   16.2  20.7\n\n\n\n\n\ndat |&gt;\n  pivot_longer(contains(\"week\"),\n               names_to = \"week\",\n               values_to = \"height_cm\")\n\n# A tibble: 75 Ã— 3\n   plant_id week  height_cm\n      &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1        1 week1      12.3\n 2        1 week2      18.2\n 3        1 week3      19.7\n 4        1 week4      24.6\n 5        1 week5      26.7\n 6        2 week1      11.8\n 7        2 week2      17.2\n 8        2 week3      21.1\n 9        2 week4      24.4\n10        2 week5      32.2\n# â€¦ with 65 more rows\n\n\n\nBAM! That is tidy data. 1. Every column is a variable â€“ id, time, height. 2. Every row is an observation â€“ a height measurement on a single plant. 3. Every cell is a single value.\n\n\ndat |&gt;\n  pivot_longer(contains(\"week\"),\n               names_to = \"week\",\n               values_to = \"height_cm\") |&gt; \n  mutate(week = as.numeric(str_remove_all(week, \"week\")))\n\n# A tibble: 75 Ã— 3\n   plant_id  week height_cm\n      &lt;int&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1        1     1      12.3\n 2        1     2      18.2\n 3        1     3      19.7\n 4        1     4      24.6\n 5        1     5      26.7\n 6        2     1      11.8\n 7        2     2      17.2\n 8        2     3      21.1\n 9        2     4      24.4\n10        2     5      32.2\n# â€¦ with 65 more rows\n\n\n\n\n\n\n\n\n\nbroom â€“ clean model output â€“ technically a subpackage of tidymodels a cousin of the tidyverse\nrvest â€“ web scraping â€“ mining data from a website\nmodelr â€“ modelling â€“ support for modelling data in the tidyverse\n\n\n\n\n\nI find it a lot easier to define the data structure as you import data. And it creates a tibble instead of data.frame.\nThere are several reasons to prefer readr::read_csv() over base Râ€™s read.csv.\n\n\n\nA hazard of caring about how coding in the tidyverse style, is that you will notice bad formatting everywhere.\n\n\n\n\n\nJanitor package\nCleaning up data\n\niris |&gt; \n  janitor::clean_names()\n\n    sepal_length sepal_width petal_length petal_width    species\n1            5.1         3.5          1.4         0.2     setosa\n2            4.9         3.0          1.4         0.2     setosa\n3            4.7         3.2          1.3         0.2     setosa\n4            4.6         3.1          1.5         0.2     setosa\n5            5.0         3.6          1.4         0.2     setosa\n6            5.4         3.9          1.7         0.4     setosa\n7            4.6         3.4          1.4         0.3     setosa\n8            5.0         3.4          1.5         0.2     setosa\n9            4.4         2.9          1.4         0.2     setosa\n10           4.9         3.1          1.5         0.1     setosa\n11           5.4         3.7          1.5         0.2     setosa\n12           4.8         3.4          1.6         0.2     setosa\n13           4.8         3.0          1.4         0.1     setosa\n14           4.3         3.0          1.1         0.1     setosa\n15           5.8         4.0          1.2         0.2     setosa\n16           5.7         4.4          1.5         0.4     setosa\n17           5.4         3.9          1.3         0.4     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.7         3.8          1.7         0.3     setosa\n20           5.1         3.8          1.5         0.3     setosa\n21           5.4         3.4          1.7         0.2     setosa\n22           5.1         3.7          1.5         0.4     setosa\n23           4.6         3.6          1.0         0.2     setosa\n24           5.1         3.3          1.7         0.5     setosa\n25           4.8         3.4          1.9         0.2     setosa\n26           5.0         3.0          1.6         0.2     setosa\n27           5.0         3.4          1.6         0.4     setosa\n28           5.2         3.5          1.5         0.2     setosa\n29           5.2         3.4          1.4         0.2     setosa\n30           4.7         3.2          1.6         0.2     setosa\n31           4.8         3.1          1.6         0.2     setosa\n32           5.4         3.4          1.5         0.4     setosa\n33           5.2         4.1          1.5         0.1     setosa\n34           5.5         4.2          1.4         0.2     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.0         3.2          1.2         0.2     setosa\n37           5.5         3.5          1.3         0.2     setosa\n38           4.9         3.6          1.4         0.1     setosa\n39           4.4         3.0          1.3         0.2     setosa\n40           5.1         3.4          1.5         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n42           4.5         2.3          1.3         0.3     setosa\n43           4.4         3.2          1.3         0.2     setosa\n44           5.0         3.5          1.6         0.6     setosa\n45           5.1         3.8          1.9         0.4     setosa\n46           4.8         3.0          1.4         0.3     setosa\n47           5.1         3.8          1.6         0.2     setosa\n48           4.6         3.2          1.4         0.2     setosa\n49           5.3         3.7          1.5         0.2     setosa\n50           5.0         3.3          1.4         0.2     setosa\n51           7.0         3.2          4.7         1.4 versicolor\n52           6.4         3.2          4.5         1.5 versicolor\n53           6.9         3.1          4.9         1.5 versicolor\n54           5.5         2.3          4.0         1.3 versicolor\n55           6.5         2.8          4.6         1.5 versicolor\n56           5.7         2.8          4.5         1.3 versicolor\n57           6.3         3.3          4.7         1.6 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n59           6.6         2.9          4.6         1.3 versicolor\n60           5.2         2.7          3.9         1.4 versicolor\n61           5.0         2.0          3.5         1.0 versicolor\n62           5.9         3.0          4.2         1.5 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.9          4.7         1.4 versicolor\n65           5.6         2.9          3.6         1.3 versicolor\n66           6.7         3.1          4.4         1.4 versicolor\n67           5.6         3.0          4.5         1.5 versicolor\n68           5.8         2.7          4.1         1.0 versicolor\n69           6.2         2.2          4.5         1.5 versicolor\n70           5.6         2.5          3.9         1.1 versicolor\n71           5.9         3.2          4.8         1.8 versicolor\n72           6.1         2.8          4.0         1.3 versicolor\n73           6.3         2.5          4.9         1.5 versicolor\n74           6.1         2.8          4.7         1.2 versicolor\n75           6.4         2.9          4.3         1.3 versicolor\n76           6.6         3.0          4.4         1.4 versicolor\n77           6.8         2.8          4.8         1.4 versicolor\n78           6.7         3.0          5.0         1.7 versicolor\n79           6.0         2.9          4.5         1.5 versicolor\n80           5.7         2.6          3.5         1.0 versicolor\n81           5.5         2.4          3.8         1.1 versicolor\n82           5.5         2.4          3.7         1.0 versicolor\n83           5.8         2.7          3.9         1.2 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           6.7         3.1          4.7         1.5 versicolor\n88           6.3         2.3          4.4         1.3 versicolor\n89           5.6         3.0          4.1         1.3 versicolor\n90           5.5         2.5          4.0         1.3 versicolor\n91           5.5         2.6          4.4         1.2 versicolor\n92           6.1         3.0          4.6         1.4 versicolor\n93           5.8         2.6          4.0         1.2 versicolor\n94           5.0         2.3          3.3         1.0 versicolor\n95           5.6         2.7          4.2         1.3 versicolor\n96           5.7         3.0          4.2         1.2 versicolor\n97           5.7         2.9          4.2         1.3 versicolor\n98           6.2         2.9          4.3         1.3 versicolor\n99           5.1         2.5          3.0         1.1 versicolor\n100          5.7         2.8          4.1         1.3 versicolor\n101          6.3         3.3          6.0         2.5  virginica\n102          5.8         2.7          5.1         1.9  virginica\n103          7.1         3.0          5.9         2.1  virginica\n104          6.3         2.9          5.6         1.8  virginica\n105          6.5         3.0          5.8         2.2  virginica\n106          7.6         3.0          6.6         2.1  virginica\n107          4.9         2.5          4.5         1.7  virginica\n108          7.3         2.9          6.3         1.8  virginica\n109          6.7         2.5          5.8         1.8  virginica\n110          7.2         3.6          6.1         2.5  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          6.4         2.7          5.3         1.9  virginica\n113          6.8         3.0          5.5         2.1  virginica\n114          5.7         2.5          5.0         2.0  virginica\n115          5.8         2.8          5.1         2.4  virginica\n116          6.4         3.2          5.3         2.3  virginica\n117          6.5         3.0          5.5         1.8  virginica\n118          7.7         3.8          6.7         2.2  virginica\n119          7.7         2.6          6.9         2.3  virginica\n120          6.0         2.2          5.0         1.5  virginica\n121          6.9         3.2          5.7         2.3  virginica\n122          5.6         2.8          4.9         2.0  virginica\n123          7.7         2.8          6.7         2.0  virginica\n124          6.3         2.7          4.9         1.8  virginica\n125          6.7         3.3          5.7         2.1  virginica\n126          7.2         3.2          6.0         1.8  virginica\n127          6.2         2.8          4.8         1.8  virginica\n128          6.1         3.0          4.9         1.8  virginica\n129          6.4         2.8          5.6         2.1  virginica\n130          7.2         3.0          5.8         1.6  virginica\n131          7.4         2.8          6.1         1.9  virginica\n132          7.9         3.8          6.4         2.0  virginica\n133          6.4         2.8          5.6         2.2  virginica\n134          6.3         2.8          5.1         1.5  virginica\n135          6.1         2.6          5.6         1.4  virginica\n136          7.7         3.0          6.1         2.3  virginica\n137          6.3         3.4          5.6         2.4  virginica\n138          6.4         3.1          5.5         1.8  virginica\n139          6.0         3.0          4.8         1.8  virginica\n140          6.9         3.1          5.4         2.1  virginica\n141          6.7         3.1          5.6         2.4  virginica\n142          6.9         3.1          5.1         2.3  virginica\n143          5.8         2.7          5.1         1.9  virginica\n144          6.8         3.2          5.9         2.3  virginica\n145          6.7         3.3          5.7         2.5  virginica\n146          6.7         3.0          5.2         2.3  virginica\n147          6.3         2.5          5.0         1.9  virginica\n148          6.5         3.0          5.2         2.0  virginica\n149          6.2         3.4          5.4         2.3  virginica\n150          5.9         3.0          5.1         1.8  virginica\n\n\n\n# Create a .csv file to import\nwrite_csv(iris, \"iris.csv\")\n\n\n# Try read.csv\nd.f &lt;- read.csv(\"iris.csv\")\n\nstr(d.f)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : chr  \"setosa\" \"setosa\" \"setosa\" \"setosa\" ...\n\n\n\n# Try read_csv\nread_csv(\"iris.csv\")\n\nRows: 150 Columns: 5\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (1): Species\ndbl (4): Sepal.Length, Sepal.Width, Petal.Length, Petal.Width\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 150 Ã— 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# â€¦ with 140 more rows\n\n# Set col_type as you import data -- allows you to define level order too\nd_f &lt;- read_csv(\"iris.csv\",\n                col_types = list(Species = col_factor(c(\"versicolor\",\n                                                        \"setosa\", \n                                                        \"virginica\"))))\nd_f\n\n# A tibble: 150 Ã— 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# â€¦ with 140 more rows\n\nstr(d_f)\n\nspc_tbl_ [150 Ã— 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Sepal.Length: num [1:150] 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num [1:150] 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num [1:150] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num [1:150] 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"versicolor\",\"setosa\",..: 2 2 2 2 2 2 2 2 2 2 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Sepal.Length = col_double(),\n  ..   Sepal.Width = col_double(),\n  ..   Petal.Length = col_double(),\n  ..   Petal.Width = col_double(),\n  ..   Species = col_factor(levels = c(\"versicolor\", \"setosa\", \"virginica\"), ordered = FALSE, include_na = FALSE)\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nglimpse(d_f)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.â€¦\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.â€¦\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.â€¦\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.â€¦\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, sâ€¦\n\n\n\n\n\n\n\n\ndplyr has a few core functions that are built to work on\nTaken from the dplyr vignette.\n\n\n\nfilter() chooses rows based on column values.\nslice() chooses rows based on location.\narrange() changes the order of the rows.\n\n\n\n\n\nselect() changes whether or not a column is included.\nrename() changes the name of columns.\nmutate() changes the values of columns and creates new columns.\nrelocate() changes the order of the columns.\n\n\n\n\n\nsummarise() collapses a group into a single row.\n\n\n\n\n\nFrom magrittr.\n\nx %&gt;% f is equivalent to f(x)\nx %&gt;% f(y) is equivalent to f(x, y)\nx %&gt;% f %&gt;% g %&gt;% h is equivalent to h(g(f(x)))\n\nThe argument placeholder\n\nx %&gt;% f(y, .) is equivalent to f(y, x)\nx %&gt;% f(y, z = .) is equivalent to f(y, z = x)\n\n\n\n\n\n\n\n|&gt; native pipe operator\n\n\n\nIn new versions of R (&gt; 4.1.0), there is now a native pipe operator that comes within the syntax of R itself, rather than being loaded as a part of a separate package.\nAlthough they are largely the same, there are some meaningful differences between the two. These two articles from the tidyverse and Isabella VelÃ¡squez do a good job of explaining the differences relevant differences.\nI have started just using the native pipe (|&gt;) for almost all cases now. First, becuase it just looks cleaner. But also because then you can use a pipe without explicitly loading the mattingr package (_e.g.Â iris |&gt; dplyr::glimpse()). Where if you had used the magrittr pipe (%&gt;%), but not loaded the magrittr package, you would get an error.\n\n\n\n\n\nfoo_foo &lt;- little_bunny()\nfoo_foo_1 &lt;- hop(foo_foo, through = forest)\nfoo_foo_2 &lt;- scoop(foo_foo_1, up = field_mice)\nfoo_foo_3 &lt;- bop(foo_foo_2, on = head)\n\n\nfoo_foo |&gt;\n  hop(through = forest) |&gt;\n  scoop(up = field_mice) |&gt;\n  bop(on = head)\n\n\n\n\n\n\n# dat |&gt;\n#   arrange(tissue, iu_gfw)\n\n\n# dat |&gt;\n#   arrange(desc(tissue), desc(iu_gfw))\n\n\n\n\n\n# dat |&gt;\n#   summarise(iu_gfw_avg = mean(iu_gfw))\n\n\n\n\n\n# dat |&gt;\n#   group_by(tissue) |&gt;\n#   summarise(iu_gfw_avg = mean(iu_gfw),\n#             iu_gfw_sd = sd(iu_gfw))\n\nWarning that you must be careful about the order when reusing variable names.\n\n# # Bad order\n# dat |&gt;\n#   group_by(tissue) |&gt;\n#   summarise(iu_gfw = mean(iu_gfw),\n#             sd = sd(iu_gfw))\n\n\n# # This order works because it collapses the data into a mean last\n# dat |&gt;\n#   group_by(tissue) |&gt;\n#   summarise(sd = sd(iu_gfw),\n#             iu_gfw = mean(iu_gfw))\n\nPrint out a pretty table using kableExtra.\n\n\n\nFor the most part, I find myself working with 2D structured data (e.g., tibble or data.frame). But sometimes you need to\n\nChickWeight |&gt;\n  glimpse()\n\nRows: 578\nColumns: 4\n$ weight &lt;dbl&gt; 42, 51, 59, 64, 76, 93, 106, 125, 149, 171, 199, 205, 40, 49, 5â€¦\n$ Time   &lt;dbl&gt; 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 1â€¦\n$ Chick  &lt;ord&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, â€¦\n$ Diet   &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, â€¦\n\n\n\nChickWeight |&gt;\n  group_by(Chick, Diet) |&gt;\n  nest() \n\n# A tibble: 50 Ã— 3\n# Groups:   Chick, Diet [50]\n   Chick Diet  data             \n   &lt;ord&gt; &lt;fct&gt; &lt;list&gt;           \n 1 1     1     &lt;tibble [12 Ã— 2]&gt;\n 2 2     1     &lt;tibble [12 Ã— 2]&gt;\n 3 3     1     &lt;tibble [12 Ã— 2]&gt;\n 4 4     1     &lt;tibble [12 Ã— 2]&gt;\n 5 5     1     &lt;tibble [12 Ã— 2]&gt;\n 6 6     1     &lt;tibble [12 Ã— 2]&gt;\n 7 7     1     &lt;tibble [12 Ã— 2]&gt;\n 8 8     1     &lt;tibble [11 Ã— 2]&gt;\n 9 9     1     &lt;tibble [12 Ã— 2]&gt;\n10 10    1     &lt;tibble [12 Ã— 2]&gt;\n# â€¦ with 40 more rows\n\n\n\nChickWeight_nest &lt;- ChickWeight |&gt;\n  group_by(Chick, Diet) |&gt;\n  nest() \n\nChickWeight_nest$data[1:2]\n\n[[1]]\n# A tibble: 12 Ã— 2\n   weight  Time\n    &lt;dbl&gt; &lt;dbl&gt;\n 1     42     0\n 2     51     2\n 3     59     4\n 4     64     6\n 5     76     8\n 6     93    10\n 7    106    12\n 8    125    14\n 9    149    16\n10    171    18\n11    199    20\n12    205    21\n\n[[2]]\n# A tibble: 12 Ã— 2\n   weight  Time\n    &lt;dbl&gt; &lt;dbl&gt;\n 1     40     0\n 2     49     2\n 3     58     4\n 4     72     6\n 5     84     8\n 6    103    10\n 7    122    12\n 8    138    14\n 9    162    16\n10    187    18\n11    209    20\n12    215    21\n\n\n\n\n\n\n# Load library\nlibrary(broom)\n\nCheck out the broom vignette.\nAnd the broom and dplyr vignette.\ntidy: constructs a tibble that summarizes the modelâ€™s statistical findings. This includes coefficients and p-values for each term in a regression, per-cluster information in clustering applications, or per-test information for multtest functions.\nglance: construct a concise one-row summary of the model. This typically contains values such as R^2, adjusted R^2, and residual standard error that are computed once for the entire model.\n\nChickWeight |&gt;\n  group_by(Chick, Diet) |&gt;\n  nest() |&gt;\n  mutate(\n    fit = map(data, ~ lm(weight ~ Time, data = .x)),\n    tidied = map(fit, tidy),\n    glanced = map(fit, glance)\n  ) |&gt; \n  unnest(tidied) \n\n# A tibble: 100 Ã— 10\n# Groups:   Chick, Diet [50]\n   Chick Diet  data     fit    term    estimâ€¦Â¹ std.eâ€¦Â² statiâ€¦Â³  p.value glanced \n   &lt;ord&gt; &lt;fct&gt; &lt;list&gt;   &lt;list&gt; &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;list&gt;  \n 1 1     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   24.5    6.73     3.64 4.56e- 3 &lt;tibble&gt;\n 2 1     1     &lt;tibble&gt; &lt;lm&gt;   Time       7.99   0.524   15.3  2.97e- 8 &lt;tibble&gt;\n 3 2     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   24.7    4.93     5.01 5.26e- 4 &lt;tibble&gt;\n 4 2     1     &lt;tibble&gt; &lt;lm&gt;   Time       8.72   0.384   22.7  6.15e-10 &lt;tibble&gt;\n 5 3     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   23.2    5.08     4.56 1.04e- 3 &lt;tibble&gt;\n 6 3     1     &lt;tibble&gt; &lt;lm&gt;   Time       8.49   0.396   21.5  1.08e- 9 &lt;tibble&gt;\n 7 4     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   32.9    4.01     8.21 9.42e- 6 &lt;tibble&gt;\n 8 4     1     &lt;tibble&gt; &lt;lm&gt;   Time       6.09   0.312   19.5  2.70e- 9 &lt;tibble&gt;\n 9 5     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   16.9    7.56     2.24 4.93e- 2 &lt;tibble&gt;\n10 5     1     &lt;tibble&gt; &lt;lm&gt;   Time      10.1    0.588   17.1  9.88e- 9 &lt;tibble&gt;\n# â€¦ with 90 more rows, and abbreviated variable names Â¹â€‹estimate, Â²â€‹std.error,\n#   Â³â€‹statistic\n\n\n\nChickWeight |&gt;\n  ggplot() +\n  geom_line(aes(x = Time, \n                 y = weight, \n                 color = Chick)) +\n  facet_wrap(~ Diet)\n\n\n\n\n\n\n\n\nWickham, Hadley. 2014. â€œTidy Data.â€ J. Stat. Softw. 59 (September): 1â€“23."
  },
  {
    "objectID": "tidyverse.html#why-use-the-the-tidyverse",
    "href": "tidyverse.html#why-use-the-the-tidyverse",
    "title": "Tidyverse",
    "section": "",
    "text": "There are base R equivalents to most things that you can do in the tidyverse. So you might wonder why it is necessary, or even useful, to learn the tidyverse. I think that skepticism is fair, but here are a few reasons why I think you should not only learn the tidyverse, but make it a regular part of your workflow1.\n\nAs a data scientist, most of your time will be spent writing code, not waiting for code to execute. Therefore you should put more value the coding style that is easiest to write and understand. The tidyverse emphasizes human readable code.\nBecause of the flexible nature of some of the tidyverse functions, the tidyverse can make for more reproducible code, that is less likely to break if some of the underlying data has changed or been added too.\nAn increasing number of newly developed packages depend on the tidyverse. So you might as well embrace it.\nYou are already using it! If have made any figures in R, more likely than not, you are already used one tidyverse package, ggplot2.\n\n\n\n\n\n\n\n\n\nThe tidy tools manifesto\n\n\n\nMy favorite part of the tidyverse is the final principle in this manifesto:\n\nDesign for humans. â€œPrograms must be written for people to read, and only incidentally for machines to execute.â€ â€” Hal Abelson\n\n\n\nThe tidyverse style guide\n\nâ€œGood coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread.â€ 2\n\n\n\n\n\n\n\nCheat sheets\n\n\n\nTidyverse packages can help with many common tasks. Check out these cheat sheets for quick reference.\n\nData import\nData tidying\nData transformation\nData visualization\nFunctional programming\nStrings\nFactors\n\n\n\n\n# Load library\nlibrary(tidyverse)\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.0     âœ” readr     2.1.4\nâœ” forcats   1.0.0     âœ” stringr   1.5.0\nâœ” ggplot2   3.4.1     âœ” tibble    3.1.8\nâœ” lubridate 1.9.2     âœ” tidyr     1.3.0\nâœ” purrr     1.0.1     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\n\n\nRather than loading each package individually â€“ I often just load all of the core packages with the convenient library(tidyverse)3. Most of my scripts are dependent on at least three of the core packages, so it is easier to just have them all included. But you could load each individually."
  },
  {
    "objectID": "tidyverse.html#tidy-data",
    "href": "tidyverse.html#tidy-data",
    "title": "Tidyverse",
    "section": "",
    "text": "The tidyverse gets its name from the type of data that it is designed to interact with â€“ tidy data. So letâ€™s quickly define tidy data4.\n\n\n\n\n\n\nTidy data â€“ definition\n\n\n\n\nEvery column is a variable.\nEvery row is an observation.\nEvery cell is a single value.\n\n\n\nBut that definition is a bit abstract â€“ especially if you have never thought about whether data is messy or tidy before â€“ so letâ€™s try a practical example.\nBelow is some made-up messy data.\nImagine over the course of several days, you measure the height of a few plants\n\n# Make up some random data\ndat &lt;- tibble(\n  plant_id = 1:15,\n  week1 = rnorm(15, mean = 10, sd = 3),\n  week2 = week1*runif(15, min = 1, max = 1.5),\n  week3 = week2*runif(15, min = 1, max = 1.5),\n  week4 = week3*runif(15, min = 1, max = 1.5),\n  week5 = week4*runif(15, min = 1, max = 1.5)\n)\n\n# Print the data\ndat\n\n# A tibble: 15 Ã— 6\n   plant_id week1 week2 week3 week4 week5\n      &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1        1 12.3  18.2  19.7   24.6  26.7\n 2        2 11.8  17.2  21.1   24.4  32.2\n 3        3  9.63 14.1  18.0   24.5  29.5\n 4        4  7.52  9.25  9.62  14.4  15.0\n 5        5  9.27  9.50 10.9   15.4  19.0\n 6        6  8.02 11.0  15.8   16.6  22.6\n 7        7  8.05  8.62 12.3   15.8  19.6\n 8        8  7.43  8.65  8.68  11.4  13.9\n 9        9 12.0  16.6  18.1   26.2  32.9\n10       10 11.6  15.6  20.3   25.1  28.2\n11       11  5.64  7.77  7.86  10.2  12.5\n12       12 14.2  15.5  18.2   19.5  23.0\n13       13 11.5  14.4  20.8   24.6  32.9\n14       14  5.39  7.97 10.4   15.4  17.1\n15       15  9.12 13.5  14.8   16.2  20.7\n\n\n\n\n\ndat |&gt;\n  pivot_longer(contains(\"week\"),\n               names_to = \"week\",\n               values_to = \"height_cm\")\n\n# A tibble: 75 Ã— 3\n   plant_id week  height_cm\n      &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1        1 week1      12.3\n 2        1 week2      18.2\n 3        1 week3      19.7\n 4        1 week4      24.6\n 5        1 week5      26.7\n 6        2 week1      11.8\n 7        2 week2      17.2\n 8        2 week3      21.1\n 9        2 week4      24.4\n10        2 week5      32.2\n# â€¦ with 65 more rows\n\n\n\nBAM! That is tidy data. 1. Every column is a variable â€“ id, time, height. 2. Every row is an observation â€“ a height measurement on a single plant. 3. Every cell is a single value.\n\n\ndat |&gt;\n  pivot_longer(contains(\"week\"),\n               names_to = \"week\",\n               values_to = \"height_cm\") |&gt; \n  mutate(week = as.numeric(str_remove_all(week, \"week\")))\n\n# A tibble: 75 Ã— 3\n   plant_id  week height_cm\n      &lt;int&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1        1     1      12.3\n 2        1     2      18.2\n 3        1     3      19.7\n 4        1     4      24.6\n 5        1     5      26.7\n 6        2     1      11.8\n 7        2     2      17.2\n 8        2     3      21.1\n 9        2     4      24.4\n10        2     5      32.2\n# â€¦ with 65 more rows"
  },
  {
    "objectID": "tidyverse.html#advanced-techniques",
    "href": "tidyverse.html#advanced-techniques",
    "title": "Tidyverse",
    "section": "",
    "text": "broom â€“ clean model output â€“ technically a subpackage of tidymodels a cousin of the tidyverse\nrvest â€“ web scraping â€“ mining data from a website\nmodelr â€“ modelling â€“ support for modelling data in the tidyverse"
  },
  {
    "objectID": "tidyverse.html#importing-data",
    "href": "tidyverse.html#importing-data",
    "title": "Tidyverse",
    "section": "",
    "text": "I find it a lot easier to define the data structure as you import data. And it creates a tibble instead of data.frame.\nThere are several reasons to prefer readr::read_csv() over base Râ€™s read.csv."
  },
  {
    "objectID": "tidyverse.html#tools-for-quick-clean-up",
    "href": "tidyverse.html#tools-for-quick-clean-up",
    "title": "Tidyverse",
    "section": "",
    "text": "A hazard of caring about how coding in the tidyverse style, is that you will notice bad formatting everywhere.\n\n\n\n\n\nJanitor package\nCleaning up data\n\niris |&gt; \n  janitor::clean_names()\n\n    sepal_length sepal_width petal_length petal_width    species\n1            5.1         3.5          1.4         0.2     setosa\n2            4.9         3.0          1.4         0.2     setosa\n3            4.7         3.2          1.3         0.2     setosa\n4            4.6         3.1          1.5         0.2     setosa\n5            5.0         3.6          1.4         0.2     setosa\n6            5.4         3.9          1.7         0.4     setosa\n7            4.6         3.4          1.4         0.3     setosa\n8            5.0         3.4          1.5         0.2     setosa\n9            4.4         2.9          1.4         0.2     setosa\n10           4.9         3.1          1.5         0.1     setosa\n11           5.4         3.7          1.5         0.2     setosa\n12           4.8         3.4          1.6         0.2     setosa\n13           4.8         3.0          1.4         0.1     setosa\n14           4.3         3.0          1.1         0.1     setosa\n15           5.8         4.0          1.2         0.2     setosa\n16           5.7         4.4          1.5         0.4     setosa\n17           5.4         3.9          1.3         0.4     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.7         3.8          1.7         0.3     setosa\n20           5.1         3.8          1.5         0.3     setosa\n21           5.4         3.4          1.7         0.2     setosa\n22           5.1         3.7          1.5         0.4     setosa\n23           4.6         3.6          1.0         0.2     setosa\n24           5.1         3.3          1.7         0.5     setosa\n25           4.8         3.4          1.9         0.2     setosa\n26           5.0         3.0          1.6         0.2     setosa\n27           5.0         3.4          1.6         0.4     setosa\n28           5.2         3.5          1.5         0.2     setosa\n29           5.2         3.4          1.4         0.2     setosa\n30           4.7         3.2          1.6         0.2     setosa\n31           4.8         3.1          1.6         0.2     setosa\n32           5.4         3.4          1.5         0.4     setosa\n33           5.2         4.1          1.5         0.1     setosa\n34           5.5         4.2          1.4         0.2     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.0         3.2          1.2         0.2     setosa\n37           5.5         3.5          1.3         0.2     setosa\n38           4.9         3.6          1.4         0.1     setosa\n39           4.4         3.0          1.3         0.2     setosa\n40           5.1         3.4          1.5         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n42           4.5         2.3          1.3         0.3     setosa\n43           4.4         3.2          1.3         0.2     setosa\n44           5.0         3.5          1.6         0.6     setosa\n45           5.1         3.8          1.9         0.4     setosa\n46           4.8         3.0          1.4         0.3     setosa\n47           5.1         3.8          1.6         0.2     setosa\n48           4.6         3.2          1.4         0.2     setosa\n49           5.3         3.7          1.5         0.2     setosa\n50           5.0         3.3          1.4         0.2     setosa\n51           7.0         3.2          4.7         1.4 versicolor\n52           6.4         3.2          4.5         1.5 versicolor\n53           6.9         3.1          4.9         1.5 versicolor\n54           5.5         2.3          4.0         1.3 versicolor\n55           6.5         2.8          4.6         1.5 versicolor\n56           5.7         2.8          4.5         1.3 versicolor\n57           6.3         3.3          4.7         1.6 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n59           6.6         2.9          4.6         1.3 versicolor\n60           5.2         2.7          3.9         1.4 versicolor\n61           5.0         2.0          3.5         1.0 versicolor\n62           5.9         3.0          4.2         1.5 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.9          4.7         1.4 versicolor\n65           5.6         2.9          3.6         1.3 versicolor\n66           6.7         3.1          4.4         1.4 versicolor\n67           5.6         3.0          4.5         1.5 versicolor\n68           5.8         2.7          4.1         1.0 versicolor\n69           6.2         2.2          4.5         1.5 versicolor\n70           5.6         2.5          3.9         1.1 versicolor\n71           5.9         3.2          4.8         1.8 versicolor\n72           6.1         2.8          4.0         1.3 versicolor\n73           6.3         2.5          4.9         1.5 versicolor\n74           6.1         2.8          4.7         1.2 versicolor\n75           6.4         2.9          4.3         1.3 versicolor\n76           6.6         3.0          4.4         1.4 versicolor\n77           6.8         2.8          4.8         1.4 versicolor\n78           6.7         3.0          5.0         1.7 versicolor\n79           6.0         2.9          4.5         1.5 versicolor\n80           5.7         2.6          3.5         1.0 versicolor\n81           5.5         2.4          3.8         1.1 versicolor\n82           5.5         2.4          3.7         1.0 versicolor\n83           5.8         2.7          3.9         1.2 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           6.7         3.1          4.7         1.5 versicolor\n88           6.3         2.3          4.4         1.3 versicolor\n89           5.6         3.0          4.1         1.3 versicolor\n90           5.5         2.5          4.0         1.3 versicolor\n91           5.5         2.6          4.4         1.2 versicolor\n92           6.1         3.0          4.6         1.4 versicolor\n93           5.8         2.6          4.0         1.2 versicolor\n94           5.0         2.3          3.3         1.0 versicolor\n95           5.6         2.7          4.2         1.3 versicolor\n96           5.7         3.0          4.2         1.2 versicolor\n97           5.7         2.9          4.2         1.3 versicolor\n98           6.2         2.9          4.3         1.3 versicolor\n99           5.1         2.5          3.0         1.1 versicolor\n100          5.7         2.8          4.1         1.3 versicolor\n101          6.3         3.3          6.0         2.5  virginica\n102          5.8         2.7          5.1         1.9  virginica\n103          7.1         3.0          5.9         2.1  virginica\n104          6.3         2.9          5.6         1.8  virginica\n105          6.5         3.0          5.8         2.2  virginica\n106          7.6         3.0          6.6         2.1  virginica\n107          4.9         2.5          4.5         1.7  virginica\n108          7.3         2.9          6.3         1.8  virginica\n109          6.7         2.5          5.8         1.8  virginica\n110          7.2         3.6          6.1         2.5  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          6.4         2.7          5.3         1.9  virginica\n113          6.8         3.0          5.5         2.1  virginica\n114          5.7         2.5          5.0         2.0  virginica\n115          5.8         2.8          5.1         2.4  virginica\n116          6.4         3.2          5.3         2.3  virginica\n117          6.5         3.0          5.5         1.8  virginica\n118          7.7         3.8          6.7         2.2  virginica\n119          7.7         2.6          6.9         2.3  virginica\n120          6.0         2.2          5.0         1.5  virginica\n121          6.9         3.2          5.7         2.3  virginica\n122          5.6         2.8          4.9         2.0  virginica\n123          7.7         2.8          6.7         2.0  virginica\n124          6.3         2.7          4.9         1.8  virginica\n125          6.7         3.3          5.7         2.1  virginica\n126          7.2         3.2          6.0         1.8  virginica\n127          6.2         2.8          4.8         1.8  virginica\n128          6.1         3.0          4.9         1.8  virginica\n129          6.4         2.8          5.6         2.1  virginica\n130          7.2         3.0          5.8         1.6  virginica\n131          7.4         2.8          6.1         1.9  virginica\n132          7.9         3.8          6.4         2.0  virginica\n133          6.4         2.8          5.6         2.2  virginica\n134          6.3         2.8          5.1         1.5  virginica\n135          6.1         2.6          5.6         1.4  virginica\n136          7.7         3.0          6.1         2.3  virginica\n137          6.3         3.4          5.6         2.4  virginica\n138          6.4         3.1          5.5         1.8  virginica\n139          6.0         3.0          4.8         1.8  virginica\n140          6.9         3.1          5.4         2.1  virginica\n141          6.7         3.1          5.6         2.4  virginica\n142          6.9         3.1          5.1         2.3  virginica\n143          5.8         2.7          5.1         1.9  virginica\n144          6.8         3.2          5.9         2.3  virginica\n145          6.7         3.3          5.7         2.5  virginica\n146          6.7         3.0          5.2         2.3  virginica\n147          6.3         2.5          5.0         1.9  virginica\n148          6.5         3.0          5.2         2.0  virginica\n149          6.2         3.4          5.4         2.3  virginica\n150          5.9         3.0          5.1         1.8  virginica\n\n\n\n# Create a .csv file to import\nwrite_csv(iris, \"iris.csv\")\n\n\n# Try read.csv\nd.f &lt;- read.csv(\"iris.csv\")\n\nstr(d.f)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : chr  \"setosa\" \"setosa\" \"setosa\" \"setosa\" ...\n\n\n\n# Try read_csv\nread_csv(\"iris.csv\")\n\nRows: 150 Columns: 5\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (1): Species\ndbl (4): Sepal.Length, Sepal.Width, Petal.Length, Petal.Width\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 150 Ã— 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# â€¦ with 140 more rows\n\n# Set col_type as you import data -- allows you to define level order too\nd_f &lt;- read_csv(\"iris.csv\",\n                col_types = list(Species = col_factor(c(\"versicolor\",\n                                                        \"setosa\", \n                                                        \"virginica\"))))\nd_f\n\n# A tibble: 150 Ã— 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# â€¦ with 140 more rows\n\nstr(d_f)\n\nspc_tbl_ [150 Ã— 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Sepal.Length: num [1:150] 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num [1:150] 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num [1:150] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num [1:150] 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"versicolor\",\"setosa\",..: 2 2 2 2 2 2 2 2 2 2 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Sepal.Length = col_double(),\n  ..   Sepal.Width = col_double(),\n  ..   Petal.Length = col_double(),\n  ..   Petal.Width = col_double(),\n  ..   Species = col_factor(levels = c(\"versicolor\", \"setosa\", \"virginica\"), ordered = FALSE, include_na = FALSE)\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nglimpse(d_f)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.â€¦\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.â€¦\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.â€¦\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.â€¦\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, sâ€¦"
  },
  {
    "objectID": "tidyverse.html#wrangling-data",
    "href": "tidyverse.html#wrangling-data",
    "title": "Tidyverse",
    "section": "",
    "text": "dplyr has a few core functions that are built to work on\nTaken from the dplyr vignette.\n\n\n\nfilter() chooses rows based on column values.\nslice() chooses rows based on location.\narrange() changes the order of the rows.\n\n\n\n\n\nselect() changes whether or not a column is included.\nrename() changes the name of columns.\nmutate() changes the values of columns and creates new columns.\nrelocate() changes the order of the columns.\n\n\n\n\n\nsummarise() collapses a group into a single row.\n\n\n\n\n\nFrom magrittr.\n\nx %&gt;% f is equivalent to f(x)\nx %&gt;% f(y) is equivalent to f(x, y)\nx %&gt;% f %&gt;% g %&gt;% h is equivalent to h(g(f(x)))\n\nThe argument placeholder\n\nx %&gt;% f(y, .) is equivalent to f(y, x)\nx %&gt;% f(y, z = .) is equivalent to f(y, z = x)\n\n\n\n\n\n\n\n|&gt; native pipe operator\n\n\n\nIn new versions of R (&gt; 4.1.0), there is now a native pipe operator that comes within the syntax of R itself, rather than being loaded as a part of a separate package.\nAlthough they are largely the same, there are some meaningful differences between the two. These two articles from the tidyverse and Isabella VelÃ¡squez do a good job of explaining the differences relevant differences.\nI have started just using the native pipe (|&gt;) for almost all cases now. First, becuase it just looks cleaner. But also because then you can use a pipe without explicitly loading the mattingr package (_e.g.Â iris |&gt; dplyr::glimpse()). Where if you had used the magrittr pipe (%&gt;%), but not loaded the magrittr package, you would get an error.\n\n\n\n\n\nfoo_foo &lt;- little_bunny()\nfoo_foo_1 &lt;- hop(foo_foo, through = forest)\nfoo_foo_2 &lt;- scoop(foo_foo_1, up = field_mice)\nfoo_foo_3 &lt;- bop(foo_foo_2, on = head)\n\n\nfoo_foo |&gt;\n  hop(through = forest) |&gt;\n  scoop(up = field_mice) |&gt;\n  bop(on = head)\n\n\n\n\n\n\n# dat |&gt;\n#   arrange(tissue, iu_gfw)\n\n\n# dat |&gt;\n#   arrange(desc(tissue), desc(iu_gfw))\n\n\n\n\n\n# dat |&gt;\n#   summarise(iu_gfw_avg = mean(iu_gfw))\n\n\n\n\n\n# dat |&gt;\n#   group_by(tissue) |&gt;\n#   summarise(iu_gfw_avg = mean(iu_gfw),\n#             iu_gfw_sd = sd(iu_gfw))\n\nWarning that you must be careful about the order when reusing variable names.\n\n# # Bad order\n# dat |&gt;\n#   group_by(tissue) |&gt;\n#   summarise(iu_gfw = mean(iu_gfw),\n#             sd = sd(iu_gfw))\n\n\n# # This order works because it collapses the data into a mean last\n# dat |&gt;\n#   group_by(tissue) |&gt;\n#   summarise(sd = sd(iu_gfw),\n#             iu_gfw = mean(iu_gfw))\n\nPrint out a pretty table using kableExtra.\n\n\n\nFor the most part, I find myself working with 2D structured data (e.g., tibble or data.frame). But sometimes you need to\n\nChickWeight |&gt;\n  glimpse()\n\nRows: 578\nColumns: 4\n$ weight &lt;dbl&gt; 42, 51, 59, 64, 76, 93, 106, 125, 149, 171, 199, 205, 40, 49, 5â€¦\n$ Time   &lt;dbl&gt; 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 1â€¦\n$ Chick  &lt;ord&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, â€¦\n$ Diet   &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, â€¦\n\n\n\nChickWeight |&gt;\n  group_by(Chick, Diet) |&gt;\n  nest() \n\n# A tibble: 50 Ã— 3\n# Groups:   Chick, Diet [50]\n   Chick Diet  data             \n   &lt;ord&gt; &lt;fct&gt; &lt;list&gt;           \n 1 1     1     &lt;tibble [12 Ã— 2]&gt;\n 2 2     1     &lt;tibble [12 Ã— 2]&gt;\n 3 3     1     &lt;tibble [12 Ã— 2]&gt;\n 4 4     1     &lt;tibble [12 Ã— 2]&gt;\n 5 5     1     &lt;tibble [12 Ã— 2]&gt;\n 6 6     1     &lt;tibble [12 Ã— 2]&gt;\n 7 7     1     &lt;tibble [12 Ã— 2]&gt;\n 8 8     1     &lt;tibble [11 Ã— 2]&gt;\n 9 9     1     &lt;tibble [12 Ã— 2]&gt;\n10 10    1     &lt;tibble [12 Ã— 2]&gt;\n# â€¦ with 40 more rows\n\n\n\nChickWeight_nest &lt;- ChickWeight |&gt;\n  group_by(Chick, Diet) |&gt;\n  nest() \n\nChickWeight_nest$data[1:2]\n\n[[1]]\n# A tibble: 12 Ã— 2\n   weight  Time\n    &lt;dbl&gt; &lt;dbl&gt;\n 1     42     0\n 2     51     2\n 3     59     4\n 4     64     6\n 5     76     8\n 6     93    10\n 7    106    12\n 8    125    14\n 9    149    16\n10    171    18\n11    199    20\n12    205    21\n\n[[2]]\n# A tibble: 12 Ã— 2\n   weight  Time\n    &lt;dbl&gt; &lt;dbl&gt;\n 1     40     0\n 2     49     2\n 3     58     4\n 4     72     6\n 5     84     8\n 6    103    10\n 7    122    12\n 8    138    14\n 9    162    16\n10    187    18\n11    209    20\n12    215    21\n\n\n\n\n\n\n# Load library\nlibrary(broom)\n\nCheck out the broom vignette.\nAnd the broom and dplyr vignette.\ntidy: constructs a tibble that summarizes the modelâ€™s statistical findings. This includes coefficients and p-values for each term in a regression, per-cluster information in clustering applications, or per-test information for multtest functions.\nglance: construct a concise one-row summary of the model. This typically contains values such as R^2, adjusted R^2, and residual standard error that are computed once for the entire model.\n\nChickWeight |&gt;\n  group_by(Chick, Diet) |&gt;\n  nest() |&gt;\n  mutate(\n    fit = map(data, ~ lm(weight ~ Time, data = .x)),\n    tidied = map(fit, tidy),\n    glanced = map(fit, glance)\n  ) |&gt; \n  unnest(tidied) \n\n# A tibble: 100 Ã— 10\n# Groups:   Chick, Diet [50]\n   Chick Diet  data     fit    term    estimâ€¦Â¹ std.eâ€¦Â² statiâ€¦Â³  p.value glanced \n   &lt;ord&gt; &lt;fct&gt; &lt;list&gt;   &lt;list&gt; &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;list&gt;  \n 1 1     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   24.5    6.73     3.64 4.56e- 3 &lt;tibble&gt;\n 2 1     1     &lt;tibble&gt; &lt;lm&gt;   Time       7.99   0.524   15.3  2.97e- 8 &lt;tibble&gt;\n 3 2     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   24.7    4.93     5.01 5.26e- 4 &lt;tibble&gt;\n 4 2     1     &lt;tibble&gt; &lt;lm&gt;   Time       8.72   0.384   22.7  6.15e-10 &lt;tibble&gt;\n 5 3     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   23.2    5.08     4.56 1.04e- 3 &lt;tibble&gt;\n 6 3     1     &lt;tibble&gt; &lt;lm&gt;   Time       8.49   0.396   21.5  1.08e- 9 &lt;tibble&gt;\n 7 4     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   32.9    4.01     8.21 9.42e- 6 &lt;tibble&gt;\n 8 4     1     &lt;tibble&gt; &lt;lm&gt;   Time       6.09   0.312   19.5  2.70e- 9 &lt;tibble&gt;\n 9 5     1     &lt;tibble&gt; &lt;lm&gt;   (Interâ€¦   16.9    7.56     2.24 4.93e- 2 &lt;tibble&gt;\n10 5     1     &lt;tibble&gt; &lt;lm&gt;   Time      10.1    0.588   17.1  9.88e- 9 &lt;tibble&gt;\n# â€¦ with 90 more rows, and abbreviated variable names Â¹â€‹estimate, Â²â€‹std.error,\n#   Â³â€‹statistic\n\n\n\nChickWeight |&gt;\n  ggplot() +\n  geom_line(aes(x = Time, \n                 y = weight, \n                 color = Chick)) +\n  facet_wrap(~ Diet)\n\n\n\n\n\n\n\n\nWickham, Hadley. 2014. â€œTidy Data.â€ J. Stat. Softw. 59 (September): 1â€“23."
  },
  {
    "objectID": "tidyverse.html#footnotes",
    "href": "tidyverse.html#footnotes",
    "title": "Tidyverse",
    "section": "",
    "text": "Maybe even convert some of your old scripts to incorporate the tidyverse.â†©ï¸\nHonestly I think that joke underestimates how important good coding style is. You can actually read â€œbutitsuremakesthingseasiertoreadâ€ pretty easily because you are an expert reader â€“ youâ€™ve been at it everyday for decades â€“ coding, probably not so much. I donâ€™t think can overstate how important I think it is to write visually pleasing code.â†©ï¸\nNotice above that this function call loads nine core tidyverse packages. Any other tidyverse packages, including some we will cover later (e.g., broom), must be loaded separately.â†©ï¸\nWickham (2014)â†©ï¸"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "References"
  }
]