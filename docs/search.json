[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science Workshop",
    "section": "",
    "text": "Welcome\nThank you for checking out this workshop! This page contains a brief overview of the goals, structure, and prerequisites of the workshop."
  },
  {
    "objectID": "index.html#goals",
    "href": "index.html#goals",
    "title": "Data Science Workshop",
    "section": "Goals",
    "text": "Goals\nAs an open-source programming language, there is an abundance of approaches to doing data science in R. It is a wide open landscape ready for your exploration! But — to extend this metaphor to its breaking point — it isn’t just a flat landscape, where each spot is as fertile as the next. It is more complicated. Its closer to a fitness landscape where there are hidden local and global optima 1. You are encouraged to explore that space for yourself – find the high points and low points – what works best for you and what doesn’t2. But it is my hope that this workshop will serve as a useful initialization of your search of that complex adaptive landscape. And that along the way you will gain tools which will help you dig out of those valleys and climb to the top of those peaks. I have the following high-level goals for this workshop:\n\nEncourage best practices to ensure computational reproducibility. Reproducibility is not just necessary for good science – it will save you and your collaborators a lot of time in the long run. Making sure your code is reproducible is not as difficult as it may seem.\nFoster an appreciation of the tidyverse and its underlying principles. Tools in R, and many other programming languages, are constantly evolving and that can make learning new tools seem futile. Especially if you already have something functional with a different set of tools. But the tidyverse, is likely to stick around, and it also represents something beyond a set of tools. It worth thinking about as a philosophy of programming that can help us write more useful and readable code.\nPersuade you to go beyond a graph that merely gets the job done and toward a version that most clearly communicates the story behind your data. There are many ways to represent data in graphical form. Each time we create a figure we are making dozens – or maybe hundreds – of choices. Some choices are passive3, and some are active4, and some may have little effect5, but I hope to convince you that spending some additional time iterating figures that you will share is well worth it."
  },
  {
    "objectID": "index.html#structure",
    "href": "index.html#structure",
    "title": "Data Science Workshop",
    "section": "Structure",
    "text": "Structure\nThere are three parts to this workshop. But each is designed to be self-contained – so you may pick-and-choose to attend any or all of these workshops. The three parts are as follows:\n\nComputational reproducibility\nPrinciples of the tidyverse and advanced techniques\nData visualization for presentations and publications"
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "Data Science Workshop",
    "section": "Prerequisites",
    "text": "Prerequisites\nThis workshop assumes several things6:\n\nYou have R and RStudio installed on your machine and you come ready to follow along with some coding.\nYou have some basic familiarity with coding in R. For example, you know the difference between a vector and a data frame.\nYou are able to do some simple tasks in R – like creating an object, getting the mean of a vector, or importing a csv file.\n\n\n\n\n\n\n\nGood news if you are starting from zero\n\n\n\nYou can meet the above criteria in less than a day!\nThere are several great resources on the internet that will walk you through downloading R and R Studio and give you the basics. You will not need much experience at all for our workshop – just a familiarity with the basics. Due to our limited time, and the wealth of resources covering step zero, we will start at step one and hit the ground running.\n\nResources if you are starting out – or need a quick refresh\n\nR for Graduate Students – very accessible introduction to R & the tidyverse\nR for Data Science – a wonderfully thorough and useful book that emphasizes the tidyverse"
  },
  {
    "objectID": "index.html#disclaimer",
    "href": "index.html#disclaimer",
    "title": "Data Science Workshop",
    "section": "Disclaimer",
    "text": "Disclaimer\nThe following workshop contains my opinions on learning R and programming in general. I am no expert – so please feel free to disagree with me on anything. In general, this workshop is designed to give you some exposure to a few useful topics, but it is by necessity incomplete. Very little, if any, of this workshop is uniquely mine. Instead, over the years, I have compiled a bunch of useful nuggets from other places. And I have packaged those nuggets here to fit within the scope this workshop. But, I strongly encourage you to check out those alternative7 resources. They are linked below and throughout this document. Therefore, I hope this tutorial will be useful, if through nothing else, as a portal to more useful parts of the internet.\n\n\n\n\n\n\nAlternative resources\n\n\n\n\nR for Data Science – a wonderfully thorough and useful book that emphasizes the tidyverse\nR for Graduate Students – very accessible introduction to R & the tidyverse\nFundamentals of Data Visualization – “A guide to making visualizations that accurately reflect the data, tell a story, and look professional.” by Claus O. Wilke. This book is great, because it is not at all about programming, but just how to make the best data visualizations.\nAdvanced R – R with the nitty-gritty details for the super nerds out there.\nggplot2 book – detailed introduction to plotting with ggplot2\nLearning Statistics with R – great book with an emphasis on stats\nR Markdown: The Definitive Guide – great overview of the features of R Markdown\nR Markdown Cookbook – additional R Markdown guide\nHappy Git and GitHub for the useR – resource for version control\nNick Gotelli’s Computational Biology – a wonderful course on R taught by Nick Gotelli at UVM."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Data Science Workshop",
    "section": "",
    "text": "↩︎\nI am not claiming to have found the global optimum of data science. I promise I would share the secret if I had it.↩︎\nlike keeping the default theme – yikes!↩︎\nShould I use a box plot, strip chart, or violin plot?↩︎\nI confess I have spent way to much time trying to find the most pleasing shade of purple.↩︎\nThese prerequisites are intentionally designed to be a relatively low bar. See the green box if you don’t meet these prerequisites.↩︎\nread: better↩︎"
  },
  {
    "objectID": "repro.html#practical-reproducibility",
    "href": "repro.html#practical-reproducibility",
    "title": "1  Reproducibility",
    "section": "1.1 Practical reproducibility",
    "text": "1.1 Practical reproducibility\nMuch of the advice on computational reproducibility is somewhat abstract6. That is, in part, the nature of the beast. Each project represents its own unique challenges. But it is also because the advice is often made for a broad range of projects in all sorts of different programming languages on everything from model simulations to genome assembly, all the way to creating programmatic tools for others. In contrast, this workshop will focus on a narrower set of tasks related to statistical programming in R7. In other words, the type of programming where you have some raw data generated elsewhere (e.g., enzyme activity or species abundance data) that you are going to preform some sort of analysis on it (e.g., normalization and a significance test), and then make figures.\n\n\n\n\n\n\nTL;DR - Practical tips for computational reproducibility 8\n\n\n\n\n\n\nR & RStudio specific tips\n\nUse the “Projects” feature in R.\nDo not save .RData on exit, and do not restore .RData on open. You can change this default behavior in RStudio in the Global Options.\nUse the built in version control tools. There are easy ways to interact with Git and GitHub with the RStudio IDE.\nUse the tidyverse packages! See the tidyverse chapter of this workshop.\n\n\n\nRepository tips\n\nUse a consistent directory structure. You can save this structure as a template and begin from there, rather than build each project from scratch.\nUse sub-directories. Favor a highly nested directory structure, over a directory with dozens of files with long and repetative names. If you find yourself making a bunch of files with the same prefix, that probably means that they should all be in their own directory.\nAdd a number prefix to your scripts (and possible directories), so it is clear which order they must be run 01_normalize_data.R.\nYou can have directory structures that mirror each other – this makes it easier to know where the relevant info is saved. For example, the data from data/raw/pheno/2023-07-04_data.csv could be analyzed in a script in src/pheno/01_anova.R, and the output could be saved in output/pheno/anova_results.rds and the corresponding figure saved in output/figs/pheno/boxplot.pdf.\n\n\n\nScript writing\n\nEvery script should be able to run without errors from top to bottom (i.e., in R, source(file_name.R) or clicking the source button in RStudio should always work when you save a file).\nWhen you are using multiple packages with overlapping function names, the order that you load the libraries can matter. If you have this make sure you can\nThe order of each script should make sense and be consistent (e.g., description, load packages, load data, manipulate data, save data). If you find yourself violating this rule. Loading packages later in a script or multiple saves of data intermediates within a file, it may make sense to split up the script. See next tip.\nFavor small scripts that are focused on a single task, over big scripts that do many things.\nYou should be able to run every script with a completely clean global environment.\nDevelop a consistent coding style (e.g., snake_case, indents, comments)\nYou should be able to clone the parent directory of the project and run the scripts – without any alteration, on any machine.\n\n\n\nData handling\n\nAvoid any manual manipulation of data (i.e., don’t mess around copy-and-pasting or editing raw data, change it reproducibly with code).\nSave output automatically by writing it into the code (e.g., saveRDS(), readr::write_csv(), ggsave()).\nSave intermediate data. If you are starting with a big data set, it is nice save that intermediate so a collaborator (or you in the future, or some random researcher on the internet), can re-do an intermediate step rather than begin from raw data. If they want to know how different you results would look normalized your data in a different way\n\n\n\nRandom pet-peeves\n\nDon’t copy and paste output into R scripts. If you need to save an output table, then write it to a csv or save it as an .rds file. If you need quick access to some intermediary info then use RMarkdown or Quarto to create .html reports.\nDon’t include anything that isn’t necessary in your code.\nOpt for long and explicit variable or function names over short and implicit names.\nUse a driver script that automates the entire workflow in a single script call.\nDo not save install.packages(\"some_package\") in your script – even if it is commented out. If in the future, you happen to have a new machine that doesn’t have some_package installed, you will remember how to install it. This is something that can just be run directly in the console, when necessary, and does not need to be saved in the script.\n\n\n\nVersion control\n\nCommit and push relatively often. This makes your commit history a useful record the changes you have made. It also makes it less likely that you will run into issues pushing and pulling. Or at least less traumatic if you do run into issues.\nAlways pull first – just in case your local state is a little behind.\nDon’t commit large files (e.g., raw data or large pdf figures) to version control. The software usually has limits."
  },
  {
    "objectID": "repro.html#ten-simple-rules",
    "href": "repro.html#ten-simple-rules",
    "title": "1  Reproducibility",
    "section": "1.2 Ten simple rules",
    "text": "1.2 Ten simple rules\nThe tips outlined above are a useful and specific starting point9. But rather than rely solely on my eccentricities, let’s instead adopt these simple rules from Sandve et al. (2013). Over the course of this workshop, we will look at some specific coding practices and think about how they may violate, or adhere to, one (or more) of these rules. The additional benefit of adpoting these rules is that they are easy enough to apply to other types of projects. It is worth reading in full.\n\n\n\n\n\n\nTen simple rules for reproducible computational research\n\n\n\n\nFor every result, keep track of how it was produced\nAvoid manual data manipulation steps\nArchive the exact versions of all external programs used\nVersion control all custom scripts\nRecord all intermediate results, when possible in standardized formats\nFor analyses that include randomness, note underlying random seeds\nAlways store raw data behind plots\nGenerate hierarchical analysis output, allowing layers of increasing detail to be inspected\nConnect textual statements to underlying results\nProvide public access to scripts, runs, and results"
  },
  {
    "objectID": "repro.html#opening-in-rstudio",
    "href": "repro.html#opening-in-rstudio",
    "title": "1  Reproducibility",
    "section": "1.3 Opening in RStudio",
    "text": "1.3 Opening in RStudio\nOkay, let’s begin by opening up RStudio10. Do you have objects already in your Global Environment? Is the console full of code you ran last time? Or do you always keep RStudio running, because you are worried about loosing the results you finally managed to get, and you need to do more stuff later?\nI know people that do great work in R and live their lives like this – but it kinda makes me sweat. How do you know what is real? What if those objects were created under some other conditions and you have since edited your script? How many packages do you have loaded? What are they?11 It stresses me out, in part because you are violating Rule 1 – you don’t necessarily have a good track record of how that object was produced. It could me something that you ran into the console long ago and you have since changed your script. You want your source of truth12 to be the script. In other words, the list of specfic commands that take you from raw data to your results. Zombie objects in the Global Environment are not your friend.\nIt is best practice to start with a blank slate every time you open RStudio. This will force you to rely solely on the code infront of you. Rather than something that may or may not be what you remember it to be. It also mimics the environment of someone else, sitting down at their own machine, trying to replicate your results – getting closer to ensuring reproducibility.\n\n\n\n\n\n\nTip\n\n\n\nThere is actually an easy way to set up a blank slate as RStudio’s default behavior. Just execute usethis::use_blank_slate() in the console and it will ensure that the Global Options of RStudio are configured in such a way that you have a blank slate each time you open R. Alternatively, you can manually adjust the Global Options as explained here."
  },
  {
    "objectID": "repro.html#projects-in-rstudio",
    "href": "repro.html#projects-in-rstudio",
    "title": "1  Reproducibility",
    "section": "1.4 Projects in RStudio",
    "text": "1.4 Projects in RStudio\nProjects are your friend. Jenny Bryan, a developer at RStudio, has an impassioned blog post on why you should embrace a project-oriented workflow. You should probably read her post in full, because if you don’t listen, she is threatening to set your computer on fire 🔥. But seriously, you should read it.\nAs a way of quickly summarizing one of her points: you should make sure that your final product (i.e., your script) is completely free of things that are specific to your own personal habits. For example, do you have something similar to setwd(\"/Users/tsoleary/R/quest_workshop_2023\") at the start of your script? Or in some other way, are you using absolute paths? If you do, then for a certainty if someone else wants to run your code, they will have to edit it to make sure they don’t immediately run into an error. This means that right off the bat, your code is not reproducibility-friendly. As a remedy, she suggests using projects and the here package discussed below.\n\nhere package\nThe here package is a great way to make sure that your code can be run easily on someone else’s machine. Jenny Bryan has another post dedicated specifically to the here package: read it here.\nWhat I like about it is that it allows you to easily separate out the file and the directory that you want to place it in – see below:\n\n# Load data\ndat &lt;- read_csv(here::here(\"data/raw/counts.csv\"))\n\n\n\n\n\n\n\nhere::here\n\n\n\nAs you’ll notice above rather than load the here package with library(here) and then use the here() function, I use the package::function_name notation to call the here function without attaching the whole here package. The added bonus is that it is kinda fun to say Here, Here! 🍺\n\n\nI find the here package very useful for working with RMarkdown documents. By default, RMarkdown documents often use what ever directory that document is in as its root directory, so then all relative paths are in relation to where ever that RMarkdown document happens to be. But the here package allows you to continue to use the project root for your relative paths!\n\n\n\n\n\n\nTip\n\n\n\nProjects in RStudio allows for easy integration with Version Control! Check out the short Section 1.7 on Version Control."
  },
  {
    "objectID": "repro.html#directory-structure",
    "href": "repro.html#directory-structure",
    "title": "1  Reproducibility",
    "section": "1.5 Directory structure",
    "text": "1.5 Directory structure\nThere are thousands of ways you could structure your files in a project – but there are really only two ways of going about it. The first is ad hoc. You group up files in sub-directores as you go along, tailoring the directory structure into something that makes sense to you, or at least something that is workable. And the other way, is to use a backbone template directory struture and build off that.\nFor most of the time I have worked in R, I have used the ad hoc approach. And it the best I can say for it is that it works. In my eyes, each project is its own snowflake. But if you ask someone else to look at it, they may think a dungeon maze or London Below13 is more apt a metaphor. But I have come to embrace a consistent directory structure.\nhttps://www.r-bloggers.com/2018/08/structuring-r-projects/\n\nTemplateExample\n\n\n├── src/\n│   ├── 01_analysis/\n│   ├── 02_analysis/\n│   ├── 03_figures/\n├── data/\n│   ├── raw/\n│   ├── processed/\n├── docs/\n│   ├── index.qmd\n├── output/\n│   ├── figs/\n│   ├── tables/\n├── scratch/\n├── README.md\n└── .gitignore\n\n\n├── src/\n│   ├── 00_pheno/\n│   │   ├── 00_pheno.R\n│   ├── 01_nuclei/\n│   │   ├── 00_count_nuclei.ijm\n│   ├── 02_cellranger-arc/\n│   │   ├── 00_mkref.sh\n│   │   ├── 01_count.sh\n│   │   ├── 02_aggr.sh\n│   ├── 03_seurat/\n│   │   ├── 00_create_seurat_object.R\n│   │   ├── 01_quality_control_filtering.R\n│   │   ├── 02_initial_cluster.R\n│   ├── 04_plots/\n│   │   ├── annot.R\n│   │   ├── cluster.R\n│   │   ├── final.R\n├── data/\n│   ├── raw/\n│   │   ├── annot/\n|   |   │   ├── calderon_markers.csv\n|   |   │   ├── dmel_cell-cycle_genes.csv\n|   |   │   ├── insitu_annot.csv\n│   │   ├── nuclei/\n│   │   ├── pheno/\n│   │   ├── seq/\n│   ├── processed/\n|   |   │   ├── annot.rds\n|   |   │   ├── cluster_all.rds\n|   |   │   ├── cluster_manual.rds\n│   │   ├── annot/\n│   │   ├── genes/\n│   │   ├── seq/\n│   │   ├── seurat_object/\n|   |   │   ├── 00_dat_raw.rds\n|   |   │   ├── 01_dat_qc.rds\n|   |   │   ├── 02_dat_clust.rds\n├── docs/\n│   ├── index.qmd\n├── output/\n│   ├── figs/\n|   │   ├── annot/\n|   |   │   ├── umap.pdf\n|   |   │   ├── tsne.pdf\n|   │   ├── cluster/\n|   |   │   ├── umap.pdf\n|   |   │   ├── tsne.pdf\n|   │   ├── final/\n|   |   │   ├── fig_1.pdf\n|   |   │   ├── fig_2.pdf\n|   |   │   ├── fig_3.pdf\n│   ├── tables/\n│   ├── dars/\n|   │   ├── cell_type.rds\n|   │   ├── cluster.rds\n│   ├── degs/\n|   │   ├── cell_type.rds\n|   │   ├── cluster.rds\n├── scratch/\n├── README.md\n└── .gitignore\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you use Version Control this sort of directory structure is also helpful because you can easily mark entire directories to be ignored (e.g., including data/* our output/figs/* in the .gitignore file). Most version control software will have a file size limit. Anyway, the thing you are most concerned with version controlling is the code (i.e., the src/ directory). The data and output can and should be backed up somewhere else."
  },
  {
    "objectID": "repro.html#scripts",
    "href": "repro.html#scripts",
    "title": "1  Reproducibility",
    "section": "1.6 Scripts",
    "text": "1.6 Scripts\nI believe in short scripts that do one thing, rather then a huge unruly script that does everything. This helps adhere to Rule 5: Record all intermediate results, when possible in standardized formats & Rule 8: Generate hierarchical analysis output, allowing layers of increasing detail to be inspected. Creating small scripts with intermediate results mean that you in the future or a reviewer can easily jump into the analysis mid-way and explore the data.\nIf you read Jenny Bryan’s blog post on a project-oriented workflow referenced earlier, you likely ran across this advice:\n\nWhat about objects that take a long time to create? Isolate that bit in its own script and write the precious object to file with saveRDS(my_precious, here(\"results\", \"my_precious.rds\")). Now you can develop scripts to do downstream work that reload the precious object via my_precious &lt;- readRDS(here(\"results\", \"my_precious.rds\")). It is a good idea to break data analysis into logical, isolated pieces anyway.\n\nThis is my favorite way to code.\nImagine you have an RNA-sequencing project. The journal will require you to provide the raw sequence files. But you should also provide your audience with the raw counts file, as well as a .rds file that contains the full DESeq2 object. This allows them to easily explore the data for themselves, rather than start from step zero. Then they could easily begin again at the model analysis step, without having to repeat the mapping steps.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\n\n1.6.1 Driver scripts\nIf you now have a bunch of small scripts that do small tasks, it can be useful to create a top-level script that executes all the code in the project, generating all plots and results. This both ensures that your results are reproducible and that if you need to change one small thing, like your input data, you can easily regenerate all your results.\n\n\n\nsrc/driver.R\n\n# ------------------------------------------------------------------------------\n# Simple example driver script to execute all scripts\n# TS O'Leary\n# ------------------------------------------------------------------------------\n\n# Source all files\nsource(here::here(\"src/analysis_1/00_normalize.R\"))\nsource(here::here(\"src/analysis_1/01_analyze.R\"))\nsource(here::here(\"src/analysis_1/02_model.R\"))\nsource(here::here(\"src/analysis_1/03_integrate.R\"))\n\n\nOne thing that I have been experimenting with is using\n\n\n1.6.2 Snippets\nYou should use the available tools as much as you can to aid your workflow.\nI use snippets to create my script templates.\n\nsnippet mhead_snip\n    # ------------------------------------------------------------------------------\n    # ${1:script_description}\n    # TS O'Leary\n    # ------------------------------------------------------------------------------\n\n    # Load libraries\n    library(tidyverse)\n\n    # Load data\n    dat &lt;- read_csv(here::here(\"data/raw/starwars.csv\"))\n    \n    # Analyze data\n    dat &lt;- dat %&gt;%\n    group_by(Species) %&gt;%\n        count()\n    \n    # Save data\n    saveRDS(here::here(\"data/processed/count.rds\"))\n\nThis template ensures that I do several things:\n\nAdd a top level description to each file. I usually try to keep it to one sentance that says what the script is doing. If you have split up your scripts into bite sized chunks, this should be easy.\nGives a place to load libraries and data at the top of the script.\nReminds me to save the output at the end of the script.\n\n\n\n1.6.3 Quick tools\n\n\n1.6.4 Scratch code\nI often find that I write code that is not used in the final analysis. You may find yourself doing the same. It is sometimes a random exploratory figure that doesn’t end up telling you much, or maybe you normalized some data in the wrong way, or used an inappropriate type of statistical model. But in each case, you have spent some valuable amount of time writing that code, and so you are reluctant to remove it from you script. So you just comment it out – or worse, just leave it hanging there in the script. After all, it might be useful down the line, somehow, somewhere. I sympathize with that, but I think it is worth removing all unnecessary code. It will help you in the future when you don’t remember what you did, and don’t know if that bit of code is important.\n\n\n\n\n\n\nA tip for removing all unecessary or redundant code\n\n\n\nIt can be hard to strip your code down to only the necessary bits, but it is worth it for the sake of clarity and reproducibility. I sometimes create a scratch.R file or a scratch/ directory where I copy and paste bits of code that I am reluctant to throw away. It helps clean up the final code and makes me feel a little less like I wasted my time."
  },
  {
    "objectID": "repro.html#sec-vc",
    "href": "repro.html#sec-vc",
    "title": "1  Reproducibility",
    "section": "1.7 Version control",
    "text": "1.7 Version control\nThe details of the software are beyond the scope of this workshop, but one important way people ensure the reproducibility of their projects is to utilize Version Control. In short, Version Control is a useful way to make sure that as you edit and add to large projects over time you don’t lose or change any of the bits that make it work. For example, if you were to accidentally break a script, you could restore to a previous working version of that file, and then begin again. There are several software designed to do this, but the most popular in the data science world is Git and GitHub.\nThese tools can seem intimidating at first – especially because they typically are interfaced with in the command line. But if it makes you more comfortable, you can use the point-and-click approach to git within RStudio itself or a desktop clients (e.g., GitHub Desktop). Here is a very useful tutorial on how to use Git and GitHub within RStudio.\n\n\n\n\nGoodman, Steven N, Daniele Fanelli, and John P A Ioannidis. 2016. “What Does Research Reproducibility Mean?” Sci. Transl. Med. 8 (341): 341ps12.\n\n\nNational Academies of Sciences, Engineering, Medicine, Policy, Global Affairs, Committee on Science, Engineering, Medicine, Public Policy, Board on Research Data, et al. 2019. Understanding Reproducibility and Replicability. National Academies Press (US).\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, and Eivind Hovig. 2013. “Ten Simple Rules for Reproducible Computational Research.” PLoS Comput. Biol. 9 (10): e1003285."
  },
  {
    "objectID": "repro.html#footnotes",
    "href": "repro.html#footnotes",
    "title": "1  Reproducibility",
    "section": "",
    "text": "Please see Goodman, Fanelli, and Ioannidis (2016) for a more rigorous discussion of terms.↩︎\nOne example of this sort of reproducibility, was the independent sets of experiments that showed that DNA as the hereditary molecule.↩︎\nI hope the workshop helps 😁!↩︎\nI definitely don’t have a perfect workflow, but it has gotten better slowly over the years.↩︎\nIn particular, taking control of the small details that make your code easier to share and easier for others to understand↩︎\nGoogle data provenance and look at the flow charts.↩︎\nStatistical programming is right in R’s wheelhouse. And it is also the most common type of programming for early career students in my discipline. You design and conduct an experiment. You generate data. You analyze data. You present data.↩︎\nAs with all advice in these workshop, these are just my opinions – no more. And as with all rules, there are always good exceptions to breaking any of these rules.↩︎\nIf some of the tips don’t make sense or you want more context, read on!↩︎\nEither in reality or just as a mental exercise.↩︎\nWhat’s in the BOX???↩︎\nRead this link to R for Data Science, for more information.↩︎\nCheck out Neverwhere by Neil Gaiman↩︎"
  },
  {
    "objectID": "tidyverse.html#why-use-the-the-tidyverse",
    "href": "tidyverse.html#why-use-the-the-tidyverse",
    "title": "2  Tidyverse",
    "section": "2.1 Why use the the tidyverse?",
    "text": "2.1 Why use the the tidyverse?\nThere are base R equivalents to most things that you can do in the tidyverse. So you might wonder why it is necessary, or even useful, to learn the tidyverse. I think that skepticism is fair, but here are a few reasons why I think you should not only learn the tidyverse, but make it a regular part of your workflow1.\n\nAs a data scientist, most of your time will be spent writing code, not waiting for code to execute. Therefore you should put more value the coding style that is easiest to write and understand. The tidyverse emphasizes human readable code.\nBecause of the flexible nature of some of the tidyverse functions, the tidyverse can make for more reproducible code, that is less likely to break if some of the underlying data has changed or been added too.\nAn increasing number of newly developed packages depend on the tidyverse. So you might as well embrace it.\nYou are already using it! If have made any figures in R, more likely than not, you are already used one tidyverse package, ggplot2.\n\n\n2.1.1 Tidyverse style\n\n\n\n\n\n\nThe tidy tools manifesto\n\n\n\nMy favorite part of the tidyverse is the final principle in this manifesto:\n\nDesign for humans. “Programs must be written for people to read, and only incidentally for machines to execute.” — Hal Abelson\n\n\n\nThe tidyverse style guide\n\n“Good coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread.” 2\n\n\n\n\n\n\n\nCheat sheets\n\n\n\nTidyverse packages can help with many common tasks. Check out these cheat sheets for quick reference.\n\nData import\nData tidying\nData transformation\nData visualization\nFunctional programming\nStrings\nFactors\n\n\n\n\n# Load library\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\n\n\nRather than loading each package individually – I often just load all of the core packages with the convenient library(tidyverse)3. Most of my scripts are dependent on at least three of the core packages, so it is easier to just have them all included. But you could load each individually."
  },
  {
    "objectID": "tidyverse.html#tidy-data",
    "href": "tidyverse.html#tidy-data",
    "title": "2  Tidyverse",
    "section": "2.2 Tidy data",
    "text": "2.2 Tidy data\nThe tidyverse gets its name from the type of data that it is designed to interact with – tidy data. So let’s quickly define tidy data4.\n\n\n\n\n\n\nTidy data – definition\n\n\n\n\nEvery column is a variable.\nEvery row is an observation.\nEvery cell is a single value.\n\n\n\nBut that definition is a bit abstract – especially if you have never thought about whether data is messy or tidy before – so let’s try a practical example.\nBelow is some made-up messy data.\nImagine over the course of several days, you measure the height of a few plants\n\n# Make up some random data\ndat &lt;- tibble(\n  plant_id = 1:15,\n  week1 = rnorm(15, mean = 10, sd = 3),\n  week2 = week1*runif(15, min = 1, max = 1.5),\n  week3 = week2*runif(15, min = 1, max = 1.5),\n  week4 = week3*runif(15, min = 1, max = 1.5),\n  week5 = week4*runif(15, min = 1, max = 1.5)\n)\n\n# Print the data\ndat\n\n# A tibble: 15 × 6\n   plant_id week1 week2 week3 week4 week5\n      &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1        1 10.6  14.2  16.3   22.3  27.9\n 2        2  7.19 10.6  12.0   15.1  19.4\n 3        3  7.66  8.92 12.8   13.1  18.5\n 4        4  8.30 11.4  15.4   15.9  23.7\n 5        5 12.5  16.8  20.3   29.5  31.1\n 6        6  8.86 10.6  15.5   17.8  23.8\n 7        7 13.7  17.9  22.9   31.9  40.2\n 8        8 11.4  13.3  15.1   18.4  26.6\n 9        9 10.9  14.6  17.8   18.2  23.1\n10       10 10.7  11.9  12.5   13.4  17.4\n11       11 12.4  17.3  23.4   33.5  35.7\n12       12  6.11  7.62 10.4   13.6  14.3\n13       13 10.1  10.6  13.6   19.4  26.6\n14       14  5.83  7.05  9.92  10.3  15.0\n15       15  8.89 10.9  12.1   17.9  21.9\n\n\n\n2.2.1 Let’s tidy it\n\ndat |&gt;\n  pivot_longer(contains(\"week\"),\n               names_to = \"week\",\n               values_to = \"height_cm\")\n\n# A tibble: 75 × 3\n   plant_id week  height_cm\n      &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1        1 week1     10.6 \n 2        1 week2     14.2 \n 3        1 week3     16.3 \n 4        1 week4     22.3 \n 5        1 week5     27.9 \n 6        2 week1      7.19\n 7        2 week2     10.6 \n 8        2 week3     12.0 \n 9        2 week4     15.1 \n10        2 week5     19.4 \n# … with 65 more rows\n\n\n\nBAM! That is tidy data. 1. Every column is a variable – id, time, height. 2. Every row is an observation – a height measurement on a single plant. 3. Every cell is a single value.\n\n\ndat |&gt;\n  pivot_longer(contains(\"week\"),\n               names_to = \"week\",\n               values_to = \"height_cm\") |&gt; \n  mutate(week = as.numeric(str_remove_all(week, \"week\")))\n\n# A tibble: 75 × 3\n   plant_id  week height_cm\n      &lt;int&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1        1     1     10.6 \n 2        1     2     14.2 \n 3        1     3     16.3 \n 4        1     4     22.3 \n 5        1     5     27.9 \n 6        2     1      7.19\n 7        2     2     10.6 \n 8        2     3     12.0 \n 9        2     4     15.1 \n10        2     5     19.4 \n# … with 65 more rows"
  },
  {
    "objectID": "tidyverse.html#advanced-techniques",
    "href": "tidyverse.html#advanced-techniques",
    "title": "2  Tidyverse",
    "section": "2.3 Advanced techniques",
    "text": "2.3 Advanced techniques\n\nOther useful tidyverse packages\n\nbroom – clean model output – technically a subpackage of tidymodels a cousin of the tidyverse\nrvest – web scraping – mining data from a website\nmodelr – modelling – support for modelling data in the tidyverse"
  },
  {
    "objectID": "tidyverse.html#importing-data",
    "href": "tidyverse.html#importing-data",
    "title": "2  Tidyverse",
    "section": "2.4 Importing data",
    "text": "2.4 Importing data\nI find it a lot easier to define the data structure as you import data. And it creates a tibble instead of data.frame.\nThere are several reasons to prefer readr::read_csv() over base R’s read.csv."
  },
  {
    "objectID": "tidyverse.html#tools-for-quick-clean-up",
    "href": "tidyverse.html#tools-for-quick-clean-up",
    "title": "2  Tidyverse",
    "section": "2.5 Tools for quick clean up",
    "text": "2.5 Tools for quick clean up\nA hazard of caring about how coding in the tidyverse style, is that you will notice bad formatting everywhere.\n\n2.5.1 Stylr package\n\n\n2.5.2 Janitor package\nJanitor package\nCleaning up data\n\niris |&gt; \n  janitor::clean_names()\n\n    sepal_length sepal_width petal_length petal_width    species\n1            5.1         3.5          1.4         0.2     setosa\n2            4.9         3.0          1.4         0.2     setosa\n3            4.7         3.2          1.3         0.2     setosa\n4            4.6         3.1          1.5         0.2     setosa\n5            5.0         3.6          1.4         0.2     setosa\n6            5.4         3.9          1.7         0.4     setosa\n7            4.6         3.4          1.4         0.3     setosa\n8            5.0         3.4          1.5         0.2     setosa\n9            4.4         2.9          1.4         0.2     setosa\n10           4.9         3.1          1.5         0.1     setosa\n11           5.4         3.7          1.5         0.2     setosa\n12           4.8         3.4          1.6         0.2     setosa\n13           4.8         3.0          1.4         0.1     setosa\n14           4.3         3.0          1.1         0.1     setosa\n15           5.8         4.0          1.2         0.2     setosa\n16           5.7         4.4          1.5         0.4     setosa\n17           5.4         3.9          1.3         0.4     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.7         3.8          1.7         0.3     setosa\n20           5.1         3.8          1.5         0.3     setosa\n21           5.4         3.4          1.7         0.2     setosa\n22           5.1         3.7          1.5         0.4     setosa\n23           4.6         3.6          1.0         0.2     setosa\n24           5.1         3.3          1.7         0.5     setosa\n25           4.8         3.4          1.9         0.2     setosa\n26           5.0         3.0          1.6         0.2     setosa\n27           5.0         3.4          1.6         0.4     setosa\n28           5.2         3.5          1.5         0.2     setosa\n29           5.2         3.4          1.4         0.2     setosa\n30           4.7         3.2          1.6         0.2     setosa\n31           4.8         3.1          1.6         0.2     setosa\n32           5.4         3.4          1.5         0.4     setosa\n33           5.2         4.1          1.5         0.1     setosa\n34           5.5         4.2          1.4         0.2     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.0         3.2          1.2         0.2     setosa\n37           5.5         3.5          1.3         0.2     setosa\n38           4.9         3.6          1.4         0.1     setosa\n39           4.4         3.0          1.3         0.2     setosa\n40           5.1         3.4          1.5         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n42           4.5         2.3          1.3         0.3     setosa\n43           4.4         3.2          1.3         0.2     setosa\n44           5.0         3.5          1.6         0.6     setosa\n45           5.1         3.8          1.9         0.4     setosa\n46           4.8         3.0          1.4         0.3     setosa\n47           5.1         3.8          1.6         0.2     setosa\n48           4.6         3.2          1.4         0.2     setosa\n49           5.3         3.7          1.5         0.2     setosa\n50           5.0         3.3          1.4         0.2     setosa\n51           7.0         3.2          4.7         1.4 versicolor\n52           6.4         3.2          4.5         1.5 versicolor\n53           6.9         3.1          4.9         1.5 versicolor\n54           5.5         2.3          4.0         1.3 versicolor\n55           6.5         2.8          4.6         1.5 versicolor\n56           5.7         2.8          4.5         1.3 versicolor\n57           6.3         3.3          4.7         1.6 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n59           6.6         2.9          4.6         1.3 versicolor\n60           5.2         2.7          3.9         1.4 versicolor\n61           5.0         2.0          3.5         1.0 versicolor\n62           5.9         3.0          4.2         1.5 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.9          4.7         1.4 versicolor\n65           5.6         2.9          3.6         1.3 versicolor\n66           6.7         3.1          4.4         1.4 versicolor\n67           5.6         3.0          4.5         1.5 versicolor\n68           5.8         2.7          4.1         1.0 versicolor\n69           6.2         2.2          4.5         1.5 versicolor\n70           5.6         2.5          3.9         1.1 versicolor\n71           5.9         3.2          4.8         1.8 versicolor\n72           6.1         2.8          4.0         1.3 versicolor\n73           6.3         2.5          4.9         1.5 versicolor\n74           6.1         2.8          4.7         1.2 versicolor\n75           6.4         2.9          4.3         1.3 versicolor\n76           6.6         3.0          4.4         1.4 versicolor\n77           6.8         2.8          4.8         1.4 versicolor\n78           6.7         3.0          5.0         1.7 versicolor\n79           6.0         2.9          4.5         1.5 versicolor\n80           5.7         2.6          3.5         1.0 versicolor\n81           5.5         2.4          3.8         1.1 versicolor\n82           5.5         2.4          3.7         1.0 versicolor\n83           5.8         2.7          3.9         1.2 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           6.7         3.1          4.7         1.5 versicolor\n88           6.3         2.3          4.4         1.3 versicolor\n89           5.6         3.0          4.1         1.3 versicolor\n90           5.5         2.5          4.0         1.3 versicolor\n91           5.5         2.6          4.4         1.2 versicolor\n92           6.1         3.0          4.6         1.4 versicolor\n93           5.8         2.6          4.0         1.2 versicolor\n94           5.0         2.3          3.3         1.0 versicolor\n95           5.6         2.7          4.2         1.3 versicolor\n96           5.7         3.0          4.2         1.2 versicolor\n97           5.7         2.9          4.2         1.3 versicolor\n98           6.2         2.9          4.3         1.3 versicolor\n99           5.1         2.5          3.0         1.1 versicolor\n100          5.7         2.8          4.1         1.3 versicolor\n101          6.3         3.3          6.0         2.5  virginica\n102          5.8         2.7          5.1         1.9  virginica\n103          7.1         3.0          5.9         2.1  virginica\n104          6.3         2.9          5.6         1.8  virginica\n105          6.5         3.0          5.8         2.2  virginica\n106          7.6         3.0          6.6         2.1  virginica\n107          4.9         2.5          4.5         1.7  virginica\n108          7.3         2.9          6.3         1.8  virginica\n109          6.7         2.5          5.8         1.8  virginica\n110          7.2         3.6          6.1         2.5  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          6.4         2.7          5.3         1.9  virginica\n113          6.8         3.0          5.5         2.1  virginica\n114          5.7         2.5          5.0         2.0  virginica\n115          5.8         2.8          5.1         2.4  virginica\n116          6.4         3.2          5.3         2.3  virginica\n117          6.5         3.0          5.5         1.8  virginica\n118          7.7         3.8          6.7         2.2  virginica\n119          7.7         2.6          6.9         2.3  virginica\n120          6.0         2.2          5.0         1.5  virginica\n121          6.9         3.2          5.7         2.3  virginica\n122          5.6         2.8          4.9         2.0  virginica\n123          7.7         2.8          6.7         2.0  virginica\n124          6.3         2.7          4.9         1.8  virginica\n125          6.7         3.3          5.7         2.1  virginica\n126          7.2         3.2          6.0         1.8  virginica\n127          6.2         2.8          4.8         1.8  virginica\n128          6.1         3.0          4.9         1.8  virginica\n129          6.4         2.8          5.6         2.1  virginica\n130          7.2         3.0          5.8         1.6  virginica\n131          7.4         2.8          6.1         1.9  virginica\n132          7.9         3.8          6.4         2.0  virginica\n133          6.4         2.8          5.6         2.2  virginica\n134          6.3         2.8          5.1         1.5  virginica\n135          6.1         2.6          5.6         1.4  virginica\n136          7.7         3.0          6.1         2.3  virginica\n137          6.3         3.4          5.6         2.4  virginica\n138          6.4         3.1          5.5         1.8  virginica\n139          6.0         3.0          4.8         1.8  virginica\n140          6.9         3.1          5.4         2.1  virginica\n141          6.7         3.1          5.6         2.4  virginica\n142          6.9         3.1          5.1         2.3  virginica\n143          5.8         2.7          5.1         1.9  virginica\n144          6.8         3.2          5.9         2.3  virginica\n145          6.7         3.3          5.7         2.5  virginica\n146          6.7         3.0          5.2         2.3  virginica\n147          6.3         2.5          5.0         1.9  virginica\n148          6.5         3.0          5.2         2.0  virginica\n149          6.2         3.4          5.4         2.3  virginica\n150          5.9         3.0          5.1         1.8  virginica\n\n\n\n# Create a .csv file to import\nwrite_csv(iris, \"iris.csv\")\n\n\n# Try read.csv\nd.f &lt;- read.csv(\"iris.csv\")\n\nstr(d.f)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : chr  \"setosa\" \"setosa\" \"setosa\" \"setosa\" ...\n\n\n\n# Try read_csv\nread_csv(\"iris.csv\")\n\nRows: 150 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Species\ndbl (4): Sepal.Length, Sepal.Width, Petal.Length, Petal.Width\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 150 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# … with 140 more rows\n\n# Set col_type as you import data -- allows you to define level order too\nd_f &lt;- read_csv(\"iris.csv\",\n                col_types = list(Species = col_factor(c(\"versicolor\",\n                                                        \"setosa\", \n                                                        \"virginica\"))))\nd_f\n\n# A tibble: 150 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# … with 140 more rows\n\nstr(d_f)\n\nspc_tbl_ [150 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Sepal.Length: num [1:150] 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num [1:150] 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num [1:150] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num [1:150] 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"versicolor\",\"setosa\",..: 2 2 2 2 2 2 2 2 2 2 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Sepal.Length = col_double(),\n  ..   Sepal.Width = col_double(),\n  ..   Petal.Length = col_double(),\n  ..   Petal.Width = col_double(),\n  ..   Species = col_factor(levels = c(\"versicolor\", \"setosa\", \"virginica\"), ordered = FALSE, include_na = FALSE)\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nglimpse(d_f)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…"
  },
  {
    "objectID": "tidyverse.html#wrangling-data",
    "href": "tidyverse.html#wrangling-data",
    "title": "2  Tidyverse",
    "section": "2.6 Wrangling data",
    "text": "2.6 Wrangling data\n\n2.6.1 Intro to dplyr\ndplyr has a few core functions that are built to work on\nTaken from the dplyr vignette.\n\n2.6.1.1 Rows\n\nfilter() chooses rows based on column values.\nslice() chooses rows based on location.\narrange() changes the order of the rows.\n\n\n\n2.6.1.2 Columns\n\nselect() changes whether or not a column is included.\nrename() changes the name of columns.\nmutate() changes the values of columns and creates new columns.\nrelocate() changes the order of the columns.\n\n\n\n2.6.1.3 Groups of rows\n\nsummarise() collapses a group into a single row.\n\n\n\n\n2.6.2 Pipe %&gt;%\nFrom magrittr.\n\nx %&gt;% f is equivalent to f(x)\nx %&gt;% f(y) is equivalent to f(x, y)\nx %&gt;% f %&gt;% g %&gt;% h is equivalent to h(g(f(x)))\n\nThe argument placeholder\n\nx %&gt;% f(y, .) is equivalent to f(y, x)\nx %&gt;% f(y, z = .) is equivalent to f(y, z = x)\n\n\n\n\n\n\n\n|&gt; native pipe operator\n\n\n\nIn new versions of R (&gt; 4.1.0), there is now a native pipe operator that comes within the syntax of R itself, rather than being loaded as a part of a separate package.\nAlthough they are largely the same, there are some meaningful differences between the two. These two articles from the tidyverse and Isabella Velásquez do a good job of explaining the differences relevant differences.\nI have started just using the native pipe (|&gt;) for almost all cases now. First, becuase it just looks cleaner. But also because then you can use a pipe without explicitly loading the mattingr package (_e.g. iris |&gt; dplyr::glimpse()). Where if you had used the magrittr pipe (%&gt;%), but not loaded the magrittr package, you would get an error.\n\n\n\n2.6.2.1 A fun example from R for data science\n\nfoo_foo &lt;- little_bunny()\nfoo_foo_1 &lt;- hop(foo_foo, through = forest)\nfoo_foo_2 &lt;- scoop(foo_foo_1, up = field_mice)\nfoo_foo_3 &lt;- bop(foo_foo_2, on = head)\n\n\nfoo_foo |&gt;\n  hop(through = forest) |&gt;\n  scoop(up = field_mice) |&gt;\n  bop(on = head)\n\n\n\n\n2.6.3 arrange\n\n# dat |&gt;\n#   arrange(tissue, iu_gfw)\n\n\n# dat |&gt;\n#   arrange(desc(tissue), desc(iu_gfw))\n\n\n\n2.6.4 summarise\n\n# dat |&gt;\n#   summarise(iu_gfw_avg = mean(iu_gfw))\n\n\n\n2.6.5 group_by\n\n# dat |&gt;\n#   group_by(tissue) |&gt;\n#   summarise(iu_gfw_avg = mean(iu_gfw),\n#             iu_gfw_sd = sd(iu_gfw))\n\nWarning that you must be careful about the order when reusing variable names.\n\n# # Bad order\n# dat |&gt;\n#   group_by(tissue) |&gt;\n#   summarise(iu_gfw = mean(iu_gfw),\n#             sd = sd(iu_gfw))\n\n\n# # This order works because it collapses the data into a mean last\n# dat |&gt;\n#   group_by(tissue) |&gt;\n#   summarise(sd = sd(iu_gfw),\n#             iu_gfw = mean(iu_gfw))\n\nPrint out a pretty table using kableExtra.\n\n\n2.6.6 nest\nFor the most part, I find myself working with 2D structured data (e.g., tibble or data.frame). But sometimes you need to\n\nChickWeight |&gt;\n  glimpse()\n\nRows: 578\nColumns: 4\n$ weight &lt;dbl&gt; 42, 51, 59, 64, 76, 93, 106, 125, 149, 171, 199, 205, 40, 49, 5…\n$ Time   &lt;dbl&gt; 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 1…\n$ Chick  &lt;ord&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ Diet   &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n\n\n\nChickWeight |&gt;\n  group_by(Chick, Diet) |&gt;\n  nest() \n\n# A tibble: 50 × 3\n# Groups:   Chick, Diet [50]\n   Chick Diet  data             \n   &lt;ord&gt; &lt;fct&gt; &lt;list&gt;           \n 1 1     1     &lt;tibble [12 × 2]&gt;\n 2 2     1     &lt;tibble [12 × 2]&gt;\n 3 3     1     &lt;tibble [12 × 2]&gt;\n 4 4     1     &lt;tibble [12 × 2]&gt;\n 5 5     1     &lt;tibble [12 × 2]&gt;\n 6 6     1     &lt;tibble [12 × 2]&gt;\n 7 7     1     &lt;tibble [12 × 2]&gt;\n 8 8     1     &lt;tibble [11 × 2]&gt;\n 9 9     1     &lt;tibble [12 × 2]&gt;\n10 10    1     &lt;tibble [12 × 2]&gt;\n# … with 40 more rows\n\n\n\nChickWeight_nest &lt;- ChickWeight |&gt;\n  group_by(Chick, Diet) |&gt;\n  nest() \n\nChickWeight_nest$data[1:2]\n\n[[1]]\n# A tibble: 12 × 2\n   weight  Time\n    &lt;dbl&gt; &lt;dbl&gt;\n 1     42     0\n 2     51     2\n 3     59     4\n 4     64     6\n 5     76     8\n 6     93    10\n 7    106    12\n 8    125    14\n 9    149    16\n10    171    18\n11    199    20\n12    205    21\n\n[[2]]\n# A tibble: 12 × 2\n   weight  Time\n    &lt;dbl&gt; &lt;dbl&gt;\n 1     40     0\n 2     49     2\n 3     58     4\n 4     72     6\n 5     84     8\n 6    103    10\n 7    122    12\n 8    138    14\n 9    162    16\n10    187    18\n11    209    20\n12    215    21\n\n\n\n\n2.6.7 broom\n\n# Load library\nlibrary(broom)\n\nCheck out the broom vignette.\nAnd the broom and dplyr vignette.\ntidy: constructs a tibble that summarizes the model’s statistical findings. This includes coefficients and p-values for each term in a regression, per-cluster information in clustering applications, or per-test information for multtest functions.\nglance: construct a concise one-row summary of the model. This typically contains values such as R^2, adjusted R^2, and residual standard error that are computed once for the entire model.\n\nChickWeight |&gt;\n  group_by(Chick, Diet) |&gt;\n  nest() |&gt;\n  mutate(\n    fit = map(data, ~ lm(weight ~ Time, data = .x)),\n    tidied = map(fit, tidy),\n    glanced = map(fit, glance)\n  ) |&gt; \n  unnest(tidied) \n\n# A tibble: 100 × 10\n# Groups:   Chick, Diet [50]\n   Chick Diet  data     fit    term    estim…¹ std.e…² stati…³  p.value glanced \n   &lt;ord&gt; &lt;fct&gt; &lt;list&gt;   &lt;list&gt; &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;list&gt;  \n 1 1     1     &lt;tibble&gt; &lt;lm&gt;   (Inter…   24.5    6.73     3.64 4.56e- 3 &lt;tibble&gt;\n 2 1     1     &lt;tibble&gt; &lt;lm&gt;   Time       7.99   0.524   15.3  2.97e- 8 &lt;tibble&gt;\n 3 2     1     &lt;tibble&gt; &lt;lm&gt;   (Inter…   24.7    4.93     5.01 5.26e- 4 &lt;tibble&gt;\n 4 2     1     &lt;tibble&gt; &lt;lm&gt;   Time       8.72   0.384   22.7  6.15e-10 &lt;tibble&gt;\n 5 3     1     &lt;tibble&gt; &lt;lm&gt;   (Inter…   23.2    5.08     4.56 1.04e- 3 &lt;tibble&gt;\n 6 3     1     &lt;tibble&gt; &lt;lm&gt;   Time       8.49   0.396   21.5  1.08e- 9 &lt;tibble&gt;\n 7 4     1     &lt;tibble&gt; &lt;lm&gt;   (Inter…   32.9    4.01     8.21 9.42e- 6 &lt;tibble&gt;\n 8 4     1     &lt;tibble&gt; &lt;lm&gt;   Time       6.09   0.312   19.5  2.70e- 9 &lt;tibble&gt;\n 9 5     1     &lt;tibble&gt; &lt;lm&gt;   (Inter…   16.9    7.56     2.24 4.93e- 2 &lt;tibble&gt;\n10 5     1     &lt;tibble&gt; &lt;lm&gt;   Time      10.1    0.588   17.1  9.88e- 9 &lt;tibble&gt;\n# … with 90 more rows, and abbreviated variable names ¹​estimate, ²​std.error,\n#   ³​statistic\n\n\n\nChickWeight |&gt;\n  ggplot() +\n  geom_line(aes(x = Time, \n                 y = weight, \n                 color = Chick)) +\n  facet_wrap(~ Diet)\n\n\n\n\n\n\n\n\nWickham, Hadley. 2014. “Tidy Data.” J. Stat. Softw. 59 (September): 1–23."
  },
  {
    "objectID": "tidyverse.html#footnotes",
    "href": "tidyverse.html#footnotes",
    "title": "2  Tidyverse",
    "section": "",
    "text": "Maybe even convert some of your old scripts to incorporate the tidyverse.↩︎\nHonestly I think that joke underestimates how important good coding style is. You can actually read “butitsuremakesthingseasiertoread” pretty easily because you are an expert reader – you’ve been at it everyday for decades – coding, probably not so much. I don’t think can overstate how important I think it is to write visually pleasing code.↩︎\nNotice above that this function call loads nine core tidyverse packages. Any other tidyverse packages, including some we will cover later (e.g., broom), must be loaded separately.↩︎\nWickham (2014)↩︎"
  },
  {
    "objectID": "data_viz.html#gallery-of-visualizations",
    "href": "data_viz.html#gallery-of-visualizations",
    "title": "3  Data visualization",
    "section": "3.1 Gallery of visualizations",
    "text": "3.1 Gallery of visualizations"
  },
  {
    "objectID": "data_viz.html#explore-the-data",
    "href": "data_viz.html#explore-the-data",
    "title": "3  Data visualization",
    "section": "3.2 Explore the data",
    "text": "3.2 Explore the data\n\nMeet the Palmer penguins\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\n\n\n\nTest\n\n\n\n\n\n\n\n# Load libraries\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(palmerpenguins)\n\n\n# Take a peak at the data\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…"
  },
  {
    "objectID": "data_viz.html#choosing-a-type-of-visualization",
    "href": "data_viz.html#choosing-a-type-of-visualization",
    "title": "3  Data visualization",
    "section": "3.3 Choosing a type of visualization",
    "text": "3.3 Choosing a type of visualization\nOkay this is a little bit of a warm up\nChoosing a type of visualization depends entirely on the sorts of questions you are trying to ask. So for now, let’s pick a few different questions. I don’t know anything about these penguins. So here are some simple questions that I have brainstormed:\n\nAre different species of penguins different weights?\nAre penguins from different islands different weights?\n\n\nWe will stick with the first question for now. But it is worth trying the others.\nI really hate the default theme for ggplot. So rather than look at it. Let’s just set something that is a little easier on the eyes at the beginning. This command below will set cowplot::theme_minimal_grid() as the default theme for all plots going forward.\n\n# Set a nicer looking theme as a place holder\ntheme_set(cowplot::theme_minimal_grid())\n\n\nBox plotViolin plotStrip plotBeeswarmHistogramDensity plot\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_boxplot(\n    aes(x = species,\n        y = body_mass_g))\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_violin(\n    aes(x = species,\n        y = body_mass_g))\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_jitter(\n    aes(x = species,\n        y = body_mass_g),\n    width = 0.1)\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  ggbeeswarm::geom_beeswarm(\n    corral.width = 2.0,\n    aes(x = species,\n        y = body_mass_g)) \n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_histogram(\n    aes(x = body_mass_g),\n    color = \"grey20\",\n    fill = \"grey80\",\n    bins = 30) +\n  facet_wrap(~species,\n             nrow = 3)\n\n\n\n\n\n\n\npenguins |&gt; \n  ggplot() +\n  geom_density(\n    aes(x = body_mass_g,\n        color = species,\n        fill = species),\n    alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice the advantages and disadvantages of the different styles.\n\n\n\nSome have more information than others. If you had to pick one? Which would you pick?\n\n\nFortunately we don’t have to pick."
  },
  {
    "objectID": "data_viz.html#limits",
    "href": "data_viz.html#limits",
    "title": "3  Data visualization",
    "section": "3.4 Limits",
    "text": "3.4 Limits\n\npenguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_violin(width = 0.8) + \n  geom_boxplot(width = 0.2) +\n  scale_y_continuous(\n    limits = c(0, 7000)\n  )\n\n\n\n\n\npenguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_boxplot(\n    width = 0.6,\n    outlier.shape = NA\n    ) + \n  ggbeeswarm::geom_beeswarm(\n    shape = 21,\n    width = 0.2\n    ) +\n  scale_y_continuous(\n    limits = c(0, 7000)\n  )"
  },
  {
    "objectID": "data_viz.html#creating-the-axes",
    "href": "data_viz.html#creating-the-axes",
    "title": "3  Data visualization",
    "section": "3.5 Creating the axes",
    "text": "3.5 Creating the axes\n\npenguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_boxplot(\n    width = 0.6,\n    outlier.shape = NA\n    ) + \n  ggbeeswarm::geom_beeswarm(\n    shape = 21,\n    width = 0.2\n    ) +\n  scale_y_continuous(\n    name = \"Body mass (g)\",\n    limits = c(0, 7000)\n    ) +\n  scale_x_discrete(\n   name = element_blank()\n  )"
  },
  {
    "objectID": "data_viz.html#choosing-a-theme",
    "href": "data_viz.html#choosing-a-theme",
    "title": "3  Data visualization",
    "section": "3.6 Choosing a theme",
    "text": "3.6 Choosing a theme\n\npenguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_boxplot(\n    width = 0.6,\n    outlier.shape = NA\n    ) + \n  ggbeeswarm::geom_beeswarm(\n    shape = 21,\n    width = 0.2\n    ) +\n  scale_y_continuous(\n    name = \"Body mass (g)\",\n    limits = c(0, 7000)\n    ) +\n  scale_x_discrete(\n   name = element_blank()\n   ) +\n  cowplot::theme_minimal_hgrid()\n\n\n\n\nOh no! Look at that brual\n\npenguins |&gt; \n  ggplot(\n    aes(x = species,\n        y = body_mass_g)\n    ) +\n  geom_boxplot(\n    width = 0.6,\n    outlier.shape = NA\n    ) + \n  ggbeeswarm::geom_beeswarm(\n    shape = 21,\n    width = 0.2\n    ) +\n  scale_y_continuous(\n    name = \"Body mass (g)\",\n    limits = c(0, 7000),\n    expand = c(0, 0.5)\n    ) +\n  scale_x_discrete(\n   name = element_blank()\n   ) +\n  cowplot::theme_minimal_hgrid()"
  },
  {
    "objectID": "data_viz.html#the-small-details",
    "href": "data_viz.html#the-small-details",
    "title": "3  Data visualization",
    "section": "3.7 The small details",
    "text": "3.7 The small details\n\npenguins |&gt;  \n  ggplot(\n    aes(x = body_mass_g)\n    ) +\n  geom_histogram(\n    color = \"grey20\",\n    fill = \"grey80\"\n    ) +\n  facet_grid(rows = vars(island),\n             cols = vars(species)) +\n  cowplot::theme_minimal_hgrid() +\n  theme(strip.background = element_rect(fill = \"grey90\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`)."
  },
  {
    "objectID": "data_viz.html#footnotes",
    "href": "data_viz.html#footnotes",
    "title": "3  Data visualization",
    "section": "",
    "text": "Shhh! Don’t tell that to Chapter 1 of this workshop.↩︎"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Goodman, Steven N, Daniele Fanelli, and John P A Ioannidis. 2016.\n“What Does Research Reproducibility Mean?” Sci. Transl.\nMed. 8 (341): 341ps12.\n\n\nNational Academies of Sciences, Engineering, Medicine, Policy, Global\nAffairs, Committee on Science, Engineering, Medicine, Public Policy,\nBoard on Research Data, et al. 2019. Understanding Reproducibility\nand Replicability. National Academies Press (US).\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, and Eivind Hovig.\n2013. “Ten Simple Rules for Reproducible Computational\nResearch.” PLoS Comput. Biol. 9 (10): e1003285.\n\n\nWickham, Hadley. 2014. “Tidy Data.” J. Stat.\nSoftw. 59 (September): 1–23."
  }
]